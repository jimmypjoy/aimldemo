{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f164aa49",
   "metadata": {},
   "source": [
    "# LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "214d1f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain \n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter \n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "import os\n",
    "from IPython.display import Image, display\n",
    "import streamlit as st\n",
    "from langchain.vectorstores import Chroma \n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.document_loaders import TextLoader \n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain_community.utilities.dalle_image_generator import DallEAPIWrapper\n",
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
    "from langchain.cache import InMemoryCache\n",
    "import langchain\n",
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate,SystemMessagePromptTemplate,AIMessagePromptTemplate\n",
    "from langchain.output_parsers import CommaSeparatedListOutputParser,DatetimeOutputParser\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.chains import SimpleSequentialChain,SequentialChain\n",
    "from langchain.memory import ChatMessageHistory\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "import pickle\n",
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from langchain_core.documents import Document\n",
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c968aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1539dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jimmy\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_core\\_api\\deprecation.py:151: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "llm = OpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2db1f0a",
   "metadata": {},
   "source": [
    "# Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d288563",
   "metadata": {},
   "outputs": [],
   "source": [
    "#llm('One sentence about Piscataway, NJ')\n",
    "llm('one sentence about Gospel of John chapter1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cac582",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = llm.generate(['Once sentence about Piscataway, NJ','One sentence about Edison, NJ'],max_tokens=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce89c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49600ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c6e869",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a233355b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.generations[0][0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42e3838",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.generations[1][0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd16dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba15f5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chat([HumanMessage(content='One sentence about Piscataway, NJ')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660a375e",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2bde9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3e1ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chat([SystemMessage(content='You are a comedian'),\n",
    "    HumanMessage(content='five sentencec about Piscataway, NJ')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef10cd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5546dcd7",
   "metadata": {},
   "source": [
    "## InMemoryCache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a690c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain.llm_cache = InMemoryCache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94a4572",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.predict('tell me one sentence about Somerset,NJ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8495e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.predict('tell me one sentence about Somerset,NJ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e374e766",
   "metadata": {},
   "source": [
    "## PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb3b40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = llm.generate([\"Can you explain in 5 sentences about Citibank?\"]*1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287b917c",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f35612e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for res in result.generations:\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d78fa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(\"Can you explain in 5 sentences about {company}?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b64391",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(llm=llm,prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bebfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.run('Citibank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef978c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.run('Wells Fargo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf02dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_input_prompt = PromptTemplate(input_variables=[],\n",
    "                                   template = 'Tell me a fact')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd57865",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_input_prompt.format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958e6101",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm(no_input_prompt.format())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3f033c",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_input_prompt = PromptTemplate(input_variables=['topic'],\n",
    "                                   template = 'Tell me a fact about {topic}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76937e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm(single_input_prompt.format(topic='Somerset NJ'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73863351",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_input_prompt = PromptTemplate(\n",
    "    input_variables=[\"topic\", \"level\"], \n",
    "    template=\"Tell me a fact about {topic} for a student {level} level.\"\n",
    ")\n",
    "llm(multiple_input_prompt.format(topic='Mars',level='8th Grade'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa16129",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_input_prompt.input_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9385dade",
   "metadata": {},
   "source": [
    "## Serizalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0082943",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_input_prompt.save(\"prompt.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13c2f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import load_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9050ac16",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_prompt = load_prompt('prompt.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa0dc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cc30bb",
   "metadata": {},
   "source": [
    "## Chat Model Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8233f8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template=\"You are an AI recipe assistant that specializes in {dietary_preference} dishes that can be prepared in {cooking_time}.\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8034277",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message_prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495a4902",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_template=\"{recipe_request}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b87894",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_message_prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38f5184",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6ae78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d820d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt.format_prompt(cooking_time=\"15 min\", dietary_preference=\"Vegan\", recipe_request=\"Quick Snack\").to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797029d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "request = chat_prompt.format_prompt(cooking_time=\"15 min\", dietary_preference=\"Vegan\", recipe_request=\"Quick Snack\").to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28a9345",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e839a10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chat(request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49f2168",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263d0f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b124fa",
   "metadata": {},
   "source": [
    "# Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "245b12a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jimmy\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_core\\_api\\deprecation.py:151: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a76674eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "store = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00aab602",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryChatMessageHistory()\n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51eb3abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(model, get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cdc89874",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"abc2\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b75efbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi! I'm JJ\")],\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4b1a151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nice to meet you, JJ! How can I assist you today?'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ade5b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What's my name?\")],\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af945ca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, I don't know your name as I am an AI assistant and do not have access to that information.\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168c9ad3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f47bc099",
   "metadata": {},
   "source": [
    "## Text embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb46607",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Some normal text to send to OpenAI to be embedded into a N dimensional vector\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d893dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f57a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_text = embeddings.embed_query(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc2edab",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(type(embedded_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7eacd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f5ce28",
   "metadata": {},
   "source": [
    "## Few shot promot/ Prevoulsy provided example to chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb72391",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"You are a helpful assistant providing description on places\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75756b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_input_text = \"Please provide two facts about Piscataway, NJ\"\n",
    "example_input_one = HumanMessagePromptTemplate.from_template(example_input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d68852",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_template = \"{example_input_text}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1935f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_output_text = \"\"\n",
    "example_output_one = HumanMessagePromptTemplate.from_template(example_input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1696ce13",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [system_message_prompt, example_input_one, example_output_one, human_message_prompt]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a986b378",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_example_text = \"Please provide two facts about Edison, NJ\"\n",
    "request = chat_prompt.format_prompt(example_input_text=some_example_text).to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf0f00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chat(request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a175d38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00095e1b",
   "metadata": {},
   "source": [
    "## Parsisng output- comma seperated values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286a812b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = CommaSeparatedListOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de13bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "format_instructions = output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c25020a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd1f154",
   "metadata": {},
   "outputs": [],
   "source": [
    "reply = \"one, two, three\"\n",
    "output_parser.parse(reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145b0280",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_template = '{request} {format_instructions}'\n",
    "human_prompt = HumanMessagePromptTemplate.from_template(human_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573085c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt = ChatPromptTemplate.from_messages([human_prompt])\n",
    "\n",
    "chat_prompt.format_prompt(request=\"Please provide 3 facts about Piscataway, NJ\",\n",
    "                   format_instructions = output_parser.get_format_instructions())\n",
    "\n",
    "request = chat_prompt.format_prompt(request=\"Please provide 3 facts about Piscataway, NJ\",\n",
    "                   format_instructions = output_parser.get_format_instructions()).to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bd581d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chat(request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57826f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6dd736",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d56727",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_formatted = output_parser.parse(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7636524e",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(output_formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff932e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_formatted[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61e79d5",
   "metadata": {},
   "source": [
    "## Parsisng output- Date time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfed3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.predict('When was Piscataway,NJ incorporated?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5868a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = DatetimeOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919f3a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33034c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_text = \"{request}\\n{format_instructions}\"\n",
    "human_prompt=HumanMessagePromptTemplate.from_template(template_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4e2162",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt = ChatPromptTemplate.from_messages([human_prompt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c9bb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chat_prompt.format(request=\"When was Piscataway,NJ incorporated?\",\n",
    "                   format_instructions=output_parser.get_format_instructions()\n",
    "                   ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1833b88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "request = chat_prompt.format_prompt(request=\"When was Piscataway,NJ incorporated?\",\n",
    "                   format_instructions=output_parser.get_format_instructions()\n",
    "                   ).to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168204e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chat(request,temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a4f9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4d48a5",
   "metadata": {},
   "source": [
    "## Pydantic JSON Parser- python object conversion of output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca31195",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db3da6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scientist(BaseModel):\n",
    "    discoveries: list = Field(description=\"Python list of discoveries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb275a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'Provide 3 discoveries of Thomas A Edison' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ded6808",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = PydanticOutputParser(pydantic_object=Scientist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584aac87",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5b943a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605e49fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = prompt.format_prompt(query=\"Provide 3 discoveries of Thomas A Edison\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1e5414",
   "metadata": {},
   "outputs": [],
   "source": [
    "#output = chat(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1c5a34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee76cc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0fa719c1",
   "metadata": {},
   "source": [
    "# logging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafb7827",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig()\n",
    "logging.getLogger('langchain.retrievers.multi_query').setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2064563d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9daa69f1",
   "metadata": {},
   "source": [
    "# Document/Data Connectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7ecaf0",
   "metadata": {},
   "source": [
    "## Loading CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0c327c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import CSVLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367497f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = CSVLoader('penguins.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07fa9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152e11dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe7396e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9825106f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2681a42d",
   "metadata": {},
   "source": [
    "## Loading custom .txt File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f856ad97",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'constitution.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd79dc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = TextLoader(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7a5c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48f3f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714139fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133466d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b39bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = Chroma.from_documents(chunks, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e56a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model='gpt-3.5-turbo', temperature=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70196ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever=vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d80c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = RetrievalQA.from_chain_type(llm, retriever=retriever )\n",
    "#crc = ConversationalRetrievalChain.from_llm(llm,retriever)\n",
    "#st.session_state.crc = crc\n",
    "#st.success('File uploaded, chunked and embedded successfully')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd97c3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'what is the age to be a senator?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86be7b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.run(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620659ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbd8a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_query_retriever = MultiQueryRetriever.from_llm(retriever=retriever,llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b37664",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_docs = multi_query_retriever.get_relevant_documents(query=question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a78b146",
   "metadata": {},
   "source": [
    "## ContextualCompressionRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57c1e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9575a955",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressor = LLMChainExtractor.from_llm(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca594ad0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824e7cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "compression_retriever = ContextualCompressionRetriever(base_compressor=compressor, base_retriever=retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4f88ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = vector_store.similarity_search('what is the age to be a senator?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813e00dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a12670",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_docs = compression_retriever.get_relevant_documents(\"what is the age to be a senator?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55240a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722a0b84",
   "metadata": {},
   "source": [
    "## Loading custom PDF File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e0db5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_name= 'doc_inputs/falcon-users-guide-2021-09.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8d1118",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_loader = PyPDFLoader(pdf_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f67a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = pdf_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f23d771",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f788855",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0af661",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055491f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = Chroma.from_documents(chunks, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6c6399",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model='gpt-3.5-turbo', temperature=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162e9c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever=vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0ec3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = RetrievalQA.from_chain_type(llm, retriever=retriever )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe941c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'where can I find the standard price for Falcon 9 and Falcon Heavy launch services?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8335e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.run(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba54ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de65bbc3",
   "metadata": {},
   "source": [
    "# Loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e5177b",
   "metadata": {},
   "source": [
    "## WebBaseLoader - loads web pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7540ecc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3552d209",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = WebBaseLoader(\"https://www.biblegateway.com/passage/?search=jn+1&version=NABRE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ede4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709082ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1e7f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(data[0].page_content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70875a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3915d5ca",
   "metadata": {},
   "source": [
    "## WikipediaLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fd679b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WikipediaLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f62472e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = WikipediaLoader(query='Gospel of John')\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2afc65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ac0cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0f9e2a",
   "metadata": {},
   "source": [
    "# ChromaDB file peristence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50a43ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = TextLoader(\"constitution.txt\")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b890ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split it into chunks\n",
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(chunk_size=500)\n",
    "docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc806217",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_function = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1fc15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load it into Chroma\n",
    "db = Chroma.from_documents(docs, embedding_function,persist_directory='chroma_db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c937e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpful to force a save\n",
    "db.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eaf0532",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_connection = Chroma(persist_directory='chroma_db/',embedding_function=embedding_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3810c833",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_doc = \"How many amendments are there?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c772bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = db_connection.similarity_search(new_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea94a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc0028d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a new document\n",
    "loader = TextLoader(\"custom_text_data.txt\")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7ba138",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(chunk_size=500)\n",
    "docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8d9269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load it into Chroma\n",
    "db = Chroma.from_documents(docs, embedding_function,persist_directory='chroma_db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ca2f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = db.similarity_search('asdfg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16d0301",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9acd0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9096af24",
   "metadata": {},
   "source": [
    "# Create Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe883057",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.9)\n",
    "prompt = \"Brooklyn bridge in teh night\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19385fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_url = DallEAPIWrapper().run(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759e9f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1115351",
   "metadata": {},
   "outputs": [],
   "source": [
    "!(image_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebb2d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(url=image_url))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b327ba9",
   "metadata": {},
   "source": [
    "# LLMChains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd3dc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_message_prompt = HumanMessagePromptTemplate.from_template(\n",
    "        \"Tell me 3 things about {place}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080cfc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt_template = ChatPromptTemplate.from_messages([human_message_prompt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a648e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce967b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(llm=chat, prompt=chat_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0249d16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.run(place=\"Piscataway, NJ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53469ce",
   "metadata": {},
   "source": [
    "## Simple Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d17a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"Give me a simple bullet point outline for a blog post on {topic}\"\n",
    "first_prompt = ChatPromptTemplate.from_template(template)\n",
    "chain_one = LLMChain(llm=llm,prompt=first_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6726c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"Write a blog post using this outline: {outline}\"\n",
    "second_prompt = ChatPromptTemplate.from_template(template)\n",
    "chain_two = LLMChain(llm=llm,prompt=second_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff722e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_chain = SimpleSequentialChain(chains=[chain_one,chain_two],\n",
    "                                  verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e05e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = full_chain.run(\"Data Science\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ac1fc7",
   "metadata": {},
   "source": [
    "## Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ee6ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "template1 = \"Give a summary of this employee's performance review:\\n{review}\"\n",
    "prompt1 = ChatPromptTemplate.from_template(template1)\n",
    "chain_1 = LLMChain(llm=llm,\n",
    "                     prompt=prompt1,\n",
    "                     output_key=\"review_summary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3118a73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "template2 = \"Identify key employee weaknesses in this review summary:\\n{review_summary}\"\n",
    "prompt2 = ChatPromptTemplate.from_template(template2)\n",
    "chain_2 = LLMChain(llm=llm,\n",
    "                     prompt=prompt2,\n",
    "                     output_key=\"weaknesses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd011b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "template3 = \"Create a personalized plan to help address and fix these weaknesses:\\n{weaknesses}\"\n",
    "prompt3 = ChatPromptTemplate.from_template(template3)\n",
    "chain_3 = LLMChain(llm=llm,\n",
    "                     prompt=prompt3,\n",
    "                     output_key=\"final_plan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b50d50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_chain = SequentialChain(chains=[chain_1,chain_2,chain_3],\n",
    "                            input_variables=['review'],\n",
    "                            output_variables=['review_summary','weaknesses','final_plan'],\n",
    "                            verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9c4085",
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_review = '''\n",
    "Employee Information:\n",
    "Name: Joe Schmo\n",
    "Position: Software Engineer\n",
    "Date of Review: July 14, 2023\n",
    "\n",
    "Strengths:\n",
    "Joe is a highly skilled software engineer with a deep understanding of programming languages, algorithms, and software development best practices. His technical expertise shines through in his ability to efficiently solve complex problems and deliver high-quality code.\n",
    "\n",
    "One of Joe's greatest strengths is his collaborative nature. He actively engages with cross-functional teams, contributing valuable insights and seeking input from others. His open-mindedness and willingness to learn from colleagues make him a true team player.\n",
    "\n",
    "Joe consistently demonstrates initiative and self-motivation. He takes the lead in seeking out new projects and challenges, and his proactive attitude has led to significant improvements in existing processes and systems. His dedication to self-improvement and growth is commendable.\n",
    "\n",
    "Another notable strength is Joe's adaptability. He has shown great flexibility in handling changing project requirements and learning new technologies. This adaptability allows him to seamlessly transition between different projects and tasks, making him a valuable asset to the team.\n",
    "\n",
    "Joe's problem-solving skills are exceptional. He approaches issues with a logical mindset and consistently finds effective solutions, often thinking outside the box. His ability to break down complex problems into manageable parts is key to his success in resolving issues efficiently.\n",
    "\n",
    "Weaknesses:\n",
    "While Joe possesses numerous strengths, there are a few areas where he could benefit from improvement. One such area is time management. Occasionally, Joe struggles with effectively managing his time, resulting in missed deadlines or the need for additional support to complete tasks on time. Developing better prioritization and time management techniques would greatly enhance his efficiency.\n",
    "\n",
    "Another area for improvement is Joe's written communication skills. While he communicates well verbally, there have been instances where his written documentation lacked clarity, leading to confusion among team members. Focusing on enhancing his written communication abilities will help him effectively convey ideas and instructions.\n",
    "\n",
    "Additionally, Joe tends to take on too many responsibilities and hesitates to delegate tasks to others. This can result in an excessive workload and potential burnout. Encouraging him to delegate tasks appropriately will not only alleviate his own workload but also foster a more balanced and productive team environment.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bae576e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = seq_chain(employee_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19b3d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec87b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results['final_plan'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9f4463",
   "metadata": {},
   "source": [
    "## LLMRouterChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d93631",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.router.llm_router import LLMRouterChain,RouterOutputParser\n",
    "from langchain.chains.router import MultiPromptChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072a8a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "beginner_template = '''You are a physics teacher who is really\n",
    "focused on beginners and explaining complex topics in simple to understand terms. \n",
    "You assume no prior knowledge. Here is the question\\n{input}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5927f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_template = '''You are a world expert physics professor who explains physics topics\n",
    "to advanced audience members. You can assume anyone you answer has a \n",
    "PhD level understanding of Physics. Here is the question\\n{input}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89263fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_infos = [\n",
    "      {'name':'advanced physics','description': 'Answers advanced physics questions',\n",
    "     'prompt_template':expert_template},\n",
    "    {'name':'beginner physics','description': 'Answers basic beginner physics questions',\n",
    "     'prompt_template':beginner_template},\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5149ef31",
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_chains = {}\n",
    "for p_info in prompt_infos:\n",
    "    name = p_info[\"name\"]\n",
    "    prompt_template = p_info[\"prompt_template\"]\n",
    "    prompt = ChatPromptTemplate.from_template(template=prompt_template)\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    destination_chains[name] = chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b817db5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.router.multi_prompt_prompt import MULTI_PROMPT_ROUTER_TEMPLATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec8ac6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(MULTI_PROMPT_ROUTER_TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfde4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
    "destinations_str = \"\\n\".join(destinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eff60bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(destinations_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32de4aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(\n",
    "    destinations=destinations_str\n",
    ")\n",
    "router_prompt = PromptTemplate(\n",
    "    template=router_template,\n",
    "    input_variables=[\"input\"],\n",
    "    output_parser=RouterOutputParser(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2555add",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(router_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c09d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_chain = LLMRouterChain.from_llm(llm, router_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56137b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_prompt = ChatPromptTemplate.from_template(\"{input}\")\n",
    "default_chain = LLMChain(llm=llm,prompt=default_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b85126",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = MultiPromptChain(router_chain=router_chain, \n",
    "                         destination_chains=destination_chains, \n",
    "                         default_chain=default_chain, verbose=True\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9134e6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.run(\"How do magnets work?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3664269f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.run(\"How do Feynman Diagrams work?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1438a2f8",
   "metadata": {},
   "source": [
    "## TransformChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e76069",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import TransformChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bb0c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_review = open('yelp_review.txt').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdba956a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(yelp_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e61eca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_review.split('REVIEW:')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8b7598",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_fun(inputs: dict) -> dict:\n",
    "    '''\n",
    "    Notice how this always takes an inputs dictionary.\n",
    "    Also outputs a dictionary. You can call the output and input keys whatever you want, \n",
    "    just make sure to reference it correct in the chain call.\n",
    "    '''   \n",
    "    text = inputs['text']\n",
    "    only_review_text = text.split('REVIEW:')[-1]\n",
    "    lower_case_text = only_review_text.lower()\n",
    "    return {'output':lower_case_text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e09761",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_chain = TransformChain(input_variables=['text'],\n",
    "                                 output_variables=['output'],\n",
    "                                 transform=transformer_fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751f2eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"Create a one sentence summary of this review:\\n{review_text}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0397ac2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI()\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "summary_chain = LLMChain(llm=llm,\n",
    "                     prompt=prompt,\n",
    "                     output_key=\"review_summary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cd8abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequential_chain = SimpleSequentialChain(chains=[transform_chain,summary_chain],\n",
    "                                        verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990d8812",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = sequential_chain(yelp_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd48059d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0d1054",
   "metadata": {},
   "outputs": [],
   "source": [
    "result['input']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3c1b3b",
   "metadata": {},
   "source": [
    "## LLMMathChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1514724a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import LLMMathChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746bbafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_math_model = LLMMathChain.from_llm(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b085b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_math_model(\"What is 17 raised to the power of 11?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a79508",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5682c8d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e5bfce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5101af4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "85475fa4",
   "metadata": {},
   "source": [
    "#  OpenAI Functions API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e14e369",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.openai_functions import create_openai_fn_chain,create_structured_output_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5451293",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scientist():\n",
    "    \n",
    "    def __init__(self,first_name,last_name):\n",
    "        self.first_name = first_name\n",
    "        self.last_name = last_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76818904",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_schema = {\"title\": \"Scientist\",\n",
    "               \"description\": \"Information about a famous scientist\",\n",
    "               \"type\": \"object\",\n",
    "               \"properties\":{\n",
    "                   \"first_name\":{'title':'First Name',\n",
    "                                 'description': \"First name of scientist\",\n",
    "                                 \"type\": \"string\"},\n",
    "                   \"last_name\":{'title':'Last Name',\n",
    "                                 'description': \"Last name of scientist\",\n",
    "                                 \"type\": \"string\"},\n",
    "               },\n",
    "                \"required\": ['first_name','last_name']\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c244b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = 'Name a famous {country} scientist'\n",
    "# human_prompt = HumanMessagePromptTemplate.from_template(template)\n",
    "chat_prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c5bcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = create_structured_output_chain(json_schema,llm,chat_prompt,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df27645",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chain.run(country='Indian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8a7090",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d71f3fc",
   "metadata": {},
   "source": [
    "# Memory / History"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695426de",
   "metadata": {},
   "source": [
    "## ChatMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45d8aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = ChatMessageHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a4f211",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.add_user_message(\"Hello, nice to meet you.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb044380",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.add_ai_message(\"Nice to meet you too!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3523d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64109c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294731bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67f64539",
   "metadata": {},
   "source": [
    "## ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cc696e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.0)\n",
    "memory = ConversationBufferMemory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49190162",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a047c52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation.predict(input=\"Hello, nice to meet you!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7b104d",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation.predict(input=\"Tell me about the Einstein-Szilard Letter \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d57a081",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2533874",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd974f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"Very Interesting.\"}, \n",
    "                    {\"output\": \"Yes, it was my pleasure as an AI to answer.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157850a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc2482b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to pickle\n",
    "with open('memory.pkl','wb') as f:\n",
    "    f.write(pickle.dumps(conversation.memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4147595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read back from pickle file\n",
    "llm = ChatOpenAI(temperature=0.0)\n",
    "reload_conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = pickle.loads(open('memory.pkl','rb').read()),\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1579e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload_conversation.memory.buffer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb5b3ad",
   "metadata": {},
   "source": [
    "# Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a99811",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c42270",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = load_tools([\"llm-math\"], llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9e4f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(AgentType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a57426",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent(tools, \n",
    "                         llm, \n",
    "                         agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, \n",
    "                         verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfab6936",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.run(\"What is 2 times 3?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f729771",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.run(\"What is 2 times 3? What is that number multiplied by 5?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c6bf2e",
   "metadata": {},
   "source": [
    "## Python Agent Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8309fa9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Tool\n",
    "from langchain_experimental.utilities import PythonREPL\n",
    "from langchain_experimental.tools.python.tool import PythonREPLTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619562bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.agents.agent_toolkits import create_python_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0040728d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4b4f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_python_agent(tool=PythonREPLTool(),\n",
    "                         llm=llm, \n",
    "                         agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, \n",
    "                         verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354fd84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "python_list = [7,3,1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585ba536",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.run(f'''Sort this Python list in descending order {python_list}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545a28a7",
   "metadata": {},
   "source": [
    "## Custom Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76d79cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d3799e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def first_verse(text: str) -> str:\n",
    "    '''Returns the first verse in the book named jmj_qwerty'''\n",
    "    return \"In the beginning was the Word, and the Word was with God, and the Word was God and He was in the beginning with God\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050752e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = load_tools([\"llm-math\"], llm=llm) \n",
    "tools = tools +[first_verse]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab7ce2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent(tools, \n",
    "                         llm, \n",
    "                         agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, \n",
    "                         verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3ee73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.run(\"what is the first verse in the book named jmj_qwerty?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6266e2c",
   "metadata": {},
   "source": [
    "## Conversation Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aaa0705",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e057f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_chain = initialize_agent(tools, \n",
    "                               llm,\n",
    "                               agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION, \n",
    "                               verbose=True, \n",
    "                               memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592377f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_chain.run(input=\"What are some good thai food recipes?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adccea7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_chain.run(\"Which one of those dishes is the spiciest?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd276c0",
   "metadata": {},
   "source": [
    "# Metadata query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff50620",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\n",
    "    Document(\n",
    "        page_content=\"A bunch of scientists bring back dinosaurs and mayhem breaks loose\",\n",
    "        metadata={\"year\": 1993, \"rating\": 7.7, \"genre\": \"science fiction\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Leo DiCaprio gets lost in a dream within a dream within a dream within a ...\",\n",
    "        metadata={\"year\": 2010, \"director\": \"Christopher Nolan\", \"rating\": 8.2},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"A psychologist / detective gets lost in a series of dreams within dreams within dreams and Inception reused the idea\",\n",
    "        metadata={\"year\": 2006, \"director\": \"Satoshi Kon\", \"rating\": 8.6},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"A bunch of normal-sized women are supremely wholesome and some men pine after them\",\n",
    "        metadata={\"year\": 2019, \"director\": \"Greta Gerwig\", \"rating\": 8.3},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Toys come alive and have a blast doing so\",\n",
    "        metadata={\"year\": 1995, \"genre\": \"animated\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Three men walk into the Zone, three men walk out of the Zone\",\n",
    "        metadata={\n",
    "            \"year\": 1979,\n",
    "            \"director\": \"Andrei Tarkovsky\",\n",
    "            \"genre\": \"thriller\",\n",
    "            \"rating\": 9.9,\n",
    "        },\n",
    "    ),\n",
    "]\n",
    "vectorstore = Chroma.from_documents(docs, OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a652195e",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"genre\",\n",
    "        description=\"The genre of the movie. One of ['science fiction', 'comedy', 'drama', 'thriller', 'romance', 'action', 'animated']\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"year\",\n",
    "        description=\"The year the movie was released\",\n",
    "        type=\"integer\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"director\",\n",
    "        description=\"The name of the movie director\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"rating\", description=\"A 1-10 rating for the movie\", type=\"float\"\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf6a661",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_content_description = \"Brief summary of a movie\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d637860b",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm,\n",
    "    vectorstore,\n",
    "    document_content_description,\n",
    "    metadata_field_info,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a83d29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.invoke(\"I want to watch a movie rated higher than 8.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665f2c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.invoke(\"How many movies has rating higher than 9?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b779ada",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9dd11889",
   "metadata": {},
   "source": [
    "# Vector Databases- Milvus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac745488",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39396821",
   "metadata": {},
   "source": [
    "# Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2015b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9770fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cce1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2\", pad_token_id=tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653342f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode context the generation is conditioned on\n",
    "model_inputs = tokenizer('Gospel of John begins with', return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc1f486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate 40 new tokens\n",
    "greedy_output = model.generate(**model_inputs, max_new_tokens=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed05b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "greedy_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ee2e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Output:\\n\" + 100 * '-')\n",
    "print(tokenizer.decode(greedy_output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee40c86",
   "metadata": {},
   "source": [
    "## Hugging Gcae- Accessing Pre-trained Models Using Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c37205",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=\"gpt2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0bea85",
   "metadata": {},
   "source": [
    "pipe('Gospel of John begins with', max_length=30, num_return_sequences=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fdc161",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe('Gospel of Mark begins with', max_length=30, num_return_sequences=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac6095f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Config, GPT2Model\n",
    "\n",
    "# Building the config\n",
    "config = GPT2Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4185c32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76019b2",
   "metadata": {},
   "source": [
    "## Hugging Face with Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffb0035",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f99383",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import HuggingFaceEndpoint\n",
    "from langchain.llms import HuggingFaceHub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5898ca64",
   "metadata": {},
   "source": [
    "## Hugging Face with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe43824",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c430d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27ef278",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = HuggingFaceEndpoint(repo_id=\"mistralai/Mistral-7B-Instruct-v0.2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9cfe50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The LLM takes a prompt as an input and outputs a completion\n",
    "our_query = 'Gospel of John begins with'\n",
    "\n",
    "#Last week langchain has recommended to use invoke function for the below please :)\n",
    "completion = llm.invoke(our_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1ab98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8169caeb",
   "metadata": {},
   "source": [
    "## Tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd77b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sshleifer/distilbart-cnn-12-6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18973f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_inputs =     [\n",
    "        \"I love deep learning!\",\n",
    "        \"I hate this so much!\",\n",
    "    ]\n",
    "inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab45422",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Tokenizer output for \"I love deep learning!\"')\n",
    "print(f\"Input ids: {inputs['input_ids'][0]}\")\n",
    "print(f\"Attention Mask: {inputs['attention_mask'][0]}\")\n",
    "print(\"-\"*100)\n",
    "print('Tokenizer output for \"I hate this so much!\"')\n",
    "print(f\"Input ids: {inputs['input_ids'][1]}\")\n",
    "print(f\"Attention Mask: {inputs['attention_mask'][1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a851ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer('In the beginning was the Word, and the Word was with God,and the Word was God.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7fcb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.tokenize('In the beginning was the Word, and the Word was with God,and the Word was God.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b90c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8180deb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e883f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_tokens = tokenizer.decode(token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68045b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d282006",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_prepped_ids = tokenizer.prepare_for_model(token_ids)\n",
    "model_prepped_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd87ca5",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2968aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "classifier(\n",
    "    [\n",
    "        \"I love deep learning!\",\n",
    "        \"I hate this so much!\",\n",
    "        'In the beginning was the Word, and the Word was with God,and the Word was God.',\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c32b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_generator = pipeline(\"text-generation\")\n",
    "\n",
    "text_generator([\n",
    "    'In the beginning was the Word, and the Word was with God',\n",
    "    'When two objects in space get close to each other'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8ad666",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer = pipeline(\"summarization\")\n",
    "\n",
    "summarizer([\n",
    "    \"\"\"A Fibonacci heap is a collection of trees satisfying the min-heap property. It allows faster amortized time for many operations than binary or binomial heaps.\n",
    "    Trees in a Fibonacci heap can have any shape, which facilitates efficient operations. Lazy strategies are employed: node removals and consolidations are delayed until\n",
    "    absolutely necessary (like during an extract-min operation). The main advantage lies in decreasing a key and merging two heaps, which are constant and amortized\n",
    "    constant time, respectively. Nodes have a \"mark\" indicating if they've lost a child since the last time they were made a child of another node, assisting in\n",
    "    restructuring during operations.\"\"\"\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e7861f",
   "metadata": {},
   "source": [
    "## Model Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941b1a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "model = AutoModel.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43791c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer('In the beginning was the Word, and the Word was with God,and the Word was God.', padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "outputs = model(**inputs)\n",
    "\n",
    "print(outputs.last_hidden_state.shape) # the token embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd02c435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get the full context vector for the sequence\n",
    "context_vectors = outputs.last_hidden_state.mean(dim=1)\n",
    "context_vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01a125e",
   "metadata": {},
   "source": [
    "## Hugging Face Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2deca252",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"fka/awesome-chatgpt-prompts\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9acdb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"samsum\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1b1909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload GPT Prompt dataset (Cache keeps from loading it twice)\n",
    "dataset = load_dataset(\"fka/awesome-chatgpt-prompts\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a0ee14",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f85adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle & sample\n",
    "\n",
    "dataset = dataset['train'].shuffle(seed=37).select(range(100))\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3007d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Test Dataset\n",
    "\n",
    "dataset = dataset.train_test_split(train_size=0.8, seed=42)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fb87c6",
   "metadata": {},
   "source": [
    "## Creating and uploading custom dataset into Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4eefa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the sgm files are what contains the articles\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Open the file and parse its content with BeautifulSoup\n",
    "reuters_articles = []\n",
    "for i in range(22):\n",
    "  if i < 10:\n",
    "    i = f\"0{i}\"\n",
    "\n",
    "  # load file data\n",
    "  with open(f\"reuters21578/reut2-0{i}.sgm\", 'r', encoding='latin-1') as file:\n",
    "      soup = BeautifulSoup(file, \"html.parser\")\n",
    "\n",
    "  # Extract articles' titles and bodies\n",
    "  articles = []\n",
    "  for reuters in soup.find_all('reuters'):\n",
    "      title = reuters.title.string if reuters.title else \"\"\n",
    "      body = reuters.body.string if reuters.body else \"\"\n",
    "      articles.append({\n",
    "            'title': title,\n",
    "            'body': body\n",
    "        })\n",
    "\n",
    "  reuters_articles.extend(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d99688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the first few articles for inspection\n",
    "for i, article in enumerate(reuters_articles[:5]):\n",
    "  print(article)\n",
    "  print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2db63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(reuters_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f20185",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "TRAIN_PCT, VALID_PCT = 0.8, 0.1\n",
    "\n",
    "# Split the data\n",
    "train_articles = reuters_articles[:int(len(reuters_articles)*TRAIN_PCT)]\n",
    "valid_articles = reuters_articles[int(len(reuters_articles)*TRAIN_PCT): int(len(reuters_articles)*(TRAIN_PCT + VALID_PCT))]\n",
    "test_articles = reuters_articles[int(len(reuters_articles)*(TRAIN_PCT + VALID_PCT)):]\n",
    "\n",
    "# Function to save articles as JSONL\n",
    "def save_as_jsonl(data, filename):\n",
    "    with open(filename, \"w\") as f:\n",
    "        for article in data:\n",
    "            f.write(json.dumps(article) + \"\\n\")\n",
    "\n",
    "# Save them into temporary JSONL files\n",
    "save_as_jsonl(train_articles, \"train.jsonl\")\n",
    "save_as_jsonl(valid_articles, \"valid.jsonl\")\n",
    "save_as_jsonl(test_articles, \"test.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1dde8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load them as datasets\n",
    "data_files = {\"train\": \"train.jsonl\", \"validation\": \"valid.jsonl\", \"test\": \"test.jsonl\"}\n",
    "dataset = load_dataset(\"json\", data_files=data_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ac7c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c5ef09",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e13184",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25e98b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b0b224",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cf9092",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.push_to_hub(\"test_dataset1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a2a8a4",
   "metadata": {},
   "source": [
    "## Downloading custom dataset from Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f5a9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"jimmypjoy/test_dataset1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c18b5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d633ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column to this dataset\n",
    "def create_full_article_col(example):\n",
    "\n",
    "  return {'full_article': f\"TITLE:{example['title']}\\n\\nBODY:{example['body']}\"}\n",
    "\n",
    "dataset = dataset.map(create_full_article_col)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf21c65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['train'][0]['full_article']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61a658c",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60a7359",
   "metadata": {},
   "source": [
    "## Creating custom Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df856040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a batched dataset for training, creates an iterator object for later usage when training tokenizer\n",
    "\n",
    "training_corpus = (\n",
    "    dataset[\"train\"][i : i + 1000][\"full_article\"]\n",
    "    for i in range(0, len(dataset[\"train\"]), 1000)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aab91e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_tokenizer = AutoTokenizer.from_pretrained(\"gpt2\") # train gpt2 tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd7ab90",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = old_tokenizer.train_new_from_iterator(training_corpus, 52000) # vocab size of 52000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48968af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = dataset['test'][2]['full_article']\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6047dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_tokenizer.tokenize(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f08161",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.tokenize(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6bd0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1195401",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.push_to_hub(\"gpt2-reuters-tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66125962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use newly created tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"jimmypjoy/gpt2-reuters-tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880382b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = dataset['test'][2]\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af590292",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.tokenize(example['full_article'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a37be4c",
   "metadata": {},
   "source": [
    "## Training gpt2 from scratch in Hugging Face "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648a4fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"jimmypjoy/test_dataset1\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac7a1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_full_article_col(example):\n",
    "\n",
    "  return {'full_article': f\"TITLE:{example['title']}\\n\\nBODY:{example['body']}\"}\n",
    "\n",
    "dataset = dataset.map(create_full_article_col)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff69a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['train'][0]['full_article']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a02261d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"jimmypjoy/gpt2-reuters-tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64bee0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTEXT_LENGTH = 512\n",
    "\n",
    "def tokenize(element):\n",
    "    outputs = tokenizer(\n",
    "        element[\"full_article\"],\n",
    "        truncation=True,\n",
    "        max_length=CONTEXT_LENGTH,\n",
    "        return_overflowing_tokens=False\n",
    "    )\n",
    "\n",
    "    return outputs\n",
    "\n",
    "\n",
    "tokenized_datasets = dataset.map(\n",
    "    tokenize, batched=True, remove_columns=dataset[\"train\"].column_names\n",
    ")\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b754ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, GPT2LMHeadModel, AutoConfig\n",
    "\n",
    "config = AutoConfig.from_pretrained(\n",
    "    \"gpt2\",\n",
    "    vocab_size=len(tokenizer),\n",
    "    n_ctx=CONTEXT_LENGTH,\n",
    "    bos_token_id=tokenizer.bos_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4c875e",
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c642b77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPT2LMHeadModel(config)\n",
    "model_size = sum(t.numel() for t in model.parameters())\n",
    "print(f\"GPT-2 size: {model_size/1000**2:.1f}M parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e3a17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accdca75",
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70c0b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./reuters-gpt2-text-gen\",  # local directory\n",
    "    hub_model_id=\"ingeniumacademy/reuters-gpt2-text-gen\",  # identifier on the Hub\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    auto_find_batch_size=True,\n",
    "    num_train_epochs=2,\n",
    "    gradient_accumulation_steps=8,\n",
    "    weight_decay=0.1,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    learning_rate=5e-4,\n",
    "    fp16=True,\n",
    "    push_to_hub=True,\n",
    "    logging_steps=10\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884462a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f98a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9886cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Our Model In Pipeline\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "#pipe = pipeline(\n",
    "#    \"text-generation\", model=\"jimmypjoy/reuters-gpt2-text-gen\"\n",
    "#)\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\", model=\"ingeniumacademy/reuters-gpt2-text-gen\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d087dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = dataset['test'][2]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f3944d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"TITLE:{sample['title']}\\n\\nBODY:\"\n",
    "pipe(prompt, max_new_tokens=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6b0801",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"TITLE:{sample['title']}\"\n",
    "pipe(prompt, max_new_tokens=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258e98c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
