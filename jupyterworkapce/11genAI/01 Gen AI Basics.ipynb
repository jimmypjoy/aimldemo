{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f164aa49",
   "metadata": {},
   "source": [
    "# LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "214d1f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain \n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter \n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "import os\n",
    "from IPython.display import Image, display\n",
    "import streamlit as st\n",
    "from langchain.vectorstores import Chroma \n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.document_loaders import TextLoader \n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain_community.utilities.dalle_image_generator import DallEAPIWrapper\n",
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
    "from langchain.cache import InMemoryCache\n",
    "import langchain\n",
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate,SystemMessagePromptTemplate,AIMessagePromptTemplate\n",
    "from langchain.output_parsers import CommaSeparatedListOutputParser,DatetimeOutputParser\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.chains import SimpleSequentialChain,SequentialChain\n",
    "from langchain.memory import ChatMessageHistory\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "import pickle\n",
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from langchain_core.documents import Document\n",
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5e8fe4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_environment():\n",
    "    import sys\n",
    "    sys.path.append('C:\\\\gitworkspace\\\\aimldemo\\\\jupyterworkapce')\n",
    "    import stratup_env_setup\n",
    "    stratup_env_setup.set_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "70f696a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c1539dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2db1f0a",
   "metadata": {},
   "source": [
    "# Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6d288563",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jimmy\\AppData\\Local\\Temp\\ipykernel_18800\\2437324265.py:2: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  llm('One sentence about Paris')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nParis is the capital of France and known for its iconic landmarks, rich history, and romantic atmosphere.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#llm('One sentence about Piscataway, NJ')\n",
    "llm('One sentence about Paris')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "06cac582",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = llm.generate(['Once sentence about Piscataway, NJ','One sentence about Edison, NJ'],max_tokens=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2ce89c38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMResult(generations=[[Generation(text='\\n\\nPiscataway, NJ is a diverse and vibrant community located in central New Jersey.', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='\\n\\nEdison, NJ is a diverse and bustling township known for its strong economy, top-rated schools, and vibrant community.', generation_info={'finish_reason': 'stop', 'logprobs': None})]], llm_output={'token_usage': {'total_tokens': 59, 'completion_tokens': 44, 'prompt_tokens': 15}, 'model_name': 'gpt-3.5-turbo-instruct'}, run=[RunInfo(run_id=UUID('0016e142-9219-4c46-9090-087947dccebd')), RunInfo(run_id=UUID('084340da-fac2-4922-9666-206370f21d16'))], type='LLMResult')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f49600ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.outputs.llm_result.LLMResult"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "81c6e869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'$defs': {'BaseMessage': {'additionalProperties': True,\n",
       "   'description': 'Base abstract message class.\\n\\nMessages are the inputs and outputs of ChatModels.',\n",
       "   'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "      {'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]},\n",
       "       'type': 'array'}],\n",
       "     'title': 'Content'},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'title': 'Type', 'type': 'string'},\n",
       "    'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Name'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Id'}},\n",
       "   'required': ['content', 'type'],\n",
       "   'title': 'BaseMessage',\n",
       "   'type': 'object'},\n",
       "  'BaseMessageChunk': {'additionalProperties': True,\n",
       "   'description': 'Message chunk, which can be concatenated with other Message chunks.',\n",
       "   'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "      {'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]},\n",
       "       'type': 'array'}],\n",
       "     'title': 'Content'},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'title': 'Type', 'type': 'string'},\n",
       "    'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Name'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Id'}},\n",
       "   'required': ['content', 'type'],\n",
       "   'title': 'BaseMessageChunk',\n",
       "   'type': 'object'},\n",
       "  'ChatGeneration': {'description': 'A single chat generation output.\\n\\nA subclass of Generation that represents the response from a chat model\\nthat generates chat messages.\\n\\nThe `message` attribute is a structured representation of the chat message.\\nMost of the time, the message will be of type `AIMessage`.\\n\\nUsers working with chat models will usually access information via either\\n`AIMessage` (returned from runnable interfaces) or `LLMResult` (available\\nvia callbacks).',\n",
       "   'properties': {'text': {'default': '', 'title': 'Text', 'type': 'string'},\n",
       "    'generation_info': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Generation Info'},\n",
       "    'type': {'const': 'ChatGeneration',\n",
       "     'default': 'ChatGeneration',\n",
       "     'enum': ['ChatGeneration'],\n",
       "     'title': 'Type',\n",
       "     'type': 'string'},\n",
       "    'message': {'$ref': '#/$defs/BaseMessage'}},\n",
       "   'required': ['message'],\n",
       "   'title': 'ChatGeneration',\n",
       "   'type': 'object'},\n",
       "  'ChatGenerationChunk': {'description': 'ChatGeneration chunk, which can be concatenated with other\\nChatGeneration chunks.',\n",
       "   'properties': {'text': {'default': '', 'title': 'Text', 'type': 'string'},\n",
       "    'generation_info': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Generation Info'},\n",
       "    'type': {'const': 'ChatGenerationChunk',\n",
       "     'default': 'ChatGenerationChunk',\n",
       "     'enum': ['ChatGenerationChunk'],\n",
       "     'title': 'Type',\n",
       "     'type': 'string'},\n",
       "    'message': {'$ref': '#/$defs/BaseMessageChunk'}},\n",
       "   'required': ['message'],\n",
       "   'title': 'ChatGenerationChunk',\n",
       "   'type': 'object'},\n",
       "  'Generation': {'description': 'A single text generation output.\\n\\nGeneration represents the response from an \"old-fashioned\" LLM that\\ngenerates regular text (not chat messages).\\n\\nThis model is used internally by chat model and will eventually\\nbe mapped to a more general `LLMResult` object, and then projected into\\nan `AIMessage` object.\\n\\nLangChain users working with chat models will usually access information via\\n`AIMessage` (returned from runnable interfaces) or `LLMResult` (available\\nvia callbacks). Please refer the `AIMessage` and `LLMResult` schema documentation\\nfor more information.',\n",
       "   'properties': {'text': {'title': 'Text', 'type': 'string'},\n",
       "    'generation_info': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Generation Info'},\n",
       "    'type': {'const': 'Generation',\n",
       "     'default': 'Generation',\n",
       "     'enum': ['Generation'],\n",
       "     'title': 'Type',\n",
       "     'type': 'string'}},\n",
       "   'required': ['text'],\n",
       "   'title': 'Generation',\n",
       "   'type': 'object'},\n",
       "  'GenerationChunk': {'description': 'Generation chunk, which can be concatenated with other Generation chunks.',\n",
       "   'properties': {'text': {'title': 'Text', 'type': 'string'},\n",
       "    'generation_info': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Generation Info'},\n",
       "    'type': {'const': 'Generation',\n",
       "     'default': 'Generation',\n",
       "     'enum': ['Generation'],\n",
       "     'title': 'Type',\n",
       "     'type': 'string'}},\n",
       "   'required': ['text'],\n",
       "   'title': 'GenerationChunk',\n",
       "   'type': 'object'},\n",
       "  'RunInfo': {'description': 'Class that contains metadata for a single execution of a Chain or model.\\n\\nDefined for backwards compatibility with older versions of langchain_core.\\n\\nThis model will likely be deprecated in the future.\\n\\nUsers can acquire the run_id information from callbacks or via run_id\\ninformation present in the astream_event API (depending on the use case).',\n",
       "   'properties': {'run_id': {'format': 'uuid',\n",
       "     'title': 'Run Id',\n",
       "     'type': 'string'}},\n",
       "   'required': ['run_id'],\n",
       "   'title': 'RunInfo',\n",
       "   'type': 'object'}},\n",
       " 'description': 'A container for results of an LLM call.\\n\\nBoth chat models and LLMs generate an LLMResult object. This object contains\\nthe generated outputs and any additional information that the model provider\\nwants to return.',\n",
       " 'properties': {'generations': {'items': {'items': {'anyOf': [{'$ref': '#/$defs/Generation'},\n",
       "      {'$ref': '#/$defs/ChatGeneration'},\n",
       "      {'$ref': '#/$defs/GenerationChunk'},\n",
       "      {'$ref': '#/$defs/ChatGenerationChunk'}]},\n",
       "    'type': 'array'},\n",
       "   'title': 'Generations',\n",
       "   'type': 'array'},\n",
       "  'llm_output': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "   'default': None,\n",
       "   'title': 'Llm Output'},\n",
       "  'run': {'anyOf': [{'items': {'$ref': '#/$defs/RunInfo'}, 'type': 'array'},\n",
       "    {'type': 'null'}],\n",
       "   'default': None,\n",
       "   'title': 'Run'},\n",
       "  'type': {'const': 'LLMResult',\n",
       "   'default': 'LLMResult',\n",
       "   'enum': ['LLMResult'],\n",
       "   'title': 'Type',\n",
       "   'type': 'string'}},\n",
       " 'required': ['generations'],\n",
       " 'title': 'LLMResult',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a233355b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nPiscataway, NJ is a diverse and vibrant community located in central New Jersey.'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.generations[0][0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b42e3838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nEdison, NJ is a diverse and bustling township known for its strong economy, top-rated schools, and vibrant community.'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.generations[1][0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3fd16dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jimmy\\AppData\\Local\\Temp\\ipykernel_18800\\3310371265.py:1: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  chat = ChatOpenAI()\n"
     ]
    }
   ],
   "source": [
    "chat = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ba15f5a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jimmy\\AppData\\Local\\Temp\\ipykernel_18800\\1919734953.py:1: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = chat([HumanMessage(content='One sentence about Piscataway, NJ')])\n"
     ]
    }
   ],
   "source": [
    "result = chat([HumanMessage(content='One sentence about Piscataway, NJ')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "660a375e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2c2bde9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Piscataway, NJ is a diverse and thriving community located in central New Jersey.'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5a3e1ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chat([SystemMessage(content='You are a comedian'),\n",
    "    HumanMessage(content='five sentencec about Piscataway, NJ')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ef10cd50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Piscataway, NJ, also known as \"The Home of Rutgers University,\" is a vibrant town filled with diverse cultures and communities. It has a rich history dating back to the colonial era and is named after the Piscataway Native American tribe. The town offers a mix of suburban living and urban amenities, with plenty of parks, restaurants, and shopping centers. Residents can enjoy outdoor activities at places like Johnson Park or take a stroll along the Raritan River. With its proximity to major highways and public transportation, Piscataway is a convenient location for both work and play.'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7595e05",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "10322585",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Today is December 5, 2024\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "0f45e5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "ce59fa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_text = embeddings.embed_query(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "b91fe697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(embedded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "ad2f3da0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.013985867914812407,\n",
       " -0.009167040896666867,\n",
       " -0.01763147340138314,\n",
       " -0.009717195505143078,\n",
       " -0.029509518934311547,\n",
       " -0.004172561314872382,\n",
       " -0.023795860403298924,\n",
       " -0.008603628911054026,\n",
       " -0.03409635349409849,\n",
       " 0.011069383711820339,\n",
       " 0.02717633045433078,\n",
       " 0.004364783970127574,\n",
       " -0.0023597009059475415,\n",
       " -0.0049779085588656435,\n",
       " -0.01028060749075592,\n",
       " 0.017578445755481807,\n",
       " 0.020216539939766152,\n",
       " -0.014410083494087494,\n",
       " 0.02681839896677106,\n",
       " -0.026301386404152534,\n",
       " 0.008630141802682097,\n",
       " -0.0011027956154498234,\n",
       " -0.016769783934373738,\n",
       " 0.011977470739178864,\n",
       " 0.021741064735993663,\n",
       " 0.0013712448131962354,\n",
       " -0.0004001880384064996,\n",
       " -0.016663730505216263,\n",
       " 0.04228902327169146,\n",
       " -0.012892185989444409,\n",
       " 0.014980123702607354,\n",
       " -0.018692013280893455,\n",
       " 0.009670797013471358,\n",
       " -0.04112242996302368,\n",
       " -0.011884673755835426,\n",
       " -0.03218738059339281,\n",
       " -0.016690245259489526,\n",
       " -0.011937700470414163,\n",
       " 0.017697757493098508,\n",
       " 0.022098996223553383,\n",
       " -0.013064524441639845,\n",
       " 0.020057458864707348,\n",
       " 0.004020108462720592,\n",
       " 0.0017979463253074278,\n",
       " -0.042739753605239815,\n",
       " 0.008709682340211501,\n",
       " 0.029907221621958566,\n",
       " -0.017498905217952405,\n",
       " -0.022324361390327556,\n",
       " 0.0076093726575977814,\n",
       " 0.025996480699848955,\n",
       " 0.008066730748391851,\n",
       " -0.026274871649879274,\n",
       " -0.026685830783340324,\n",
       " 0.013680963141831424,\n",
       " -0.02380911684911296,\n",
       " -0.025466211691416392,\n",
       " -0.010598768709550937,\n",
       " -0.029854193976057233,\n",
       " 9.055756177562834e-06,\n",
       " 0.006200843159226976,\n",
       " -0.022947429244748747,\n",
       " 0.002377928984603138,\n",
       " 0.027282385746133443,\n",
       " -0.01209678154547297,\n",
       " -0.021780835936080958,\n",
       " -0.05695098389285861,\n",
       " 0.008689797671490447,\n",
       " 0.003950510725213013,\n",
       " 0.015165718600616825,\n",
       " 0.0119509569162282,\n",
       " 0.006180958024844626,\n",
       " 0.005750113757001222,\n",
       " -0.007881135850382378,\n",
       " 0.004056564620031785,\n",
       " -0.010897046190947496,\n",
       " 0.00034653963689191853,\n",
       " 0.02082634948572812,\n",
       " 0.007224926881426098,\n",
       " -0.019924890681276612,\n",
       " 0.02087937713162945,\n",
       " -0.02479011619109387,\n",
       " -0.02025630927720826,\n",
       " 0.029005762817507056,\n",
       " 0.0239019138324564,\n",
       " 0.016955379763705807,\n",
       " -0.0010795963696139637,\n",
       " 0.010684938401309954,\n",
       " -0.005541320078817188,\n",
       " -0.0006827224426609731,\n",
       " 0.016040664513440262,\n",
       " 0.020534700227238578,\n",
       " 0.0037417168141983294,\n",
       " 0.029695112900998424,\n",
       " -0.019315081135314646,\n",
       " 0.009239952279966658,\n",
       " 0.008928419284078656,\n",
       " 0.02469731920775043,\n",
       " -0.006833852882347397,\n",
       " -0.012149808260051707,\n",
       " 0.02485640028280924,\n",
       " 0.007907649673333045,\n",
       " -0.020243052831394225,\n",
       " -0.0017068061648600947,\n",
       " -0.03216086770176474,\n",
       " 0.003678747299597768,\n",
       " 0.008345122629744763,\n",
       " 0.009438803623790166,\n",
       " 0.020150255848050785,\n",
       " 0.003592578306330698,\n",
       " -0.02770660132540853,\n",
       " 0.026062764791564323,\n",
       " 0.02091914646907156,\n",
       " -0.054458716200464226,\n",
       " 0.005163502991213819,\n",
       " -0.025426440491329097,\n",
       " -0.016690245259489526,\n",
       " -0.016146717942597737,\n",
       " 0.013018125018645531,\n",
       " -0.0033125296020816808,\n",
       " 0.034414515644216104,\n",
       " 0.027388439175290918,\n",
       " 0.009021216267422095,\n",
       " -0.010055242323981745,\n",
       " 0.001748233489351551,\n",
       " 0.011692450634918935,\n",
       " -0.004755857969206276,\n",
       " -0.010989843174290937,\n",
       " 0.0041261623575393645,\n",
       " 0.02013699940223675,\n",
       " 0.002369643473138717,\n",
       " -0.003927311479377154,\n",
       " -0.017021663855421174,\n",
       " 0.0037019465454336277,\n",
       " -0.003867655843399452,\n",
       " 0.019938147127090647,\n",
       " -0.04194434822994578,\n",
       " 0.016067177405068335,\n",
       " -0.03165711158496025,\n",
       " -0.014966867256793318,\n",
       " 0.011851531709977742,\n",
       " 0.023782603957484886,\n",
       " -0.007655771149269501,\n",
       " -0.007330981241906167,\n",
       " -0.006552147355202273,\n",
       " 0.005693772930968976,\n",
       " 0.0066913428302174316,\n",
       " 0.005743485534094205,\n",
       " -0.000416551842058004,\n",
       " -0.019527187993629593,\n",
       " 0.032532055635138495,\n",
       " -0.009153783519530237,\n",
       " 0.0006557947050245915,\n",
       " -0.00680071130215101,\n",
       " 0.016491392984343423,\n",
       " 0.022801604615503977,\n",
       " 0.007079102717842624,\n",
       " 0.014184719258635915,\n",
       " 0.004759172080659784,\n",
       " -0.008915161906942026,\n",
       " -0.012202835905953039,\n",
       " -0.014078664898155846,\n",
       " -0.001045625912308227,\n",
       " -0.005680516019493643,\n",
       " 0.027003992933457937,\n",
       " 0.015709245917508614,\n",
       " 0.017432622988882224,\n",
       " 0.009412290732162095,\n",
       " 0.009538229761363218,\n",
       " -0.007377379733577887,\n",
       " -0.031020787284725022,\n",
       " 0.012474598633076338,\n",
       " -0.03197527373507786,\n",
       " 0.004421125261821118,\n",
       " -0.02171455184436559,\n",
       " 0.03049051827629246,\n",
       " 0.007509946985686028,\n",
       " 0.0016330655552049807,\n",
       " -0.056632821742740994,\n",
       " -0.0025651804726780675,\n",
       " -0.02297394213637682,\n",
       " 0.0043316419242698904,\n",
       " -0.005829654294530626,\n",
       " 0.00021045085032611382,\n",
       " -0.014237745973214653,\n",
       " 0.013329658945856127,\n",
       " 0.046690263864791526,\n",
       " 0.007536460808636693,\n",
       " 0.01252762627897767,\n",
       " -0.009929303294780622,\n",
       " 0.03759613342010186,\n",
       " 0.01703492030123521,\n",
       " 0.022098996223553383,\n",
       " -0.01870526972670749,\n",
       " -0.6579588794083788,\n",
       " -0.021847118165151138,\n",
       " 3.746584560914826e-05,\n",
       " -0.02667257433752629,\n",
       " 0.0032827019005081544,\n",
       " 0.03189573133490327,\n",
       " 0.016146717942597737,\n",
       " 0.00942554717797613,\n",
       " -0.01060539786378055,\n",
       " 0.00012583552142586283,\n",
       " 0.006180958024844626,\n",
       " 0.0304640035220192,\n",
       " 0.016451623646901316,\n",
       " 7.664056631630091e-05,\n",
       " -0.01655767707605879,\n",
       " -0.0058627963403883095,\n",
       " 0.01360142260430202,\n",
       " -0.0016065519650849632,\n",
       " -0.01430403006493002,\n",
       " 0.027467979712820324,\n",
       " -0.010519229103344128,\n",
       " 0.013422455929199566,\n",
       " -0.027759627108664673,\n",
       " -0.011056127266006304,\n",
       " 0.020627499073227206,\n",
       " -0.02469731920775043,\n",
       " 0.007251440704376764,\n",
       " -0.04183829293814312,\n",
       " -0.03406984060247042,\n",
       " -0.013144064979169248,\n",
       " -0.020057458864707348,\n",
       " 0.029986762159487968,\n",
       " 0.007423778225249606,\n",
       " -0.011838275264163707,\n",
       " 0.03584624531974536,\n",
       " -0.0027988306852553655,\n",
       " -0.018519675760020612,\n",
       " 0.00844454783599522,\n",
       " 0.00780822400142129,\n",
       " 0.032505542743510425,\n",
       " -0.023795860403298924,\n",
       " -0.006714542541714589,\n",
       " -0.007702170106602518,\n",
       " 0.010134782861511147,\n",
       " -0.015072921617273386,\n",
       " 0.008828993146505605,\n",
       " 0.007708798329509536,\n",
       " -0.007324352553337852,\n",
       " 0.018029176089030156,\n",
       " -0.020362362706365735,\n",
       " 0.008954932175706727,\n",
       " 0.0004950566324466925,\n",
       " -0.011844903487070724,\n",
       " 0.0098431345343442,\n",
       " -0.025161305987112817,\n",
       " 0.0049944795817944854,\n",
       " 0.025943453053947622,\n",
       " 0.011042869888869673,\n",
       " 0.0076491429263624835,\n",
       " -0.014555908123332266,\n",
       " -0.02643395272493808,\n",
       " -0.012792760783193951,\n",
       " -0.019102972414354505,\n",
       " 0.021515699569219487,\n",
       " -0.019487418656187486,\n",
       " 0.013614679050116056,\n",
       " -0.0029131700915385585,\n",
       " 0.03396378531066775,\n",
       " 0.006833852882347397,\n",
       " 0.008941675729892693,\n",
       " 0.004159304403397048,\n",
       " 0.018108716626559558,\n",
       " -0.00830535236098006,\n",
       " 0.007834737358710658,\n",
       " 0.024975712020425936,\n",
       " 0.006658201250021045,\n",
       " 0.008729567940255149,\n",
       " -0.020269565723022295,\n",
       " -0.0034301833526490313,\n",
       " 0.007324352553337852,\n",
       " 0.007357494599195536,\n",
       " -0.027083533470987343,\n",
       " -0.021038458206688256,\n",
       " 0.010433059411585113,\n",
       " 0.01581529934666609,\n",
       " 0.0008401463455777008,\n",
       " -0.02536015639961373,\n",
       " 0.006847109793822729,\n",
       " 0.002225476365281998,\n",
       " 0.011135667803535707,\n",
       " 0.019288566381041383,\n",
       " 0.018413622330863137,\n",
       " 0.020455159689709172,\n",
       " -0.006121303087358871,\n",
       " 0.016133461496783703,\n",
       " -0.009505087715505534,\n",
       " -0.005319269489157819,\n",
       " 0.014012381737763072,\n",
       " -0.016783042242832964,\n",
       " 0.008099872794249535,\n",
       " -0.013283260454184407,\n",
       " 0.004066506954392312,\n",
       " 0.009829878088530164,\n",
       " 0.0048287702838286616,\n",
       " 0.033088841260489506,\n",
       " 0.022841375815591272,\n",
       " -0.029244384430095267,\n",
       " 0.01393284120023367,\n",
       " -0.0033721850052287334,\n",
       " -0.03351305497711941,\n",
       " -0.013243490185419706,\n",
       " -0.01293195625820911,\n",
       " -0.005726914511165363,\n",
       " 0.013787016570988898,\n",
       " 0.003083850789515295,\n",
       " -0.02807778925878229,\n",
       " 0.026062764791564323,\n",
       " -0.004762486192113294,\n",
       " -0.008683169448583428,\n",
       " 0.022934172798934713,\n",
       " 0.025678318549731342,\n",
       " 0.015019893971372055,\n",
       " 0.009737080173864132,\n",
       " 0.0020050830641800328,\n",
       " -0.005912508943513538,\n",
       " 0.02219179506954201,\n",
       " -0.017618216955569106,\n",
       " -0.024405671811906077,\n",
       " -0.03958464499569175,\n",
       " -0.006363238345739292,\n",
       " -0.007251440704376764,\n",
       " -0.0009768565862487007,\n",
       " 0.012090153322565952,\n",
       " 0.008974817775750377,\n",
       " 0.020866118823170226,\n",
       " -0.0018228027432853665,\n",
       " 0.021674780644278295,\n",
       " -0.018294310593246436,\n",
       " 0.003576007516232505,\n",
       " -0.013270004008370372,\n",
       " -0.007112244763700308,\n",
       " 0.018625729189178087,\n",
       " 0.010618654309594586,\n",
       " 0.006601859958327502,\n",
       " -0.003170019549951716,\n",
       " -0.014529394300381599,\n",
       " -0.008563858642289325,\n",
       " -0.003022538330641488,\n",
       " 0.0012784474806068233,\n",
       " 0.008046845148348202,\n",
       " -0.016292542571842508,\n",
       " -0.016027406204981037,\n",
       " 0.006568717912469818,\n",
       " 0.021741064735993663,\n",
       " -0.014675218929626371,\n",
       " 0.0032744163890437335,\n",
       " -0.013482111798007915,\n",
       " -0.018267797701618366,\n",
       " -0.02977465343852783,\n",
       " 0.006939906777166168,\n",
       " 0.003950510725213013,\n",
       " 0.023451185361553238,\n",
       " 0.011268235055643847,\n",
       " -0.008689797671490447,\n",
       " 0.011095897534771006,\n",
       " -0.0030705941108706107,\n",
       " -0.011162180695163778,\n",
       " 0.029615572363469022,\n",
       " 0.0019470847167597349,\n",
       " -0.005746799645547714,\n",
       " -0.014741503021341739,\n",
       " -0.004540435602453925,\n",
       " 0.004842026729642697,\n",
       " -0.0007891907178267579,\n",
       " 0.0013008183149946302,\n",
       " -0.0007577059605264773,\n",
       " 0.011327889993129602,\n",
       " -0.021555470769306785,\n",
       " 0.01548388075073444,\n",
       " -0.004235530829472943,\n",
       " 0.009153783519530237,\n",
       " -0.015550163911127212,\n",
       " -0.005498235698598977,\n",
       " 0.003330757680737277,\n",
       " 0.00975696577390778,\n",
       " 0.011732220903683636,\n",
       " 0.014741503021341739,\n",
       " 0.007072474494935607,\n",
       " -0.026831655412585094,\n",
       " 0.019169256506069873,\n",
       " -0.010201066953226515,\n",
       " 0.02863457302148811,\n",
       " -0.017472392326324332,\n",
       " -0.014052152006527775,\n",
       " 0.0026347784430162955,\n",
       " -0.009273094325824342,\n",
       " -0.01935485047275675,\n",
       " -0.018771553818422857,\n",
       " 0.023636779328240116,\n",
       " 0.004858597752571539,\n",
       " 0.021078227544130364,\n",
       " -0.015218745315195563,\n",
       " 0.03406984060247042,\n",
       " 0.0045702635368581,\n",
       " -0.014781272358783844,\n",
       " -0.005697087042422485,\n",
       " -0.005349097423561994,\n",
       " -0.015894839884195492,\n",
       " 0.01724702715955016,\n",
       " 0.009982330009359358,\n",
       " -0.010718079515845042,\n",
       " -0.04512596600583153,\n",
       " -0.02094565936069963,\n",
       " 0.007867879404568342,\n",
       " 0.010658424578359287,\n",
       " 0.015735758809136684,\n",
       " -0.0031236210582799968,\n",
       " 0.0014110149655456126,\n",
       " -0.010804248276281464,\n",
       " -0.0045603207368362765,\n",
       " 0.0027226044920101197,\n",
       " 0.01093018823680518,\n",
       " 0.00524967175165024,\n",
       " -0.006459349906197537,\n",
       " -0.007224926881426098,\n",
       " 0.005932394077895889,\n",
       " -0.011407430530659006,\n",
       " 0.0175386764180397,\n",
       " 0.011433944353609672,\n",
       " -0.06082195547752611,\n",
       " 0.0012585624626397969,\n",
       " -0.0025038680138042605,\n",
       " -0.00923332405705964,\n",
       " 0.0017648043958650684,\n",
       " 0.012593909439370443,\n",
       " -0.010943444682619216,\n",
       " 0.02302696978227815,\n",
       " -0.015735758809136684,\n",
       " 0.033300948118804456,\n",
       " 0.020349106260551697,\n",
       " 0.013813530393939564,\n",
       " 0.012461342187262303,\n",
       " 0.03881575623731617,\n",
       " 0.005190016348503188,\n",
       " -0.037543107636845714,\n",
       " -0.01279938900610097,\n",
       " -0.012057011276708269,\n",
       " 0.024100766107602502,\n",
       " 0.020229796385580187,\n",
       " -0.005494921587145468,\n",
       " -0.023583753544983974,\n",
       " -0.0018194885154165332,\n",
       " 0.0012900472199400775,\n",
       " 0.00857711508810336,\n",
       " 0.020746808948198716,\n",
       " -0.023716319865769518,\n",
       " -0.0011624510185968759,\n",
       " 0.01748564877213837,\n",
       " 0.006220728293609327,\n",
       " 0.03396378531066775,\n",
       " 0.02171455184436559,\n",
       " 0.02052144378142454,\n",
       " -0.017976148443128823,\n",
       " -0.003037452065012927,\n",
       " 0.016385339555185948,\n",
       " -0.005769998891383573,\n",
       " -0.009465317446740833,\n",
       " -0.001350531034535183,\n",
       " 0.007384007956484905,\n",
       " -0.020932402914885594,\n",
       " -0.025824143178976113,\n",
       " -0.028581547238231968,\n",
       " 0.011274863278550866,\n",
       " -0.021992942794395908,\n",
       " 0.008848878746549254,\n",
       " -0.019673012622874367,\n",
       " 0.009180297342480902,\n",
       " -0.009418918955069112,\n",
       " -0.013654449318880758,\n",
       " -0.00020962230791082105,\n",
       " 0.0038212573517277327,\n",
       " -0.021621754861022153,\n",
       " 0.005332526400633152,\n",
       " 0.016186487280039845,\n",
       " -0.00112102369410542,\n",
       " -0.032081329026880524,\n",
       " -0.02216528031526875,\n",
       " -0.011274863278550866,\n",
       " -0.03346002919386326,\n",
       " 0.0048287702838286616,\n",
       " -0.009299608148775007,\n",
       " 0.04313745443024164,\n",
       " -0.0027226044920101197,\n",
       " -0.0012254205331974374,\n",
       " 0.015510393642362511,\n",
       " 0.006717856653168098,\n",
       " 0.006273755473849362,\n",
       " -0.014317286510744055,\n",
       " -0.020176768739678858,\n",
       " -0.016491392984343423,\n",
       " 0.008119757462970587,\n",
       " 0.016756527488559703,\n",
       " 0.014754759467155773,\n",
       " -0.039054375987259186,\n",
       " 0.011791876772491987,\n",
       " 0.010684938401309954,\n",
       " -0.021436159031690084,\n",
       " -0.015178975046430862,\n",
       " 0.003675433188144259,\n",
       " -0.0009221724666972358,\n",
       " 0.010419802965771077,\n",
       " -0.004225588029451118,\n",
       " -0.021913402256866506,\n",
       " -0.0046431753858191885,\n",
       " -0.0071984135241367295,\n",
       " 0.012010612785036548,\n",
       " -0.01330314512290546,\n",
       " -0.024392413503446852,\n",
       " 0.013747246302224196,\n",
       " 0.009829878088530164,\n",
       " 0.011228464786879146,\n",
       " 0.002174106473599366,\n",
       " -0.004069821531507118,\n",
       " -0.014025638183577108,\n",
       " 0.11771991358712858,\n",
       " 0.019049944768453175,\n",
       " 0.015099434508901458,\n",
       " 0.027003992933457937,\n",
       " -0.018175000718274926,\n",
       " 0.002371300528865471,\n",
       " -0.02521433177036896,\n",
       " -0.012872301320723355,\n",
       " 0.0014300715720645862,\n",
       " 0.011798504995399004,\n",
       " 0.0116791941891049,\n",
       " 0.012302261112203497,\n",
       " 0.012494484233119987,\n",
       " -0.021886889365238433,\n",
       " 0.005531377744456661,\n",
       " 0.0015452395062111564,\n",
       " -0.017724270384726577,\n",
       " 0.004258730075308802,\n",
       " -0.019460903901914225,\n",
       " 0.0018012604367609367,\n",
       " -0.02126382151081724,\n",
       " -0.00697967704593087,\n",
       " -0.007317724330430834,\n",
       " 0.022085739777739345,\n",
       " 0.01840036402240391,\n",
       " -0.015603191557028544,\n",
       " 0.02911181624666453,\n",
       " 0.01834733823914777,\n",
       " 0.014224489527400616,\n",
       " -0.0036224060079042245,\n",
       " 0.008656655625632764,\n",
       " 0.005630803416368415,\n",
       " 0.012063639499615286,\n",
       " 0.0059290799664423795,\n",
       " -0.008093243640019922,\n",
       " 0.00663168742707038,\n",
       " -0.004822141595260346,\n",
       " 0.0058130837372630815,\n",
       " 0.019275309935227348,\n",
       " 0.002276846256964629,\n",
       " 0.0014996695424028142,\n",
       " 0.006045076661282976,\n",
       " -0.0038742842991371187,\n",
       " -0.01008175614693241,\n",
       " 0.022297848498699487,\n",
       " -0.004159304403397048,\n",
       " -0.010983214951383918,\n",
       " 0.02720284520860404,\n",
       " 0.007973932833725817,\n",
       " 0.010433059411585113,\n",
       " 0.01906320121426721,\n",
       " -0.009730451950957113,\n",
       " -0.025612034458015975,\n",
       " 0.006094789264408204,\n",
       " -0.0291383291382926,\n",
       " 0.0098431345343442,\n",
       " 0.002508839413815173,\n",
       " -0.0037218316798159788,\n",
       " -0.01696863620951984,\n",
       " -0.023411414161465943,\n",
       " 0.011076011934727356,\n",
       " -0.04491385914751658,\n",
       " -0.012023869230850585,\n",
       " -0.011626167474526163,\n",
       " 0.020243052831394225,\n",
       " -0.006117988510244064,\n",
       " -0.02223156440698412,\n",
       " -0.0182810541474324,\n",
       " -0.006008620503971784,\n",
       " -0.010028729432353674,\n",
       " 0.016491392984343423,\n",
       " -0.01565621827160728,\n",
       " -0.004530493268093399,\n",
       " 0.025492724583044465,\n",
       " 0.007556345943019045,\n",
       " 0.01395935409186174,\n",
       " 0.029960247405214708,\n",
       " -0.009133898850809183,\n",
       " -0.004334956035723399,\n",
       " 0.020362362706365735,\n",
       " 0.006393066280143467,\n",
       " -0.02493594082033864,\n",
       " -0.018214770055717033,\n",
       " -0.0051336750568096445,\n",
       " 0.002764031816501576,\n",
       " 0.028395951408899903,\n",
       " -0.01637208310937191,\n",
       " -0.01619974558849907,\n",
       " -0.004954709313029784,\n",
       " 0.03547505366108123,\n",
       " 0.017909864351413455,\n",
       " -0.001488898330932937,\n",
       " 0.02473709040783773,\n",
       " 0.01858595985173598,\n",
       " -0.024617778670221028,\n",
       " -0.016292542571842508,\n",
       " 0.008457804281809254,\n",
       " 0.012653565308178794,\n",
       " -0.008882020792406938,\n",
       " 0.005163502991213819,\n",
       " 0.014661962483812335,\n",
       " 0.002865114311309436,\n",
       " -0.0025999795742625057,\n",
       " -0.025837399624790147,\n",
       " -0.003072251166597365,\n",
       " 0.015338056121489668,\n",
       " -0.0024375843877501905,\n",
       " 0.0026795198789612605,\n",
       " -0.02013699940223675,\n",
       " -0.019527187993629593,\n",
       " 0.0105457419949722,\n",
       " -0.023079995565534292,\n",
       " 0.01963324142278707,\n",
       " -0.008782594654833886,\n",
       " -0.013223604585376057,\n",
       " 0.031020787284725022,\n",
       " -8.420105769260463e-05,\n",
       " -0.0033970413067913475,\n",
       " -0.004858597752571539,\n",
       " 0.0037781729715095223,\n",
       " 0.017459135880510297,\n",
       " -0.004238844940926452,\n",
       " 0.0363234848196314,\n",
       " -0.00861688535686806,\n",
       " 0.020508187335610505,\n",
       " 0.006031819749807643,\n",
       " -0.0007042646909777404,\n",
       " -0.0003508895245899733,\n",
       " 0.009153783519530237,\n",
       " 0.007231555569994413,\n",
       " -0.0057401714226406955,\n",
       " -0.004914939044265082,\n",
       " 0.0033638994937643125,\n",
       " -0.03555459606125582,\n",
       " -0.013561652335537319,\n",
       " -0.00396045305957354,\n",
       " -0.01073796511588869,\n",
       " 0.002198963007992629,\n",
       " -0.0028319724982824005,\n",
       " -0.014516137854567564,\n",
       " -0.005955593323731748,\n",
       " 0.002371300528865471,\n",
       " 0.002217190853817577,\n",
       " -0.018519675760020612,\n",
       " 0.008378263744279852,\n",
       " -0.02639418338749597,\n",
       " -0.016690245259489526,\n",
       " -0.011056127266006304,\n",
       " 0.01561644800284258,\n",
       " 0.02887319463407632,\n",
       " -0.027547520250349726,\n",
       " -0.007728683463891887,\n",
       " 0.010877160590903849,\n",
       " -0.0020398819329338225,\n",
       " 0.0022453614996643485,\n",
       " 0.00017906964445683974,\n",
       " 0.0018725154628259192,\n",
       " -0.0350773528360794,\n",
       " 0.018214770055717033,\n",
       " 0.01703492030123521,\n",
       " 0.03324792233554832,\n",
       " -0.008722939717348131,\n",
       " 0.010134782861511147,\n",
       " -0.015125948331852124,\n",
       " 0.025346899953799695,\n",
       " -0.015430853104833107,\n",
       " 0.005538005967363678,\n",
       " 0.020335849814737662,\n",
       " -0.018758297372608822,\n",
       " 0.015589934179891914,\n",
       " 0.008331865252608131,\n",
       " 0.0008065902104113149,\n",
       " -0.003930625590830662,\n",
       " -0.01598763686753893,\n",
       " -0.00962439852179964,\n",
       " 0.007781710644131921,\n",
       " 0.008457804281809254,\n",
       " -0.003375499116682242,\n",
       " -0.0048486549525497144,\n",
       " -0.04281929228012402,\n",
       " -0.01358816522716539,\n",
       " -0.011612910097389533,\n",
       " -0.0182810541474324,\n",
       " 0.006618430981256344,\n",
       " 0.0017300055271112788,\n",
       " -0.011420687907795636,\n",
       " 0.02192665870268054,\n",
       " 0.022152023869454713,\n",
       " 0.02264252354044517,\n",
       " 0.0038212573517277327,\n",
       " -0.01063191075540862,\n",
       " -0.007006190868881536,\n",
       " 0.038789239620397716,\n",
       " 0.012063639499615286,\n",
       " 0.015457366927783774,\n",
       " -0.020932402914885594,\n",
       " -0.005564519324653047,\n",
       " -0.005514806721527819,\n",
       " 0.0044608955305858195,\n",
       " 0.014489624031616898,\n",
       " -0.0007825623202967536,\n",
       " 0.013680963141831424,\n",
       " -0.01358816522716539,\n",
       " 0.009286350771638377,\n",
       " 0.00792090611914708,\n",
       " -0.010658424578359287,\n",
       " -0.040088401112496244,\n",
       " -0.0012560767626343407,\n",
       " 0.006094789264408204,\n",
       " -0.025333643507985656,\n",
       " -0.0006827224426609731,\n",
       " -0.020428646798081103,\n",
       " -0.0212107957275611,\n",
       " -0.04210342930500459,\n",
       " -0.0017167487320512702,\n",
       " -0.03650908251160866,\n",
       " -0.034918271761020594,\n",
       " 0.031498030509901444,\n",
       " -0.016716758151117596,\n",
       " -0.04517899178908768,\n",
       " 0.009611141144663007,\n",
       " -0.008663283848539781,\n",
       " 0.02481663094536713,\n",
       " 0.0189438913392957,\n",
       " 0.05122406891603195,\n",
       " 0.04157315657128165,\n",
       " -0.0007552203187286834,\n",
       " -0.030410977738763056,\n",
       " 0.02094565936069963,\n",
       " 0.011977470739178864,\n",
       " 0.003625720352188382,\n",
       " 0.01548388075073444,\n",
       " 0.02675211487505569,\n",
       " 0.002198963007992629,\n",
       " 0.0023265590929205065,\n",
       " 0.0009801706977022096,\n",
       " 0.02278834816968994,\n",
       " -0.044516154597224376,\n",
       " -0.028157329796311692,\n",
       " 0.0024756976007881373,\n",
       " 0.01789660790559942,\n",
       " -0.0070260760032638874,\n",
       " -0.007556345943019045,\n",
       " 0.0019537131724974015,\n",
       " -0.019553700885257666,\n",
       " 0.025068509003769376,\n",
       " -0.023398157715651905,\n",
       " -0.011593025428668479,\n",
       " -0.01490058316507795,\n",
       " -0.016981892655333876,\n",
       " -0.026115790574820465,\n",
       " -0.008146271285921254,\n",
       " -0.01191781580169311,\n",
       " -0.005750113757001222,\n",
       " 0.006525633532251608,\n",
       " -0.008278838538029396,\n",
       " -0.0044608955305858195,\n",
       " -0.010757849784609743,\n",
       " 0.011659308589061251,\n",
       " -0.012408315472683566,\n",
       " -0.005899252497699502,\n",
       " 0.03316837993537372,\n",
       " 0.009127270627902166,\n",
       " 0.01318383524793395,\n",
       " 0.0010323691172482183,\n",
       " -0.003957138948120031,\n",
       " -0.023186050857336958,\n",
       " -0.016955379763705807,\n",
       " -0.0046829456545838906,\n",
       " 0.019858606589561244,\n",
       " -0.014821042627548547,\n",
       " -0.0018112030039521122,\n",
       " -0.008597000688147009,\n",
       " 0.014171462812821879,\n",
       " 0.008988074221564411,\n",
       " 0.02354398234489668,\n",
       " -0.00522978661726789,\n",
       " -0.009418918955069112,\n",
       " -0.02940346550515407,\n",
       " -0.014237745973214653,\n",
       " 0.009737080173864132,\n",
       " -0.007397264867960238,\n",
       " -0.012070267722522303,\n",
       " -0.025015481357868043,\n",
       " -0.004692888454605714,\n",
       " -0.02288114515303338,\n",
       " -0.01662396116777416,\n",
       " 0.015855068684108194,\n",
       " 0.003711889112624803,\n",
       " -0.006873623151112098,\n",
       " -0.006833852882347397,\n",
       " 0.0035362372474678034,\n",
       " -0.013515253843865599,\n",
       " 0.0013613022460050599,\n",
       " 0.026659317891712254,\n",
       " -0.005846225317459468,\n",
       " 0.0017681186237339017,\n",
       " 0.009657540567657323,\n",
       " -0.005388867692326696,\n",
       " 0.008239068269264693,\n",
       " 0.0021078228475452957,\n",
       " 0.008026960479627148,\n",
       " -0.0340168110939239,\n",
       " -0.01325674663123374,\n",
       " -0.01935485047275675,\n",
       " -0.016305799017656542,\n",
       " 0.0014400141392557617,\n",
       " -0.0013555023181307706,\n",
       " -0.02521433177036896,\n",
       " 0.0018642300677768225,\n",
       " -0.0006785797451364247,\n",
       " -0.0006698799697403151,\n",
       " 0.007476805405489641,\n",
       " -0.00780822400142129,\n",
       " -0.014781272358783844,\n",
       " 0.005640745750728942,\n",
       " 0.0014946982588072263,\n",
       " -0.014091922275292476,\n",
       " -0.043031399138438974,\n",
       " 0.030835193318038145,\n",
       " -0.008066730748391851,\n",
       " 0.0074701767169213255,\n",
       " 0.016279286126028473,\n",
       " -0.015165718600616825,\n",
       " 0.03873621383714158,\n",
       " 0.004056564620031785,\n",
       " 0.015735758809136684,\n",
       " -0.022682294740532467,\n",
       " -0.0112881197243649,\n",
       " -0.0043150709013410485,\n",
       " 0.01380027394812553,\n",
       " 0.0017631473401383138,\n",
       " -0.003063965655132944,\n",
       " -0.02278834816968994,\n",
       " -0.027255870991860182,\n",
       " -0.02646046747921134,\n",
       " 0.006992933957406204,\n",
       " 0.024007969124259062,\n",
       " 0.0007610201301876484,\n",
       " -0.002450841066394875,\n",
       " 0.002813744419626804,\n",
       " 0.025638549212289235,\n",
       " 0.009153783519530237,\n",
       " 0.00029848394397428914,\n",
       " 0.0031468203041158565,\n",
       " -0.009220067611245605,\n",
       " -0.013521882066772618,\n",
       " -0.0424215914551222,\n",
       " -0.028316410871370497,\n",
       " -0.019792322497845877,\n",
       " -0.00960451292175599,\n",
       " 0.018983660676737808,\n",
       " 0.001353845262404016,\n",
       " -0.0074038930908672555,\n",
       " -0.02526735941627029,\n",
       " -0.007211670435612063,\n",
       " 0.003342357303655207,\n",
       " -0.0032131039301699265,\n",
       " -0.009790107819765463,\n",
       " 0.015258515583960266,\n",
       " 0.030676112242979336,\n",
       " -0.01275299051442925,\n",
       " 0.013011496795738514,\n",
       " 0.010134782861511147,\n",
       " -0.00424215905237996,\n",
       " 0.011420687907795636,\n",
       " -0.02744146682119225,\n",
       " 0.013733989856410162,\n",
       " 0.034891758869392525,\n",
       " -0.006731113098982134,\n",
       " 0.014940353433842651,\n",
       " 0.035925783994629576,\n",
       " 0.001333131600158288,\n",
       " -0.024233332428388047,\n",
       " 0.025015481357868043,\n",
       " -0.0009793421698388323,\n",
       " -0.013283260454184407,\n",
       " 0.0276535736795072,\n",
       " 0.0019073144479950332,\n",
       " -0.00597216434666059,\n",
       " 0.0012751333691533144,\n",
       " -0.025824143178976113,\n",
       " -0.008524088373524622,\n",
       " 0.01410517872110651,\n",
       " 0.018121973072373596,\n",
       " -0.031153355468155758,\n",
       " 0.020985430560786927,\n",
       " -0.002477354656514892,\n",
       " -0.019487418656187486,\n",
       " 0.007523203897161361,\n",
       " -0.011327889993129602,\n",
       " 0.01144057257651669,\n",
       " -0.013667705764694794,\n",
       " 0.011029613443055638,\n",
       " -0.009332750194632691,\n",
       " -0.01935485047275675,\n",
       " -0.0008857164258013674,\n",
       " -0.040433079879532305,\n",
       " 0.02517456243292685,\n",
       " -0.00047889998986486355,\n",
       " 0.013057895287410233,\n",
       " 0.007417150002342589,\n",
       " 0.015881583438381457,\n",
       " -0.021436159031690084,\n",
       " 0.025492724583044465,\n",
       " 0.008789222877740904,\n",
       " -1.4836164476140129e-05,\n",
       " -0.017353082451352822,\n",
       " -0.010380032697006375,\n",
       " -0.00347989595577426,\n",
       " 0.012978355681203424,\n",
       " -0.014794529735920476,\n",
       " 0.017711013938912543,\n",
       " -0.02762706078787913,\n",
       " -0.017684501047284473,\n",
       " 0.0031352206811979264,\n",
       " -0.010141411084418165,\n",
       " -0.019195769397697945,\n",
       " 0.009273094325824342,\n",
       " 0.008941675729892693,\n",
       " -0.04716750708996795,\n",
       " -0.011387545861937952,\n",
       " 0.015947865667451634,\n",
       " -0.02216528031526875,\n",
       " 0.006283697808209888,\n",
       " -0.005060763207848556,\n",
       " 0.011354403816080268,\n",
       " -0.01727354191382342,\n",
       " -0.012978355681203424,\n",
       " 0.018652242080806156,\n",
       " -0.0196862690686884,\n",
       " -0.00663168742707038,\n",
       " 0.021051714652502294,\n",
       " -0.008431291390181183,\n",
       " -0.0032329890645522775,\n",
       " 0.031577572910076034,\n",
       " 0.23247030880610559,\n",
       " -0.006946535465734484,\n",
       " -0.0010754536138817532,\n",
       " 0.03690678333661049,\n",
       " 0.0009511715821997227,\n",
       " 0.02589042727069148,\n",
       " 0.025612034458015975,\n",
       " -0.008411405790137536,\n",
       " 0.0020382248772070678,\n",
       " 0.020680524856483348,\n",
       " -0.011553255159903778,\n",
       " -0.006227356982177642,\n",
       " -0.013787016570988898,\n",
       " 0.006442778883268695,\n",
       " -0.00041448046419189873,\n",
       " -0.011142296026442724,\n",
       " -0.024975712020425936,\n",
       " -0.018532932205834646,\n",
       " -0.028395951408899903,\n",
       " 0.0006292812313198984,\n",
       " 0.0013041324264481391,\n",
       " 0.016159974388411772,\n",
       " 0.016650474059402228,\n",
       " -0.021528957877678712,\n",
       " 0.0248431438369952,\n",
       " -0.009922675071873603,\n",
       " 0.006528947643705116,\n",
       " 0.015550163911127212,\n",
       " -0.013077780887453882,\n",
       " -0.011924444024600127,\n",
       " -0.03762264631172993,\n",
       " -0.008716311494441112,\n",
       " -0.007801595778514272,\n",
       " 0.012043754830894232,\n",
       " -0.013813530393939564,\n",
       " -0.009047730090372762,\n",
       " 0.008875391638177325,\n",
       " -0.03338049051897905,\n",
       " 0.03478570357758986,\n",
       " 0.017472392326324332,\n",
       " 0.020534700227238578,\n",
       " 0.011062755488913322,\n",
       " -0.005710343953897818,\n",
       " -0.011586397205761462,\n",
       " -0.01954044443944363,\n",
       " -0.005176759437027854,\n",
       " ...]"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "331ba903",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(text1, text2):\n",
    "    response1 = embeddings.embed_query(text1)\n",
    "    response2 = embeddings.embed_query(text2)\n",
    "    similarity_score = np.dot(response1,response2)\n",
    "    print(f\"Cosine Similarity between inputs: {similarity_score*100}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "0e6e9c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity between inputs: 81.36025253341899\n"
     ]
    }
   ],
   "source": [
    "cosine_similarity(text,'What day is today?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "3aba3605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity between inputs: 91.50557791215063\n"
     ]
    }
   ],
   "source": [
    "cosine_similarity('How are you?','How is your day?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "8b0a7e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity between inputs: 91.0319310609147\n"
     ]
    }
   ],
   "source": [
    "cosine_similarity('aaaa','aaaa1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "772817a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity between inputs: 78.64562198723497\n"
     ]
    }
   ],
   "source": [
    "cosine_similarity('aaaa','hello how are?. How is your day?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "b7b0de6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_chunk_1 = \"In 2020, home interest rates were at a historic low of 3%.\"\n",
    "text_chunk_2 = \"Interest rates dropped to 3% in 2020, encouraging homebuyers.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "1128ae79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity between inputs: 93.55030765664607\n"
     ]
    }
   ],
   "source": [
    "cosine_similarity(text_chunk_1,text_chunk_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "4be21efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity between inputs: 88.45950861648248\n"
     ]
    }
   ],
   "source": [
    "cosine_similarity('In 2020, home interest rates were at a historic low of 3%.', 'What was the interest rate in 2020?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "5a8bb3d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity between inputs: 83.61030890422309\n"
     ]
    }
   ],
   "source": [
    "cosine_similarity('In 2020, home interest rates were at a historic low of 3%.', 'What was the interest rate in 2024?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "81935601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity between inputs: 69.07058551329177\n"
     ]
    }
   ],
   "source": [
    "cosine_similarity('In 2020, home interest rates were at a historic low of 3%.', 'What is the capital of France?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206fe294",
   "metadata": {},
   "source": [
    "* Embeddings with defualt Chroma Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "c27e0f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chromadb.utils import embedding_functions\n",
    "from chromadb.utils.embedding_functions import ONNXMiniLM_L6_V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "8d6d71e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_chroma = ONNXMiniLM_L6_V2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "8a818147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "chromadb.utils.embedding_functions.ONNXMiniLM_L6_V2"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(embeddings_chroma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "048be4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity_chroma(text1, text2):\n",
    "    # Compute embeddings\n",
    "    response1 = onnx_embed_func(text1)  # Shape: (N, 384)\n",
    "    response2 = onnx_embed_func(text2)  # Shape: (M, 384)\n",
    "    \n",
    "    # Average the embeddings to get a single vector for each input\n",
    "    embedding1 = np.mean(response1, axis=0)  # Shape: (384,)\n",
    "    embedding2 = np.mean(response2, axis=0)  # Shape: (384,)\n",
    "    \n",
    "    # Compute cosine similarity\n",
    "    similarity_score = np.dot(embedding1, embedding2) / (\n",
    "        np.linalg.norm(embedding1) * np.linalg.norm(embedding2)\n",
    "    )\n",
    "    \n",
    "    # Print similarity as a percentage\n",
    "    print(f\"Cosine Similarity between inputs with Chroma ONNXMiniLM_L6_V2: {similarity_score * 100:.2f}%\")\n",
    "    return similarity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "7a0a3fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity between inputs with Chroma ONNXMiniLM_L6_V2: 97.14%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9713957530233606"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity_chroma(text,'What day is today?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae202449",
   "metadata": {},
   "source": [
    "* Use BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "a490d9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "81cf7c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name bert-base-uncased. Creating a new one with mean pooling.\n"
     ]
    }
   ],
   "source": [
    "embedding_bert = HuggingFaceEmbeddings(model_name=\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "d0a0408d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity_BERT(text1, text2):\n",
    "    # Compute embeddings\n",
    "    embedding1 = embedding_bert.embed_query(text1)  # Shape: (768,)\n",
    "    embedding2 = embedding_bert.embed_query(text2)  # Shape: (768,)\n",
    "    \n",
    "    # Compute cosine similarity\n",
    "    similarity_score = np.dot(embedding1, embedding2) / (\n",
    "        np.linalg.norm(embedding1) * np.linalg.norm(embedding2)\n",
    "    )\n",
    "    \n",
    "    # Print similarity as a percentage\n",
    "    print(f\"Cosine Similarity between inputs with BERT Embeddings: {similarity_score * 100:.2f}%\")\n",
    "    return similarity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "350fc207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity between inputs with BERT Embeddings: 46.49%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.46491207150696273"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity_BERT(text,'What day is today?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1036a07b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aff60527",
   "metadata": {},
   "source": [
    "# Chat Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "bb9028cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "f3a65c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chat([HumanMessage(content=\"Can you tell me a fact about Piscataway, NJ?\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "2a1cdd99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"One interesting fact about Piscataway, NJ is that it is home to Rutgers University's main campus, which is the largest institution of higher education in the state of New Jersey.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 37, 'prompt_tokens': 21, 'total_tokens': 58, 'completion_tokens_details': {'audio_tokens': 0, 'reasoning_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-73bc0836-a4eb-4ed8-a8ad-d5fdfdd23b3a-0')"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "8a42bf84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"One interesting fact about Piscataway, NJ is that it is home to Rutgers University's main campus, which is the largest institution of higher education in the state of New Jersey.\""
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "c2de400d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chat([SystemMessage(content='You are a travel guide who explain places in exactly 5 words.'),\n",
    "               HumanMessage(content='Can you tell me a fact about Piscataway, NJ?')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "94ab5c22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Historic sites, parks, diverse community.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 39, 'total_tokens': 48, 'completion_tokens_details': {'audio_tokens': 0, 'reasoning_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-51b16d3b-3899-4016-973d-228ae9dea7dc-0')"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "0c7ccaf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Historic sites, parks, diverse community.'"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5546dcd7",
   "metadata": {},
   "source": [
    "## InMemoryCache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "14a690c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain.llm_cache = InMemoryCache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "e94a4572",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jimmy\\AppData\\Local\\Temp\\ipykernel_18800\\3958892167.py:1: LangChainDeprecationWarning: The method `BaseChatModel.predict` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  llm.predict('tell me one sentence about Somerset,NJ')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Somerset, NJ is a diverse and thriving community located in central New Jersey.'"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.predict('tell me one sentence about Somerset,NJ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "d8495e1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Somerset, NJ is a diverse and thriving community located in central New Jersey.'"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.predict('tell me one sentence about Somerset,NJ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e374e766",
   "metadata": {},
   "source": [
    "## PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "eeb3b40c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Got unknown type C",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[312], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m result \u001b[38;5;241m=\u001b[39m llm\u001b[38;5;241m.\u001b[39mgenerate([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan you explain in 5 sentences about Citibank?\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_core\\language_models\\chat_models.py:643\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    641\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[0;32m    642\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[1;32m--> 643\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    644\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    645\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)  \u001b[38;5;66;03m# type: ignore[list-item]\u001b[39;00m\n\u001b[0;32m    646\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[0;32m    647\u001b[0m ]\n\u001b[0;32m    648\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_core\\language_models\\chat_models.py:633\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    632\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 633\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_with_cache(\n\u001b[0;32m    634\u001b[0m                 m,\n\u001b[0;32m    635\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    636\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[i] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    637\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    638\u001b[0m             )\n\u001b[0;32m    639\u001b[0m         )\n\u001b[0;32m    640\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    641\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_core\\language_models\\chat_models.py:851\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    849\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    850\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 851\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[0;32m    852\u001b[0m             messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    853\u001b[0m         )\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    855\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_community\\chat_models\\openai.py:469\u001b[0m, in \u001b[0;36mChatOpenAI._generate\u001b[1;34m(self, messages, stop, run_manager, stream, **kwargs)\u001b[0m\n\u001b[0;32m    465\u001b[0m     stream_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream(\n\u001b[0;32m    466\u001b[0m         messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    467\u001b[0m     )\n\u001b[0;32m    468\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m generate_from_stream(stream_iter)\n\u001b[1;32m--> 469\u001b[0m message_dicts, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_message_dicts(messages, stop)\n\u001b[0;32m    470\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    471\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[0;32m    472\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream} \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}),\n\u001b[0;32m    473\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    474\u001b[0m }\n\u001b[0;32m    475\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompletion_with_retry(\n\u001b[0;32m    476\u001b[0m     messages\u001b[38;5;241m=\u001b[39mmessage_dicts, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[0;32m    477\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_community\\chat_models\\openai.py:488\u001b[0m, in \u001b[0;36mChatOpenAI._create_message_dicts\u001b[1;34m(self, messages, stop)\u001b[0m\n\u001b[0;32m    486\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`stop` found in both the input and default params.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    487\u001b[0m     params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m stop\n\u001b[1;32m--> 488\u001b[0m message_dicts \u001b[38;5;241m=\u001b[39m [convert_message_to_dict(m) \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m messages]\n\u001b[0;32m    489\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m message_dicts, params\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_community\\chat_models\\openai.py:488\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    486\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`stop` found in both the input and default params.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    487\u001b[0m     params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m stop\n\u001b[1;32m--> 488\u001b[0m message_dicts \u001b[38;5;241m=\u001b[39m [convert_message_to_dict(m) \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m messages]\n\u001b[0;32m    489\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m message_dicts, params\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_community\\adapters\\openai.py:153\u001b[0m, in \u001b[0;36mconvert_message_to_dict\u001b[1;34m(message)\u001b[0m\n\u001b[0;32m    147\u001b[0m     message_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    148\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    149\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: message\u001b[38;5;241m.\u001b[39mcontent,\n\u001b[0;32m    150\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_call_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: message\u001b[38;5;241m.\u001b[39mtool_call_id,\n\u001b[0;32m    151\u001b[0m     }\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 153\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot unknown type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m message\u001b[38;5;241m.\u001b[39madditional_kwargs:\n\u001b[0;32m    155\u001b[0m     message_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m message\u001b[38;5;241m.\u001b[39madditional_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[1;31mTypeError\u001b[0m: Got unknown type C"
     ]
    }
   ],
   "source": [
    "result = llm.generate([\"Can you explain in 5 sentences about Citibank?\"]*1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287b917c",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "2f35612e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'AIMessage' object has no attribute 'generations'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[313], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m result\u001b[38;5;241m.\u001b[39mgenerations:\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(res)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pydantic\\main.py:856\u001b[0m, in \u001b[0;36mBaseModel.__getattr__\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m    853\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(item)  \u001b[38;5;66;03m# Raises AttributeError if appropriate\u001b[39;00m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;66;03m# this is the current error\u001b[39;00m\n\u001b[1;32m--> 856\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'AIMessage' object has no attribute 'generations'"
     ]
    }
   ],
   "source": [
    "for res in result.generations:\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "4d78fa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(\"Can you explain in 5 sentences about {company}?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "c3b64391",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(llm=llm,prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "b5bebfa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Citibank is a global bank that offers a wide range of financial products and services to individuals, businesses, and institutions. It was founded in 1812 as the City Bank of New York and has since grown to become one of the largest banks in the world. Citibank operates in over 160 countries and territories, providing consumers with access to banking services, credit cards, loans, and investment products. The bank is known for its innovative technology and digital banking solutions, making it convenient for customers to manage their finances online or through mobile apps. Citibank is committed to serving its customers with integrity and providing them with the tools and resources they need to achieve their financial goals.'"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run('Citibank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "aef978c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Wells Fargo is a multinational financial services company based in the United States. It is one of the largest banks in the country in terms of assets and market capitalization. The company offers a wide range of banking and financial services to individuals, businesses, and institutions. Wells Fargo has a network of branches and ATMs across the United States, making it easily accessible to customers. The company has faced controversy in recent years for unethical practices, resulting in fines and legal actions.'"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run('Wells Fargo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "2bf02dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_input_prompt = PromptTemplate(input_variables=[],\n",
    "                                   template = 'Tell me a fact')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "1bd57865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me a fact'"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_input_prompt.format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "958e6101",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Got unknown type T",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[320], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m llm(no_input_prompt\u001b[38;5;241m.\u001b[39mformat())\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_core\\_api\\deprecation.py:182\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    180\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    181\u001b[0m     emit_warning()\n\u001b[1;32m--> 182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_core\\language_models\\chat_models.py:1017\u001b[0m, in \u001b[0;36mBaseChatModel.__call__\u001b[1;34m(self, messages, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m   1009\u001b[0m \u001b[38;5;129m@deprecated\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.1.7\u001b[39m\u001b[38;5;124m\"\u001b[39m, alternative\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minvoke\u001b[39m\u001b[38;5;124m\"\u001b[39m, removal\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1.0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1010\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[0;32m   1011\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1015\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m   1016\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[1;32m-> 1017\u001b[0m     generation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[0;32m   1018\u001b[0m         [messages], stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m   1019\u001b[0m     )\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1020\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(generation, ChatGeneration):\n\u001b[0;32m   1021\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_core\\language_models\\chat_models.py:643\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    641\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[0;32m    642\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[1;32m--> 643\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    644\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    645\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)  \u001b[38;5;66;03m# type: ignore[list-item]\u001b[39;00m\n\u001b[0;32m    646\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[0;32m    647\u001b[0m ]\n\u001b[0;32m    648\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_core\\language_models\\chat_models.py:633\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    632\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 633\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_with_cache(\n\u001b[0;32m    634\u001b[0m                 m,\n\u001b[0;32m    635\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    636\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[i] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    637\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    638\u001b[0m             )\n\u001b[0;32m    639\u001b[0m         )\n\u001b[0;32m    640\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    641\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_core\\language_models\\chat_models.py:851\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    849\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    850\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 851\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[0;32m    852\u001b[0m             messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    853\u001b[0m         )\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    855\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_community\\chat_models\\openai.py:469\u001b[0m, in \u001b[0;36mChatOpenAI._generate\u001b[1;34m(self, messages, stop, run_manager, stream, **kwargs)\u001b[0m\n\u001b[0;32m    465\u001b[0m     stream_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream(\n\u001b[0;32m    466\u001b[0m         messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    467\u001b[0m     )\n\u001b[0;32m    468\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m generate_from_stream(stream_iter)\n\u001b[1;32m--> 469\u001b[0m message_dicts, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_message_dicts(messages, stop)\n\u001b[0;32m    470\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    471\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[0;32m    472\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream} \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}),\n\u001b[0;32m    473\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    474\u001b[0m }\n\u001b[0;32m    475\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompletion_with_retry(\n\u001b[0;32m    476\u001b[0m     messages\u001b[38;5;241m=\u001b[39mmessage_dicts, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[0;32m    477\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_community\\chat_models\\openai.py:488\u001b[0m, in \u001b[0;36mChatOpenAI._create_message_dicts\u001b[1;34m(self, messages, stop)\u001b[0m\n\u001b[0;32m    486\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`stop` found in both the input and default params.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    487\u001b[0m     params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m stop\n\u001b[1;32m--> 488\u001b[0m message_dicts \u001b[38;5;241m=\u001b[39m [convert_message_to_dict(m) \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m messages]\n\u001b[0;32m    489\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m message_dicts, params\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_community\\chat_models\\openai.py:488\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    486\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`stop` found in both the input and default params.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    487\u001b[0m     params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m stop\n\u001b[1;32m--> 488\u001b[0m message_dicts \u001b[38;5;241m=\u001b[39m [convert_message_to_dict(m) \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m messages]\n\u001b[0;32m    489\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m message_dicts, params\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_community\\adapters\\openai.py:153\u001b[0m, in \u001b[0;36mconvert_message_to_dict\u001b[1;34m(message)\u001b[0m\n\u001b[0;32m    147\u001b[0m     message_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    148\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    149\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: message\u001b[38;5;241m.\u001b[39mcontent,\n\u001b[0;32m    150\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_call_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: message\u001b[38;5;241m.\u001b[39mtool_call_id,\n\u001b[0;32m    151\u001b[0m     }\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 153\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot unknown type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m message\u001b[38;5;241m.\u001b[39madditional_kwargs:\n\u001b[0;32m    155\u001b[0m     message_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m message\u001b[38;5;241m.\u001b[39madditional_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[1;31mTypeError\u001b[0m: Got unknown type T"
     ]
    }
   ],
   "source": [
    "llm(no_input_prompt.format())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "7e3f033c",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_input_prompt = PromptTemplate(input_variables=['topic'],\n",
    "                                   template = 'Tell me a fact about {topic}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "76937e9c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Got unknown type T",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[322], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m llm(single_input_prompt\u001b[38;5;241m.\u001b[39mformat(topic\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSomerset NJ\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_core\\_api\\deprecation.py:182\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    180\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    181\u001b[0m     emit_warning()\n\u001b[1;32m--> 182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_core\\language_models\\chat_models.py:1017\u001b[0m, in \u001b[0;36mBaseChatModel.__call__\u001b[1;34m(self, messages, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m   1009\u001b[0m \u001b[38;5;129m@deprecated\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.1.7\u001b[39m\u001b[38;5;124m\"\u001b[39m, alternative\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minvoke\u001b[39m\u001b[38;5;124m\"\u001b[39m, removal\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1.0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1010\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[0;32m   1011\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1015\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m   1016\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[1;32m-> 1017\u001b[0m     generation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[0;32m   1018\u001b[0m         [messages], stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m   1019\u001b[0m     )\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1020\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(generation, ChatGeneration):\n\u001b[0;32m   1021\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_core\\language_models\\chat_models.py:643\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    641\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[0;32m    642\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[1;32m--> 643\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    644\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    645\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)  \u001b[38;5;66;03m# type: ignore[list-item]\u001b[39;00m\n\u001b[0;32m    646\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[0;32m    647\u001b[0m ]\n\u001b[0;32m    648\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_core\\language_models\\chat_models.py:633\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    632\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 633\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_with_cache(\n\u001b[0;32m    634\u001b[0m                 m,\n\u001b[0;32m    635\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    636\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[i] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    637\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    638\u001b[0m             )\n\u001b[0;32m    639\u001b[0m         )\n\u001b[0;32m    640\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    641\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_core\\language_models\\chat_models.py:851\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    849\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    850\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 851\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[0;32m    852\u001b[0m             messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    853\u001b[0m         )\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    855\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_community\\chat_models\\openai.py:469\u001b[0m, in \u001b[0;36mChatOpenAI._generate\u001b[1;34m(self, messages, stop, run_manager, stream, **kwargs)\u001b[0m\n\u001b[0;32m    465\u001b[0m     stream_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream(\n\u001b[0;32m    466\u001b[0m         messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    467\u001b[0m     )\n\u001b[0;32m    468\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m generate_from_stream(stream_iter)\n\u001b[1;32m--> 469\u001b[0m message_dicts, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_message_dicts(messages, stop)\n\u001b[0;32m    470\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    471\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[0;32m    472\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream} \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}),\n\u001b[0;32m    473\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    474\u001b[0m }\n\u001b[0;32m    475\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompletion_with_retry(\n\u001b[0;32m    476\u001b[0m     messages\u001b[38;5;241m=\u001b[39mmessage_dicts, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[0;32m    477\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_community\\chat_models\\openai.py:488\u001b[0m, in \u001b[0;36mChatOpenAI._create_message_dicts\u001b[1;34m(self, messages, stop)\u001b[0m\n\u001b[0;32m    486\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`stop` found in both the input and default params.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    487\u001b[0m     params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m stop\n\u001b[1;32m--> 488\u001b[0m message_dicts \u001b[38;5;241m=\u001b[39m [convert_message_to_dict(m) \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m messages]\n\u001b[0;32m    489\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m message_dicts, params\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_community\\chat_models\\openai.py:488\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    486\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`stop` found in both the input and default params.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    487\u001b[0m     params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m stop\n\u001b[1;32m--> 488\u001b[0m message_dicts \u001b[38;5;241m=\u001b[39m [convert_message_to_dict(m) \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m messages]\n\u001b[0;32m    489\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m message_dicts, params\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_community\\adapters\\openai.py:153\u001b[0m, in \u001b[0;36mconvert_message_to_dict\u001b[1;34m(message)\u001b[0m\n\u001b[0;32m    147\u001b[0m     message_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    148\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    149\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: message\u001b[38;5;241m.\u001b[39mcontent,\n\u001b[0;32m    150\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_call_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: message\u001b[38;5;241m.\u001b[39mtool_call_id,\n\u001b[0;32m    151\u001b[0m     }\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 153\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot unknown type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m message\u001b[38;5;241m.\u001b[39madditional_kwargs:\n\u001b[0;32m    155\u001b[0m     message_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m message\u001b[38;5;241m.\u001b[39madditional_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[1;31mTypeError\u001b[0m: Got unknown type T"
     ]
    }
   ],
   "source": [
    "llm(single_input_prompt.format(topic='Somerset NJ'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "73863351",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Got unknown type T",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[323], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m multiple_input_prompt \u001b[38;5;241m=\u001b[39m PromptTemplate(\n\u001b[0;32m      2\u001b[0m     input_variables\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtopic\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m\"\u001b[39m], \n\u001b[0;32m      3\u001b[0m     template\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTell me a fact about \u001b[39m\u001b[38;5;132;01m{topic}\u001b[39;00m\u001b[38;5;124m for a student \u001b[39m\u001b[38;5;132;01m{level}\u001b[39;00m\u001b[38;5;124m level.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m )\n\u001b[1;32m----> 5\u001b[0m llm(multiple_input_prompt\u001b[38;5;241m.\u001b[39mformat(topic\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMars\u001b[39m\u001b[38;5;124m'\u001b[39m,level\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m8th Grade\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_core\\_api\\deprecation.py:182\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    180\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    181\u001b[0m     emit_warning()\n\u001b[1;32m--> 182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_core\\language_models\\chat_models.py:1017\u001b[0m, in \u001b[0;36mBaseChatModel.__call__\u001b[1;34m(self, messages, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m   1009\u001b[0m \u001b[38;5;129m@deprecated\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.1.7\u001b[39m\u001b[38;5;124m\"\u001b[39m, alternative\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minvoke\u001b[39m\u001b[38;5;124m\"\u001b[39m, removal\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1.0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1010\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[0;32m   1011\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1015\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m   1016\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[1;32m-> 1017\u001b[0m     generation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[0;32m   1018\u001b[0m         [messages], stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m   1019\u001b[0m     )\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1020\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(generation, ChatGeneration):\n\u001b[0;32m   1021\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_core\\language_models\\chat_models.py:643\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    641\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[0;32m    642\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[1;32m--> 643\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    644\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    645\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)  \u001b[38;5;66;03m# type: ignore[list-item]\u001b[39;00m\n\u001b[0;32m    646\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[0;32m    647\u001b[0m ]\n\u001b[0;32m    648\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_core\\language_models\\chat_models.py:633\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    632\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 633\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_with_cache(\n\u001b[0;32m    634\u001b[0m                 m,\n\u001b[0;32m    635\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    636\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[i] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    637\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    638\u001b[0m             )\n\u001b[0;32m    639\u001b[0m         )\n\u001b[0;32m    640\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    641\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_core\\language_models\\chat_models.py:851\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    849\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    850\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 851\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[0;32m    852\u001b[0m             messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    853\u001b[0m         )\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    855\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_community\\chat_models\\openai.py:469\u001b[0m, in \u001b[0;36mChatOpenAI._generate\u001b[1;34m(self, messages, stop, run_manager, stream, **kwargs)\u001b[0m\n\u001b[0;32m    465\u001b[0m     stream_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream(\n\u001b[0;32m    466\u001b[0m         messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    467\u001b[0m     )\n\u001b[0;32m    468\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m generate_from_stream(stream_iter)\n\u001b[1;32m--> 469\u001b[0m message_dicts, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_message_dicts(messages, stop)\n\u001b[0;32m    470\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    471\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[0;32m    472\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream} \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}),\n\u001b[0;32m    473\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    474\u001b[0m }\n\u001b[0;32m    475\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompletion_with_retry(\n\u001b[0;32m    476\u001b[0m     messages\u001b[38;5;241m=\u001b[39mmessage_dicts, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[0;32m    477\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_community\\chat_models\\openai.py:488\u001b[0m, in \u001b[0;36mChatOpenAI._create_message_dicts\u001b[1;34m(self, messages, stop)\u001b[0m\n\u001b[0;32m    486\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`stop` found in both the input and default params.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    487\u001b[0m     params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m stop\n\u001b[1;32m--> 488\u001b[0m message_dicts \u001b[38;5;241m=\u001b[39m [convert_message_to_dict(m) \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m messages]\n\u001b[0;32m    489\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m message_dicts, params\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_community\\chat_models\\openai.py:488\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    486\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`stop` found in both the input and default params.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    487\u001b[0m     params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m stop\n\u001b[1;32m--> 488\u001b[0m message_dicts \u001b[38;5;241m=\u001b[39m [convert_message_to_dict(m) \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m messages]\n\u001b[0;32m    489\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m message_dicts, params\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_community\\adapters\\openai.py:153\u001b[0m, in \u001b[0;36mconvert_message_to_dict\u001b[1;34m(message)\u001b[0m\n\u001b[0;32m    147\u001b[0m     message_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    148\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    149\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: message\u001b[38;5;241m.\u001b[39mcontent,\n\u001b[0;32m    150\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_call_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: message\u001b[38;5;241m.\u001b[39mtool_call_id,\n\u001b[0;32m    151\u001b[0m     }\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 153\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot unknown type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m message\u001b[38;5;241m.\u001b[39madditional_kwargs:\n\u001b[0;32m    155\u001b[0m     message_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m message\u001b[38;5;241m.\u001b[39madditional_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[1;31mTypeError\u001b[0m: Got unknown type T"
     ]
    }
   ],
   "source": [
    "multiple_input_prompt = PromptTemplate(\n",
    "    input_variables=[\"topic\", \"level\"], \n",
    "    template=\"Tell me a fact about {topic} for a student {level} level.\"\n",
    ")\n",
    "llm(multiple_input_prompt.format(topic='Mars',level='8th Grade'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "8fa16129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['level', 'topic']"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiple_input_prompt.input_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9385dade",
   "metadata": {},
   "source": [
    "## Serizalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "d0082943",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_input_prompt.save(\"prompt.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "f13c2f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import load_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "9050ac16",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_prompt = load_prompt('prompt.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "3aa0dc6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['level', 'topic'], input_types={}, partial_variables={}, template='Tell me a fact about {topic} for a student {level} level.')"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cc30bb",
   "metadata": {},
   "source": [
    "## Chat Model Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "8233f8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template=\"You are an AI recipe assistant that specializes in {dietary_preference} dishes that can be prepared in {cooking_time}.\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "d8034277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cooking_time', 'dietary_preference']"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_message_prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "495a4902",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_template=\"{recipe_request}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "a9b87894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['recipe_request']"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_message_prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "d38f5184",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "4d6ae78d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cooking_time', 'dietary_preference', 'recipe_request']"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "0d820d55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are an AI recipe assistant that specializes in Vegan dishes that can be prepared in 15 min.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Quick Snack', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_prompt.format_prompt(cooking_time=\"15 min\", dietary_preference=\"Vegan\", recipe_request=\"Quick Snack\").to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "797029d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "request = chat_prompt.format_prompt(cooking_time=\"15 min\", dietary_preference=\"Vegan\", recipe_request=\"Quick Snack\").to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "a28a9345",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "e839a10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chat(request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "f49f2168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"How about trying a simple and delicious Avocado and Hummus Toast? Here's a quick recipe for you:\\n\\nIngredients:\\n- 1 ripe avocado\\n- 2 slices of whole grain bread\\n- 1/2 cup of hummus\\n- Salt and pepper to taste\\n- Optional toppings: cherry tomatoes, red pepper flakes, sesame seeds\\n\\nInstructions:\\n1. Toast the slices of bread until golden brown.\\n2. Mash the ripe avocado in a bowl and season with salt and pepper.\\n3. Spread a generous amount of hummus on each slice of toast.\\n4. Top the hummus with the mashed avocado.\\n5. Add your favorite toppings like cherry tomatoes, red pepper flakes, or sesame seeds.\\n6. Enjoy your delicious and nutritious Avocado and Hummus Toast!\\n\\nThis snack is not only quick to make but also packed with healthy fats, fiber, and protein to keep you satisfied.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 181, 'prompt_tokens': 34, 'total_tokens': 215, 'completion_tokens_details': {'audio_tokens': 0, 'reasoning_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-a96ea5d4-7b33-4584-a7d3-bbbaf170a2a6-0')"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "263d0f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How about trying a simple and delicious Avocado and Hummus Toast? Here's a quick recipe for you:\n",
      "\n",
      "Ingredients:\n",
      "- 1 ripe avocado\n",
      "- 2 slices of whole grain bread\n",
      "- 1/2 cup of hummus\n",
      "- Salt and pepper to taste\n",
      "- Optional toppings: cherry tomatoes, red pepper flakes, sesame seeds\n",
      "\n",
      "Instructions:\n",
      "1. Toast the slices of bread until golden brown.\n",
      "2. Mash the ripe avocado in a bowl and season with salt and pepper.\n",
      "3. Spread a generous amount of hummus on each slice of toast.\n",
      "4. Top the hummus with the mashed avocado.\n",
      "5. Add your favorite toppings like cherry tomatoes, red pepper flakes, or sesame seeds.\n",
      "6. Enjoy your delicious and nutritious Avocado and Hummus Toast!\n",
      "\n",
      "This snack is not only quick to make but also packed with healthy fats, fiber, and protein to keep you satisfied.\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b124fa",
   "metadata": {},
   "source": [
    "# Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "c2b9de8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "a76674eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "store = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "4f31e1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryChatMessageHistory()\n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "cbacdcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(model, get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "e18b4f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"abc2\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "8033e658",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi! I'm JJ\")],\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "e80d28a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello JJ! How can I assist you today?'"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "6a96c460",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What's my name?\")],\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "0e04081e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is JJ. How can I assist you today, JJ?'"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "b678ba33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abc2': InMemoryChatMessageHistory(messages=[HumanMessage(content=\"Hi! I'm JJ\", additional_kwargs={}, response_metadata={}), AIMessage(content='Hello JJ! How can I assist you today?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 12, 'total_tokens': 22, 'completion_tokens_details': {'audio_tokens': 0, 'reasoning_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-5293cc93-8eee-48c8-869f-464c01f79118-0'), HumanMessage(content=\"What's my name?\", additional_kwargs={}, response_metadata={}), AIMessage(content='Your name is JJ. How can I assist you today, JJ?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 35, 'total_tokens': 49, 'completion_tokens_details': {'audio_tokens': 0, 'reasoning_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-a881a45b-edff-4f73-80c3-19dbda986e13-0')])}"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f5ce28",
   "metadata": {},
   "source": [
    "## Few shot promot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "8bdf6bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a few-shot prompt template\n",
    "prompt_template = \"\"\"\n",
    "Translate the following English sentences into French:\n",
    "\n",
    "English: How are you?\n",
    "French: Comment ça va?\n",
    "\n",
    "English: What time is it?\n",
    "French: Quelle heure est-il?\n",
    "\n",
    "English: I love programming.\n",
    "French: J'adore la programmation.\n",
    "\n",
    "English: {sentence}\n",
    "French:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "29446009",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(template=prompt_template, input_variables=[\"sentence\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "61c694b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(prompt=prompt, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "f7b18662",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sentence = \"Where is the library?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "0002900f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chain.run(sentence=new_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "99272cb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Où est la bibliothèque?'"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "cf954cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message_prompt = SystemMessagePromptTemplate.from_template(\n",
    "    \"You are a helpful travel guide who explains different places\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "e689123b",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_input_one = HumanMessagePromptTemplate.from_template(\"Explain about Edison NJ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "1ca9af4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_output_one = AIMessagePromptTemplate.from_template(\"1. Edison is in teh Northeast corridor. 2. Edison is a very nice place to live. The end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "b206a508",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_message_prompt = HumanMessagePromptTemplate.from_template(\"{place_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "c8bb1b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [system_message_prompt, example_input_one, example_output_one, human_message_prompt]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "63c77bdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['place_name'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful travel guide who explains different places'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='Explain about Edison NJ'), additional_kwargs={}), AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='1. Edison is in teh Northeast corridor. 2. Edison is a very nice place to live. The end'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['place_name'], input_types={}, partial_variables={}, template='{place_name}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "03eec674",
   "metadata": {},
   "outputs": [],
   "source": [
    "place_name= \"Explain about Piscataway, NJ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "4d8bd131",
   "metadata": {},
   "outputs": [],
   "source": [
    "request = chat_prompt.format_prompt(place_name=place_name).to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "32a41111",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chat(request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "7e0ef3d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Piscataway is a township located in Middlesex County, New Jersey. It is a diverse and vibrant community that offers a mix of residential, commercial, and industrial areas. Piscataway is home to Rutgers University's main campus, which brings a youthful energy to the town.\\n\\nVisitors to Piscataway can explore the historic East Jersey Old Town Village, a collection of restored 18th and 19th-century buildings that offer a glimpse into the area's past. The township also has several parks and recreational facilities, including the scenic Johnson Park along the Raritan River.\\n\\nPiscataway is conveniently located near major highways, making it easy to access nearby cities like New Brunswick and Edison. With its rich history, cultural diversity, and convenient location, Piscataway is a great place to visit or call home.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 170, 'prompt_tokens': 66, 'total_tokens': 236, 'completion_tokens_details': {'audio_tokens': 0, 'reasoning_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-0437cc69-bee8-434a-8657-f3c877290f5a-0')"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "b6a33eac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Piscataway is a township located in Middlesex County, New Jersey. It is a diverse and vibrant community that offers a mix of residential, commercial, and industrial areas. Piscataway is home to Rutgers University's main campus, which brings a youthful energy to the town.\\n\\nVisitors to Piscataway can explore the historic East Jersey Old Town Village, a collection of restored 18th and 19th-century buildings that offer a glimpse into the area's past. The township also has several parks and recreational facilities, including the scenic Johnson Park along the Raritan River.\\n\\nPiscataway is conveniently located near major highways, making it easy to access nearby cities like New Brunswick and Edison. With its rich history, cultural diversity, and convenient location, Piscataway is a great place to visit or call home.\""
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7d22b4",
   "metadata": {},
   "source": [
    "* In the example above, it is not guaranted to have teh response in 2 numbered sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00095e1b",
   "metadata": {},
   "source": [
    "## Parsisng output- comma seperated values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "286a812b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = CommaSeparatedListOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "0de13bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "format_instructions = output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "6c25020a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`\n"
     ]
    }
   ],
   "source": [
    "print(format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "fcd1f154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['one', 'two', 'three']"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reply = \"one, two, three\"\n",
    "output_parser.parse(reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "145b0280",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_template = '{request} {format_instructions}'\n",
    "human_prompt = HumanMessagePromptTemplate.from_template(human_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "573085c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt = ChatPromptTemplate.from_messages([human_prompt])\n",
    "\n",
    "chat_prompt.format_prompt(request=\"Please provide 3 facts about Piscataway, NJ\",\n",
    "                   format_instructions = output_parser.get_format_instructions())\n",
    "\n",
    "request = chat_prompt.format_prompt(request=\"Please provide 3 facts about Piscataway, NJ\",\n",
    "                   format_instructions = output_parser.get_format_instructions()).to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "d6bd581d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chat(request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "57826f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "da6dd736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'home to Rutgers University, diverse population, historical significance'"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "89d56727",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_formatted = output_parser.parse(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "7636524e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(output_formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "bff932e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'home to Rutgers University'"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_formatted[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "434bc34b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['home to Rutgers University', 'diverse population', 'historical significance']"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "f89eed38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element 0: home to Rutgers University\n",
      "Element 1: diverse population\n",
      "Element 2: historical significance\n"
     ]
    }
   ],
   "source": [
    "for index, element in enumerate(output_formatted):\n",
    "    print(f\"Element {index}: {element}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61e79d5",
   "metadata": {},
   "source": [
    "## Parsisng output- Date time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "cdfed3f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Piscataway, NJ was incorporated as a township in 1798.'"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.predict('When was Piscataway,NJ incorporated?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "dc5868a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = DatetimeOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "919f3a91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Write a datetime string that matches the following pattern: '%Y-%m-%dT%H:%M:%S.%fZ'.\\n\\nExamples: 1318-02-03T10:34:10.864960Z, 0280-01-01T00:30:05.725060Z, 0046-04-03T12:59:26.947996Z\\n\\nReturn ONLY this string, no other words!\""
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "b33034c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_text = \"{request}\\n{format_instructions}\"\n",
    "human_prompt=HumanMessagePromptTemplate.from_template(template_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "8d4e2162",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt = ChatPromptTemplate.from_messages([human_prompt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "89c9bb47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: When was Piscataway,NJ incorporated?\n",
      "Write a datetime string that matches the following pattern: '%Y-%m-%dT%H:%M:%S.%fZ'.\n",
      "\n",
      "Examples: 1227-02-05T20:20:36.834679Z, 1535-01-18T23:56:49.280678Z, 1936-05-27T09:20:26.348541Z\n",
      "\n",
      "Return ONLY this string, no other words!\n"
     ]
    }
   ],
   "source": [
    "print(chat_prompt.format(request=\"When was Piscataway,NJ incorporated?\",\n",
    "                   format_instructions=output_parser.get_format_instructions()\n",
    "                   ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "1833b88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "request = chat_prompt.format_prompt(request=\"When was Piscataway,NJ incorporated?\",\n",
    "                   format_instructions=output_parser.get_format_instructions()\n",
    "                   ).to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "168204e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chat(request,temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "85a4f9fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1666-02-21T00:00:00.000000Z'"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4d48a5",
   "metadata": {},
   "source": [
    "## Pydantic JSON Parser- python object conversion of output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "5ca31195",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "9db3da6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scientist(BaseModel):\n",
    "    discoveries: list = Field(description=\"Python list of discoveries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "bb275a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'Provide 3 discoveries of Thomas A Edison' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "9ded6808",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = PydanticOutputParser(pydantic_object=Scientist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "584aac87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"discoveries\": {\"description\": \"Python list of discoveries\", \"items\": {}, \"title\": \"Discoveries\", \"type\": \"array\"}}, \"required\": [\"discoveries\"]}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "ee5b943a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "605e49fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = prompt.format_prompt(query=\"Provide 3 discoveries of Thomas A Edison\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "3f1e5414",
   "metadata": {},
   "outputs": [],
   "source": [
    "#output = chat(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9daa69f1",
   "metadata": {},
   "source": [
    "# Document/Data Connectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7ecaf0",
   "metadata": {},
   "source": [
    "## Loading CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "ea0c327c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import CSVLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "367497f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = CSVLoader('penguins.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "d07fa9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "152e11dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "4fe7396e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'penguins.csv', 'row': 0}, page_content='species: Adelie\\nisland: Torgersen\\nbill_length_mm: 39.1\\nbill_depth_mm: 18.7\\nflipper_length_mm: 181\\nbody_mass_g: 3750\\nsex: MALE')"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2681a42d",
   "metadata": {},
   "source": [
    "## Loading custom .txt File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "f856ad97",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'constitution.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "bd79dc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = TextLoader(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "ba7a5c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "d48f3f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "714139fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "133466d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "65b39bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = Chroma.from_documents(chunks, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "07e56a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model='gpt-3.5-turbo', temperature=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "70196ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever=vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "f2d80c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = RetrievalQA.from_chain_type(llm, retriever=retriever )\n",
    "#crc = ConversationalRetrievalChain.from_llm(llm,retriever)\n",
    "#st.session_state.crc = crc\n",
    "#st.success('File uploaded, chunked and embedded successfully')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "bd97c3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'what is the age to be a senator?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "86be7b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.run(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "620659ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To be a Senator in the United States, you must be at least thirty years old.'"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "adbd8a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_query_retriever = MultiQueryRetriever.from_llm(retriever=retriever,llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "a9b37664",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_docs = multi_query_retriever.get_relevant_documents(query=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "0a20b51b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'constitution.txt'}, page_content='person not a natural-born................\\n    No person shall be a Senator who shall          1          3       3\\n     not have attained the age of thirty\\n     years, and been nine years a.........\\n    No person shall be a Representative             1          2       2\\n     who shall not have attained the age\\n     of twenty-five years, and been seven\\n     years a..............................\\n    Right of citizens to vote shall not be         19    .......  ......\\n     denied or abridged by the United\\n     States or any State on account of\\n     sex. [Amendments]....................\\n    Right to vote shall not be denied or           24          1  ......\\n     abridged by the United States or any\\n     State for failure to pay any poll tax\\n     or other tax. [Amendments]...........\\n    Right to vote shall not be denied or           26          1  ......\\n     abridged by the United States or any\\n     State to any citizen eighteen years\\n     or older, on account of age.'),\n",
       " Document(metadata={'source': 'constitution.txt'}, page_content='the seats of one-third shall become\\n vacant at the expiration of every second\\n year.....................................\\n    No person shall be a Senator who shall          1          3       3\\n     not be thirty years of age, nine\\n     years a citizen of the United States,\\n     and an inhabitant when elected of the\\n     State for which he shall be chosen...\\n    The times, places, and manner of                1          4       1\\n     choosing Senators may be fixed by the\\n     legislature of a State, but Congress\\n     may by law make or alter such\\n     regulations, except as the places of\\n     choosing.............................\\n    If vacancies happen during the recess           1          3       2\\n     of the legislature of a State, the\\n     executive thereof may make temporary\\n     appointments until the next meeting\\n     of the legislature...................\\n    If vacancies happen the executive              17          2  ......\\n     authority of the State shall issue'),\n",
       " Document(metadata={'source': 'constitution.txt'}, page_content='diminished during their continuance\\n     in office............................\\nInferior officers, Congress, if they think          2          2       2\\n proper, may by law vest the appointment\\n of in the President alone, in the courts\\n of law, or in the heads of Departments...\\nInhabitant of the State for which he shall          1          3       3\\n be chosen. No person shall be a Senator\\n who shall not have attained the age of\\n thirty years, been nine years a citizen\\n of the United States, and who shall not,\\n when elected, be an......................\\nInsurrection or rebellion against the              14          3  ......\\n United States. No person shall be a\\n Senator or Representative in Congress, or\\n presidential elector, or hold any office,\\n civil or military, under the United\\n States, or any State, who, having taken\\n an oath as a legislative, executive, or\\n judicial officer of the United States, or\\n of a State, afterwards engaged in.\\n [Amendments].............................')]"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a78b146",
   "metadata": {},
   "source": [
    "## ContextualCompressionRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "e57c1e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "9575a955",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressor = LLMChainExtractor.from_llm(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "824e7cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "compression_retriever = ContextualCompressionRetriever(base_compressor=compressor, base_retriever=retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "0d4f88ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = vector_store.similarity_search('what is the age to be a senator?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "813e00dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'constitution.txt'}, page_content='person not a natural-born................\\n    No person shall be a Senator who shall          1          3       3\\n     not have attained the age of thirty\\n     years, and been nine years a.........\\n    No person shall be a Representative             1          2       2\\n     who shall not have attained the age\\n     of twenty-five years, and been seven\\n     years a..............................\\n    Right of citizens to vote shall not be         19    .......  ......\\n     denied or abridged by the United\\n     States or any State on account of\\n     sex. [Amendments]....................\\n    Right to vote shall not be denied or           24          1  ......\\n     abridged by the United States or any\\n     State for failure to pay any poll tax\\n     or other tax. [Amendments]...........\\n    Right to vote shall not be denied or           26          1  ......\\n     abridged by the United States or any\\n     State to any citizen eighteen years\\n     or older, on account of age.')"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "28a12670",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_docs = compression_retriever.get_relevant_documents(\"what is the age to be a senator?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "a55240a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'constitution.txt'}, page_content='No person shall be a Senator who shall not have attained the age of thirty years'),\n",
       " Document(metadata={'source': 'constitution.txt'}, page_content='No person shall be a Senator who shall not have attained the age of thirty years'),\n",
       " Document(metadata={'source': 'constitution.txt'}, page_content='No person shall be a Senator who shall not be thirty years of age'),\n",
       " Document(metadata={'source': 'constitution.txt'}, page_content='No person shall be a Senator who shall not be thirty years of age')]"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compressed_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722a0b84",
   "metadata": {},
   "source": [
    "## Loading custom PDF File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "56e0db5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_name= 'doc_inputs/falcon-users-guide-2021-09.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "3e8d1118",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_loader = PyPDFLoader(pdf_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "16f67a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overwriting cache for 0 11250\n"
     ]
    }
   ],
   "source": [
    "documents = pdf_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "2f23d771",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "9f788855",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "8d0af661",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "055491f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = Chroma.from_documents(chunks, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "ad6c6399",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model='gpt-3.5-turbo', temperature=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "162e9c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever=vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "cf0ec3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = RetrievalQA.from_chain_type(llm, retriever=retriever )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "cbe941c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'where can I find the standard price for Falcon 9 and Falcon Heavy launch services?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "3b8335e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.run(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "0ba54ff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You can find the standard price for Falcon 9 and Falcon Heavy launch services at https://www.spacex.com/media/Capabilities&Services.pdf. The pricing includes range services, standard payload integration, and third-party liability insurance. See Section 7.3 for a complete description of the standard services offered by SpaceX.'"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de65bbc3",
   "metadata": {},
   "source": [
    "# Loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e5177b",
   "metadata": {},
   "source": [
    "## WebBaseLoader - loads web pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "7540ecc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "3552d209",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = WebBaseLoader(\"https://www.google.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "b3ede4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "709082ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.documents.base.Document"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "5b1e7f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(data[0].page_content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "70875a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GoogleSearch Images Maps Play YouTube News Gmail Drive More »Web History | Settings | Sign in Advanced searchLearn practical AI skills with training and tools from GoogleAdvertisingBusiness SolutionsAbout Google© 2024 - Privacy - Terms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3915d5ca",
   "metadata": {},
   "source": [
    "## WikipediaLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "f5fd679b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WikipediaLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "8f62472e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jimmy\\AppData\\Roaming\\Python\\Python311\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file C:\\Users\\jimmy\\AppData\\Roaming\\Python\\Python311\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    }
   ],
   "source": [
    "loader = WikipediaLoader(query='New Jersey')\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "f2afc65e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'title': 'New Jersey', 'summary': \"New Jersey is a state in both the Mid-Atlantic and Northeastern regions of the United States. It is the most densely populated state and at the center of the Northeast megalopolis. New Jersey is bordered to the northeast by New York state; on its east, southeast, and south by the Atlantic Ocean; on its west by the Delaware River and Pennsylvania; and on its southwest by Delaware Bay and Delaware. At 7,354 square miles (19,050 km2), New Jersey is the fifth-smallest state in land area, but with close to 9.3 million residents as of the 2020 United States census, it ranks 11th in population. The state capital is Trenton, and the state's most populous city is Newark. New Jersey is the only U.S. state in which every county is deemed urban by the U.S. Census Bureau.\\nNew Jersey was first inhabited by Paleo-Indians as early as 13,000 B.C.E. The Lenape were the dominant Indigenous group when Europeans arrived in the early 17th century, and they were subdivived into dialectal groups such as the Munsee, in the north, and the Unami and the Unalachtigo, elsewhere. Dutch and Swedish colonists founded the first European settlements in the state, with the British later seizing control of the region and establishing the Province of New Jersey, named after Jersey. The colony's fertile lands and relative religious tolerance drew a large and diverse population. New Jersey was among the Thirteen Colonies that supported the American Revolution, hosting several pivotal battles and military commands in the American Revolutionary War. New Jersey remained in the Union during the American Civil War and provided troops, resources, and military leaders in support of the Union Army. After the war, the state emerged as a major manufacturing center and a leading destination for immigrants, helping drive the Industrial Revolution in the U.S. New Jersey was the site of many industrial, technological, and commercial innovations. Many prominent Americans associated with New Jersey have proven influential nationally and globally, including in academia, advocacy, business, entertainment, government, military, non-profit leadership, and other fields.\\nNew Jersey's central location in the Northeast megalopolis helped fuel its rapid growth and suburbanization in the second half of the 20th century. Since the beginning of the 21st century, the state's economy has become highly diversified, with major sectors including biotechnology, pharmaceuticals, information technology, finance, and tourism, and it has become an Atlantic seaboard epicenter for logistics and distribution. New Jersey remains a major destination for immigrants and is home to one of the world's most multicultural populations. Echoing historical trends, the state has increasingly re-urbanized, with growth in cities outpacing suburbs since 2008.\\nNew Jersey is one of the most educated, affluent, healthy, diverse and highly developed states in the U.S., ranking it high in several quality of life metrics. As of 2022, New Jersey had the highest annual median household income, at $96,346, of all 50 states. Almost one-tenth of all households in the state, or over 323,000, are millionaires, the highest representation of millionaires among all states. New Jersey's public school system consistently ranks at or among the top of all U.S. states. In 2024, New Jersey was ranked as having the second-healthiest population overall. New Jersey was ranked as the fourth most diverse state in 2024. New Jersey ranks near the top on both the American Human Development Index and the standard Human Development Index. According to climatology research by the U.S. National Oceanic and Atmospheric Administration, New Jersey has been the fastest-warming state by average air temperature over a 100-year period beginning in the early 20th century, which has been attributed to warming of the North Atlantic Ocean.\", 'source': 'https://en.wikipedia.org/wiki/New_Jersey'}, page_content=\"New Jersey is a state in both the Mid-Atlantic and Northeastern regions of the United States. It is the most densely populated state and at the center of the Northeast megalopolis. New Jersey is bordered to the northeast by New York state; on its east, southeast, and south by the Atlantic Ocean; on its west by the Delaware River and Pennsylvania; and on its southwest by Delaware Bay and Delaware. At 7,354 square miles (19,050 km2), New Jersey is the fifth-smallest state in land area, but with close to 9.3 million residents as of the 2020 United States census, it ranks 11th in population. The state capital is Trenton, and the state's most populous city is Newark. New Jersey is the only U.S. state in which every county is deemed urban by the U.S. Census Bureau.\\nNew Jersey was first inhabited by Paleo-Indians as early as 13,000 B.C.E. The Lenape were the dominant Indigenous group when Europeans arrived in the early 17th century, and they were subdivived into dialectal groups such as the Munsee, in the north, and the Unami and the Unalachtigo, elsewhere. Dutch and Swedish colonists founded the first European settlements in the state, with the British later seizing control of the region and establishing the Province of New Jersey, named after Jersey. The colony's fertile lands and relative religious tolerance drew a large and diverse population. New Jersey was among the Thirteen Colonies that supported the American Revolution, hosting several pivotal battles and military commands in the American Revolutionary War. New Jersey remained in the Union during the American Civil War and provided troops, resources, and military leaders in support of the Union Army. After the war, the state emerged as a major manufacturing center and a leading destination for immigrants, helping drive the Industrial Revolution in the U.S. New Jersey was the site of many industrial, technological, and commercial innovations. Many prominent Americans associated with New Jersey have proven influential nationally and globally, including in academia, advocacy, business, entertainment, government, military, non-profit leadership, and other fields.\\nNew Jersey's central location in the Northeast megalopolis helped fuel its rapid growth and suburbanization in the second half of the 20th century. Since the beginning of the 21st century, the state's economy has become highly diversified, with major sectors including biotechnology, pharmaceuticals, information technology, finance, and tourism, and it has become an Atlantic seaboard epicenter for logistics and distribution. New Jersey remains a major destination for immigrants and is home to one of the world's most multicultural populations. Echoing historical trends, the state has increasingly re-urbanized, with growth in cities outpacing suburbs since 2008.\\nNew Jersey is one of the most educated, affluent, healthy, diverse and highly developed states in the U.S., ranking it high in several quality of life metrics. As of 2022, New Jersey had the highest annual median household income, at $96,346, of all 50 states. Almost one-tenth of all households in the state, or over 323,000, are millionaires, the highest representation of millionaires among all states. New Jersey's public school system consistently ranks at or among the top of all U.S. states. In 2024, New Jersey was ranked as having the second-healthiest population overall. New Jersey was ranked as the fourth most diverse state in 2024. New Jersey ranks near the top on both the American Human Development Index and the standard Human Development Index. According to climatology research by the U.S. National Oceanic and Atmospheric Administration, New Jersey has been the fastest-warming state by average air temperature over a 100-year period beginning in the early 20th century, which has been attributed to warming of the North Atlantic Ocean.\\n\\n\\n== History ==\\n\\n\\n=== Prehistoric era ===\\n\\nThe pressure of collision between North America and Africa gave rise to the Appalac\"),\n",
       " Document(metadata={'title': 'Jersey City, New Jersey', 'summary': \"Jersey City is the second-most populous city in the U.S. state of New Jersey, after Newark. It is the county seat of Hudson County, and is the county's most populous city and its largest (by area).  As of the 2020 United States census, the city's population was 292,449, an increase of 44,852 (+18.1%) from the 2010 census count of 247,597, in turn an increase of 7,542 (+3.1%) from the 240,055 enumerated at the 2000 census. The Population Estimates Program calculated a population of 291,657 for 2023, making it the 72nd-most populous municipality in the nation.\\nConstituting part of the New York metropolitan area, Jersey City is bounded on the east by the Hudson River and Upper New York Bay and on the west by the Hackensack River and Newark Bay. A port of entry, with 30.7 miles (49.4 km) of waterfront and extensive rail infrastructure and connectivity, the city is an important transportation terminus and distribution and manufacturing center for the Port of New York and New Jersey. The Holland Tunnel, PATH mass transit system, and NY Waterway ferry service connect across the Hudson River with Manhattan. Redevelopment of the Jersey City waterfront has made the city one of the largest centers of banking and finance in the United States and has led to the district and city being nicknamed Wall Street West. Jersey City's proximity to Manhattan and its own financially based economy have propelled apartment rents in the city to some of the highest in the United States.\", 'source': 'https://en.wikipedia.org/wiki/Jersey_City,_New_Jersey'}, page_content='Jersey City is the second-most populous city in the U.S. state of New Jersey, after Newark. It is the county seat of Hudson County, and is the county\\'s most populous city and its largest (by area).  As of the 2020 United States census, the city\\'s population was 292,449, an increase of 44,852 (+18.1%) from the 2010 census count of 247,597, in turn an increase of 7,542 (+3.1%) from the 240,055 enumerated at the 2000 census. The Population Estimates Program calculated a population of 291,657 for 2023, making it the 72nd-most populous municipality in the nation.\\nConstituting part of the New York metropolitan area, Jersey City is bounded on the east by the Hudson River and Upper New York Bay and on the west by the Hackensack River and Newark Bay. A port of entry, with 30.7 miles (49.4 km) of waterfront and extensive rail infrastructure and connectivity, the city is an important transportation terminus and distribution and manufacturing center for the Port of New York and New Jersey. The Holland Tunnel, PATH mass transit system, and NY Waterway ferry service connect across the Hudson River with Manhattan. Redevelopment of the Jersey City waterfront has made the city one of the largest centers of banking and finance in the United States and has led to the district and city being nicknamed Wall Street West. Jersey City\\'s proximity to Manhattan and its own financially based economy have propelled apartment rents in the city to some of the highest in the United States.\\n\\n\\n== History ==\\n\\n\\n=== Lenape and New Netherland ===\\n\\nThe land that is now Jersey City was inhabited by the Lenape, a collection of Native American tribes (later called Delaware Indian). In 1609, Henry Hudson, seeking an alternate route to East Asia, anchored his small vessel Halve Maen (English: Half Moon) at Sandy Hook, Harsimus Cove and Weehawken Cove, and elsewhere along what was later named the North River. After spending nine days surveying the area and meeting its inhabitants, he sailed as far north as Albany. The contemporary flag of the city is a variation on the Prince\\'s Flag from the Netherlands. The stripes are blue, white and yellow, with the center of the flag showing the city seal, depicting Hudson\\'s ship, the Half Moon, and other modern vessels.\\nBy 1621, the Dutch West India Company was organized to manage this new territory and in June 1623, New Netherland became a Dutch province, with headquarters in New Amsterdam. Michael Reyniersz Pauw received a land grant as patroon on the condition that he would establish a settlement of not fewer than fifty persons within four years. He chose the west bank of the Hudson River and purchased the land from the Lenape. This grant is dated November 22, 1630, and is the earliest known conveyance for what are now Hoboken and Jersey City. Pauw, however, was an absentee landlord who neglected to populate the area and was obliged to sell his holdings back to the Company in 1633. That year, a house was built at Communipaw for Jan Evertsen Bout, superintendent of the colony, which had been named Pavonia (the Latinized form of Pauw\\'s name, which means \"peacock\"). Shortly after, another house was built at Harsimus Cove and became the home of Cornelius Van Vorst, who had succeeded Bout as superintendent, and whose family would become influential in the development of the city. Relations with the Lenape deteriorated, in part because of the colonialist\\'s mismanagement and misunderstanding of the indigenous people, and led to series of raids and reprisals and the virtual destruction of the settlement on the west bank. During Kieft\\'s War, approximately eighty Lenapes were killed by the Dutch in a massacre at Pavonia on the night of February 25, 1643.\\nScattered communities of farmsteads characterized the Dutch settlements at Pavonia: Communipaw, Harsimus, Paulus Hook, Hoebuck, Awiehaken, Pamrapo, and other lands \"behind Kill van Kull\". The village of Bergen (located inside a palisaded garrison) was established on what is now Bergen Squ'),\n",
       " Document(metadata={'title': 'New Jersey Devils', 'summary': \"The New Jersey Devils are a professional ice hockey team based in Newark, New Jersey. The Devils compete in the National Hockey League (NHL) as a member of the Metropolitan Division in the Eastern Conference. The club was founded as the Kansas City Scouts in Kansas City, Missouri, in 1974. The Scouts moved to Denver in 1976 and became the Colorado Rockies. In 1982, they moved to East Rutherford, New Jersey, and took their current name, which is derived from the legendary Jersey Devil creature. For their first 25 seasons in New Jersey, the Devils were based at the Meadowlands Sports Complex in East Rutherford and played their home games at Brendan Byrne Arena (later renamed Continental Airlines Arena). Before the 2007–08 season, the team moved to Prudential Center in Newark. The Devils are owned and managed by Harris Blitzer Sports & Entertainment (HBSE), with founders Josh Harris and David Blitzer acquiring the team in 2013.\\nThe franchise was poor to mediocre in the eight years before moving to New Jersey, a pattern that continued during the first five years in New Jersey as they failed to make the Stanley Cup playoffs and never finished higher than fifth in their division, which had six teams at the time. Their fortunes began to turn around following the hiring of the president and general manager Lou Lamoriello in 1987. Under Lamoriello's stewardship, the Devils made the playoffs all but three times between 1988 and 2012, including 13 berths in a row from 1997 to 2010, and finished with a winning record every season from 1992–93 to 2009–10. They have won the Atlantic Division regular season title nine times, most recently in 2009–10, before transferring to the newly created Metropolitan Division as part of the NHL's realignment in 2013. The Devils have reached the Stanley Cup Finals five times, winning in 1994–95, 1999–2000 and 2002–03, and losing in 2000–01 and 2011–12. The Devils were known for their defense-first approach throughout their years of Cup contention, and were one of the teams credited with popularizing the neutral zone trap in the mid-1990s.\\nThe Devils have a rivalry with their cross-Hudson River neighbor, the New York Rangers, as well as a rivalry with the Philadelphia Flyers. The Devils are one of three NHL teams in the New York metropolitan area; the others are the Rangers and the New York Islanders. The Devils are one of four major professional sports teams that play their home games in New Jersey; the others are the National Football League's New York Giants and New York Jets, and the New York Red Bulls of Major League Soccer. Since the relocation of the New Jersey Nets to Brooklyn in 2012, the Devils have been the only major league team in any sport to bill themselves as representing the state of New Jersey.\", 'source': 'https://en.wikipedia.org/wiki/New_Jersey_Devils'}, page_content=\"The New Jersey Devils are a professional ice hockey team based in Newark, New Jersey. The Devils compete in the National Hockey League (NHL) as a member of the Metropolitan Division in the Eastern Conference. The club was founded as the Kansas City Scouts in Kansas City, Missouri, in 1974. The Scouts moved to Denver in 1976 and became the Colorado Rockies. In 1982, they moved to East Rutherford, New Jersey, and took their current name, which is derived from the legendary Jersey Devil creature. For their first 25 seasons in New Jersey, the Devils were based at the Meadowlands Sports Complex in East Rutherford and played their home games at Brendan Byrne Arena (later renamed Continental Airlines Arena). Before the 2007–08 season, the team moved to Prudential Center in Newark. The Devils are owned and managed by Harris Blitzer Sports & Entertainment (HBSE), with founders Josh Harris and David Blitzer acquiring the team in 2013.\\nThe franchise was poor to mediocre in the eight years before moving to New Jersey, a pattern that continued during the first five years in New Jersey as they failed to make the Stanley Cup playoffs and never finished higher than fifth in their division, which had six teams at the time. Their fortunes began to turn around following the hiring of the president and general manager Lou Lamoriello in 1987. Under Lamoriello's stewardship, the Devils made the playoffs all but three times between 1988 and 2012, including 13 berths in a row from 1997 to 2010, and finished with a winning record every season from 1992–93 to 2009–10. They have won the Atlantic Division regular season title nine times, most recently in 2009–10, before transferring to the newly created Metropolitan Division as part of the NHL's realignment in 2013. The Devils have reached the Stanley Cup Finals five times, winning in 1994–95, 1999–2000 and 2002–03, and losing in 2000–01 and 2011–12. The Devils were known for their defense-first approach throughout their years of Cup contention, and were one of the teams credited with popularizing the neutral zone trap in the mid-1990s.\\nThe Devils have a rivalry with their cross-Hudson River neighbor, the New York Rangers, as well as a rivalry with the Philadelphia Flyers. The Devils are one of three NHL teams in the New York metropolitan area; the others are the Rangers and the New York Islanders. The Devils are one of four major professional sports teams that play their home games in New Jersey; the others are the National Football League's New York Giants and New York Jets, and the New York Red Bulls of Major League Soccer. Since the relocation of the New Jersey Nets to Brooklyn in 2012, the Devils have been the only major league team in any sport to bill themselves as representing the state of New Jersey.\\n\\n\\n== History ==\\n\\n\\n=== Kansas City and Colorado ===\\n\\nIn 1972, the NHL announced plans to add two expansion teams, including one in Kansas City, Missouri, owned by a group headed by Edwin G. Thompson. The new team was officially named the Scouts in reference to Cyrus E. Dallin's statue of the same name which stands in that city's Penn Valley Park. In the team's inaugural season, 1974–75, the Scouts were forced to wait until the ninth game to play in Kansas City's Kemper Arena, and did not post a win until beating the Washington Capitals, their expansion brethren, in their tenth contest. With 41 points in their inaugural season, the Scouts finished last in the Smythe Division; only the Capitals had fewer points in the NHL. Kansas City fell to 36 points the following season, and had a 27-game win-less streak, three short of the NHL record, which was set when the 1980–81 Winnipeg Jets went 30 games without a win. The Scouts had difficulty drawing fans to home games, and National Hockey League Players' Association (NHLPA) leader Alan Eagleson publicly expressed concerns about whether Scouts players would be paid.\\nAfter two seasons in Kansas City, the franchise moved to Denver and was renamed the Colorado \"),\n",
       " Document(metadata={'title': 'Newark, New Jersey', 'summary': \"Newark ( NEW-ərk, locally: [nʊɹk]) is the most populous city in the U.S. state of New Jersey, the county seat of Essex County, and a principal city of the New York metropolitan area. As of the 2020 census, the city's population was 311,549. The Population Estimates Program calculated a population of 304,960 for 2023, making it the 66th-most populous municipality in the nation.\\nSettled in 1666 by Puritans from New Haven Colony, Newark is one of the oldest cities in the United States. Its location at the mouth of the Passaic River, where it flows into Newark Bay, has made the city's waterfront an integral part of the Port of New York and New Jersey. Port Newark–Elizabeth is the primary container shipping terminal of the busiest seaport on the U.S. East Coast. Newark Liberty International Airport was the first municipal commercial airport in the United States and has become one of the busiest.\\nSeveral companies are headquartered in Newark, including Prudential, PSEG, Panasonic Corporation of North America, Audible.com, IDT Corporation, Manischewitz, and AeroFarms. Higher education institutions in the city include the Newark campus of Rutgers University, which includes law and medical schools and the Rutgers Institute of Jazz Studies; University Hospital; the New Jersey Institute of Technology; and Seton Hall University's law school. Newark is a home to numerous governmental offices, largely concentrated at Government Center and the Essex County Government Complex. Cultural venues include the New Jersey Performing Arts Center, Newark Symphony Hall, the Prudential Center, The Newark Museum of Art, and the New Jersey Historical Society. Branch Brook Park is the oldest county park in the United States and is home to the nation's largest collection of cherry blossom trees, numbering over 5,000.\\nNewark is divided into five political wards (East, West, South, North and Central). The majority of Black residents reside in the South, Central, and West Wards of the city, while the North and East Wards are mostly populated by Latinos. Ras Baraka has served as mayor of Newark since 2014.\", 'source': 'https://en.wikipedia.org/wiki/Newark,_New_Jersey'}, page_content='Newark ( NEW-ərk, locally: [nʊɹk]) is the most populous city in the U.S. state of New Jersey, the county seat of Essex County, and a principal city of the New York metropolitan area. As of the 2020 census, the city\\'s population was 311,549. The Population Estimates Program calculated a population of 304,960 for 2023, making it the 66th-most populous municipality in the nation.\\nSettled in 1666 by Puritans from New Haven Colony, Newark is one of the oldest cities in the United States. Its location at the mouth of the Passaic River, where it flows into Newark Bay, has made the city\\'s waterfront an integral part of the Port of New York and New Jersey. Port Newark–Elizabeth is the primary container shipping terminal of the busiest seaport on the U.S. East Coast. Newark Liberty International Airport was the first municipal commercial airport in the United States and has become one of the busiest.\\nSeveral companies are headquartered in Newark, including Prudential, PSEG, Panasonic Corporation of North America, Audible.com, IDT Corporation, Manischewitz, and AeroFarms. Higher education institutions in the city include the Newark campus of Rutgers University, which includes law and medical schools and the Rutgers Institute of Jazz Studies; University Hospital; the New Jersey Institute of Technology; and Seton Hall University\\'s law school. Newark is a home to numerous governmental offices, largely concentrated at Government Center and the Essex County Government Complex. Cultural venues include the New Jersey Performing Arts Center, Newark Symphony Hall, the Prudential Center, The Newark Museum of Art, and the New Jersey Historical Society. Branch Brook Park is the oldest county park in the United States and is home to the nation\\'s largest collection of cherry blossom trees, numbering over 5,000.\\nNewark is divided into five political wards (East, West, South, North and Central). The majority of Black residents reside in the South, Central, and West Wards of the city, while the North and East Wards are mostly populated by Latinos. Ras Baraka has served as mayor of Newark since 2014.\\n\\n\\n== History ==\\n\\nNewark was settled in 1666 by Connecticut Puritans led by Robert Treat from the New Haven Colony. It was conceived as a theocratic assembly of the faithful, though this did not last for long as new settlers came with different ideas. On October 31, 1693, it was organized as a New Jersey township based on the Newark Tract, which was first purchased on July 11, 1667. Newark was granted a royal charter on April 27, 1713. It was incorporated on February 21, 1798, by the New Jersey Legislature\\'s Township Act of 1798, as one of New Jersey\\'s initial group of 104 townships. During its time as a township, portions were taken to form Springfield Township (April 14, 1794), Caldwell Township (February 16, 1798; now known as Fairfield Township), Orange Township (November 27, 1806), Bloomfield Township (March 23, 1812) and Clinton Township (April 14, 1834, remainder reabsorbed by Newark on March 5, 1902). Newark was reincorporated as a city on April 11, 1836, replacing Newark Township, based on the results of a referendum passed on March 18, 1836. The previously independent Vailsburg borough was annexed by Newark on January 1, 1905. In 1926, South Orange Township changed its name to Maplewood. As a result of this, a portion of Maplewood known as Ivy Hill was re-annexed to Newark\\'s Vailsburg.\\nThe name of the city is thought to derive from Newark-on-Trent, England, because of the influence of the original pastor, Abraham Pierson, who came from Yorkshire but may have ministered in Newark, Nottinghamshire. But Pierson is also supposed to have said that the community reflecting the new task at hand should be named \"New Ark\" for \"New Ark of the Covenant\" and some of the colonists saw it as \"New-Work\", the settlers\\' new work with God. Whatever the origins, the name was shortened to Newark, although references to the name \"New Ark\" are found in preserved letters w'),\n",
       " Document(metadata={'title': 'New Brunswick, New Jersey', 'summary': \"New Brunswick is a city in and the county seat of Middlesex County, in the U.S. state of New Jersey. A regional commercial hub for central New Jersey, the city is both a college town (the home of Rutgers University–New Brunswick, the state's largest university) and a commuter town for residents commuting to New York City within the New York metropolitan area. New Brunswick is on the Northeast Corridor rail line, 27 miles (43 km) southwest of Manhattan. The city is located on the southern banks of the Raritan River in the heart of the Raritan Valley region.\\nAs of the 2020 United States census, the city's population was 55,266, an increase of 85 (+0.2%) from the 2010 census count of 55,181, which in turn reflected an increase of 6,608 (+13.6%) from the 48,573 counted in the 2000 census. The Census Bureau's Population Estimates Program calculated a population of 55,846 for 2023, making it the 719th-most populous municipality in the nation. Due to the concentration of medical facilities in the area, including Rutgers Robert Wood Johnson University Hospital and medical school, and Saint Peter's University Hospital, New Brunswick is known as both the Hub City and the Healthcare City. The corporate headquarters and production facilities of several global pharmaceutical companies are situated in the city, including Johnson & Johnson and Bristol Myers Squibb. New Brunswick has evolved into a major center for the sciences, arts, and cultural activities. Downtown New Brunswick is developing a growing skyline, filling in with new high-rise towers.\\nNew Brunswick is noted for its ethnic diversity. At one time, one-quarter of the Hungarian population of New Jersey resided in the city, and in the 1930s one out of three city residents was Hungarian. The Hungarian community continues as a cohesive community, with the 3,200 Hungarian residents accounting for 8% of the population of New Brunswick in 1992. Growing Asian and Hispanic communities have developed around French Street near Robert Wood Johnson University Hospital.\", 'source': 'https://en.wikipedia.org/wiki/New_Brunswick,_New_Jersey'}, page_content=\"New Brunswick is a city in and the county seat of Middlesex County, in the U.S. state of New Jersey. A regional commercial hub for central New Jersey, the city is both a college town (the home of Rutgers University–New Brunswick, the state's largest university) and a commuter town for residents commuting to New York City within the New York metropolitan area. New Brunswick is on the Northeast Corridor rail line, 27 miles (43 km) southwest of Manhattan. The city is located on the southern banks of the Raritan River in the heart of the Raritan Valley region.\\nAs of the 2020 United States census, the city's population was 55,266, an increase of 85 (+0.2%) from the 2010 census count of 55,181, which in turn reflected an increase of 6,608 (+13.6%) from the 48,573 counted in the 2000 census. The Census Bureau's Population Estimates Program calculated a population of 55,846 for 2023, making it the 719th-most populous municipality in the nation. Due to the concentration of medical facilities in the area, including Rutgers Robert Wood Johnson University Hospital and medical school, and Saint Peter's University Hospital, New Brunswick is known as both the Hub City and the Healthcare City. The corporate headquarters and production facilities of several global pharmaceutical companies are situated in the city, including Johnson & Johnson and Bristol Myers Squibb. New Brunswick has evolved into a major center for the sciences, arts, and cultural activities. Downtown New Brunswick is developing a growing skyline, filling in with new high-rise towers.\\nNew Brunswick is noted for its ethnic diversity. At one time, one-quarter of the Hungarian population of New Jersey resided in the city, and in the 1930s one out of three city residents was Hungarian. The Hungarian community continues as a cohesive community, with the 3,200 Hungarian residents accounting for 8% of the population of New Brunswick in 1992. Growing Asian and Hispanic communities have developed around French Street near Robert Wood Johnson University Hospital.\\n\\n\\n== History ==\\n\\n\\n=== Etymology ===\\nThe area around present-day New Brunswick was first inhabited by the Lenape Native Americans, whose Minisink Trail intersected the Raritan River and followed a route that would be taken by later colonial roads. The first European settlement at the site of New Brunswick was made in 1681. The settlement here was called Prigmore's Swamp (1681–1697), then known as Inian's Ferry (1691–1714). In 1714, the settlement was given the name New Brunswick, after the city of Braunschweig (Brunswick in Low German), in the state of Lower Saxony, now located in Germany. Braunschweig was an influential and powerful city in the Hanseatic League and was an administrative seat for the Duchy of Hanover. Shortly after the first settlement of New Brunswick in colonial New Jersey, George, Duke of Brunswick-Lüneburg and Elector of Hanover, became King George I of Great Britain. Alternatively, the city gets its name from King George II of Great Britain, the Duke of Brunswick-Lüneburg.\\n\\n\\n=== Colonial and Early American periods ===\\nCentrally located between New York City and Philadelphia along an early thoroughfare known as the King's Highway and situated along the Raritan River, New Brunswick became an important hub for Colonial travelers and traders. New Brunswick was incorporated as a town in 1736 and chartered as a city in 1784. It was incorporated into a town in 1798 as part of the Township Act of 1798. It was occupied by the British in the winter of 1776–1777 during the Revolutionary War.\\nThe Declaration of Independence received one of its first public readings, by Colonel John Neilson in New Brunswick on July 9, 1776, in the days following its promulgation by the Continental Congress. A bronze statue marking the event was dedicated on July 9, 2017, in Monument Square, in front of the Heldrich Hotel.\\nThe Trustees of Queen's College (now Rutgers University), founded in 1766, voted by a margin of ten to seven in 177\"),\n",
       " Document(metadata={'title': 'List of counties in New Jersey', 'summary': \"There are 21 counties in the U.S. state of New Jersey. These counties together contain 564 municipalities, or administrative entities composed of clearly defined territory; 252 boroughs, 52 cities, 15 towns, 241 townships, and 4 villages. In New Jersey, a county is a local level of government between the state and municipalities. County government in New Jersey includes a Board of County Commissioners, sheriff, clerk, and surrogate (responsible for uncontested and routine probate), all of which are elected officials. Counties organized under the Optional County Charter Law may also have an elected county executive. Counties traditionally perform state-mandated duties such as the maintenance of jails, parks, and certain roads. The site of a county's administration and courts is called the county seat.\", 'source': 'https://en.wikipedia.org/wiki/List_of_counties_in_New_Jersey'}, page_content='There are 21 counties in the U.S. state of New Jersey. These counties together contain 564 municipalities, or administrative entities composed of clearly defined territory; 252 boroughs, 52 cities, 15 towns, 241 townships, and 4 villages. In New Jersey, a county is a local level of government between the state and municipalities. County government in New Jersey includes a Board of County Commissioners, sheriff, clerk, and surrogate (responsible for uncontested and routine probate), all of which are elected officials. Counties organized under the Optional County Charter Law may also have an elected county executive. Counties traditionally perform state-mandated duties such as the maintenance of jails, parks, and certain roads. The site of a county\\'s administration and courts is called the county seat.\\n\\n\\n== History ==\\n\\nNew Jersey was governed by two groups of proprietors as two distinct provinces, East Jersey and West Jersey, between 1674 and 1702. New Jersey\\'s first counties were created as administrative districts within each province, with East Jersey split in 1675 into Bergen, Essex, Middlesex and Monmouth counties, while West Jersey\\'s initial counties of Burlington and Salem date to 1681. The most recent county created in New Jersey is Union County, created in 1857 and named after the union of the United States when the Civil War was imminent. New Jersey\\'s county names derive from several sources, though most of its counties are named after place names in England and prominent leaders in the colonial and revolutionary periods. Bergen County is the most populous county—as of the 2010 Census—with 905,116 people, while Salem County is the least populous with 66,083 people.\\n\\n\\n== New Jersey legislature representation ==\\n\\nUntil the 1960s, the New Jersey Senate had 21 representatives, one from each county regardless of population. In the wake of the 1964 decision by the Supreme Court of the United States in Reynolds v. Sims, establishing the one man, one vote principle that state legislative districts must be approximately equal in size, David Friedland filed suit in New Jersey Supreme Court on behalf of two union leaders, challenging a system under which each county was represented by a single member in the New Jersey Senate. The court ruled unanimously that the existing system was unconstitutional, ordered that interim measures be established by statute for the 1965 legislative elections, and ordered that the needed constitutional changes to restructure the New Jersey Legislature to be in compliance with \"one man, one vote\" requirements be in place before elections took place in 1967. The senate unilaterally—by internal rule, not by statute—enacted a proposal whereby each senator\\'s vote would be weighted based on the population of the county represented,  under which Cape May County\\'s senator would receive one vote while the senator from Essex County would receive 19.1 votes, in direct relation to the ratio of residents between counties. The Supreme Court ruled unanimously that it was unconstitutional for the senate to adopt a weighted voting system unilaterally. In 1966, the constitution was amended to establish 40 districts statewide, each represented by one senator and two assembly members, without relation to county boundaries.\\n\\n\\n== FIPS code ==\\n\\nThe Federal Information Processing Standard (FIPS) code, used by the United States government to uniquely identify counties, is provided with each entry. FIPS codes are five-digit numbers; for New Jersey the codes start with 34 and are completed with the three-digit county code. The FIPS code for each county in the table links to census data for that county.\\n\\n\\n== List of counties ==\\n\\n\\n== See also ==\\n\\nList of townships in New Jersey\\nCounty courthouses in New Jersey\\nList of United States counties and county equivalents\\nMetropolitan statistical areas of New Jersey—each New Jersey county is included in a metropolitan statistical area as defined by the federal Office of Management and Bu'),\n",
       " Document(metadata={'title': 'Governor of New Jersey', 'summary': \"The governor of New Jersey is the head of government of the U.S. state of New Jersey. The office of governor is an elected position with a four-year term. There is a two consecutive term term limit, with no limitation on non-consecutive terms. The official residence of the governor is Drumthwacket, a mansion located in Princeton, New Jersey. The governor's office is located inside of the New Jersey State House in Trenton, making New Jersey notable as the executive's office is located in the same building as the legislature. New Jersey is also notable for being one of the few states in which the governor's official residence is not located in the state capital.\\nThe first and longest-serving governor of New Jersey was William Livingston, who served from August 31, 1776, to July 25, 1790. A. Harry Moore remains the longest-serving popularly elected governor. The current and 56th governor is Phil Murphy, a Democrat who assumed office on January 16, 2018.\", 'source': 'https://en.wikipedia.org/wiki/Governor_of_New_Jersey'}, page_content='The governor of New Jersey is the head of government of the U.S. state of New Jersey. The office of governor is an elected position with a four-year term. There is a two consecutive term term limit, with no limitation on non-consecutive terms. The official residence of the governor is Drumthwacket, a mansion located in Princeton, New Jersey. The governor\\'s office is located inside of the New Jersey State House in Trenton, making New Jersey notable as the executive\\'s office is located in the same building as the legislature. New Jersey is also notable for being one of the few states in which the governor\\'s official residence is not located in the state capital.\\nThe first and longest-serving governor of New Jersey was William Livingston, who served from August 31, 1776, to July 25, 1790. A. Harry Moore remains the longest-serving popularly elected governor. The current and 56th governor is Phil Murphy, a Democrat who assumed office on January 16, 2018.\\n\\n\\n== Role ==\\nThe governor is directly elected by the voters to become the political and ceremonial head of the state. The governor performs the executive functions of the state, and is not directly subordinate to the federal authorities. The governor assumes additional roles, such as being the commander-in-chief of the New Jersey National Guard forces (when they are not federalized).\\nUnlike many other states that have elections for some cabinet-level positions, under the New Jersey Constitution the governor and lieutenant governor are the only officials elected on a statewide basis. Much like the president of the United States, the governor appoints the entire cabinet, subject to confirmation by the New Jersey Senate. More importantly, under the New Jersey constitution, the governor appoints all superior court judges and county prosecutors, although this is done with strong consideration of the preferences of the individual state senators who represent the district where vacancies arise. The governor is also responsible for appointing two constitutionally created officers, the New Jersey attorney general and the secretary of state of New Jersey, with the approval of the Senate.\\nAs amended in January 2002, state law allows for a maximum salary of $175,000. Phil Murphy has stated that he will accept the full salary. Jon Corzine accepted a token salary of $1 per year as governor. Previous governor Jim McGreevey received an annual salary of $157,000, a 10% reduction of the maximum allowed, while Chris Christie, Murphy\\'s immediate predecessor, accepted the full gubernatorial salary.\\nThe governor has a full-time protective security detail from the Executive Protection Unit of the New Jersey State Police while in office. A former governor is entitled to a one-person security detail from the New Jersey State Police for up to six months after leaving office.\\n\\n\\n== Oath of office ==\\n\"I, [name of governor], elected governor of the state of New Jersey, do solemnly promise and swear that I will diligently, faithfully and to the best of my knowledge, execute the said office in conformity with the powers delegated to me; and that I will to the utmost of my skill and ability, promote the peace and prosperity and maintain the lawful rights of the said state. So help me God.\"\\n\\n\\n== Lieutenant governor ==\\n\\nOn November 8, 2005, voters passed an amendment to the New Jersey State Constitution that created the position of Lieutenant Governor of New Jersey, effective with the 2009 elections. Before this amendment was passed, the President of the New Jersey Senate would simultaneously also serve as governor whenever the office of governor was vacant. This dual position was more powerful than that of an elected governor, as the individual would have a major role in both the legislative and executive branches.\\nThe amendment was prompted by New Jersey State Senate President Richard Codey serving as Governor of New Jersey in January 2002 and again from November 2004 to January 2006 after the resignations of ele'),\n",
       " Document(metadata={'title': 'Trenton, New Jersey', 'summary': \"Trenton is the capital city of the U.S. state of New Jersey and the county seat of Mercer County. It was the capital of the United States from November 1 until December 24, 1784. Trenton and Princeton are the two principal cities of the Trenton–Princeton metropolitan statistical area, which encompasses those cities and all of Mercer County for statistical purposes and constitutes part of the New York combined statistical area by the U.S. Census Bureau. However, Trenton directly borders the Philadelphia metropolitan area to its west, and the city was part of the Philadelphia combined statistical area from 1990 until 2000.\\nIn the 2020 United States census, Trenton was the state's 10th-most-populous municipality, with a population of 90,871, an increase of 5,958 (+7.0%) from the 2010 census count of 84,913, which in turn had reflected a decline of 490 (−0.6%) from the 85,403 counted in the 2000 census. The Census Bureau's Population Estimates Program calculated that the city's population was 89,661 in 2022, ranking the city the 382nd-most-populous in the country. Trenton is the only city in New Jersey that serves three separate commuter rail transit systems (Amtrak, NJ Transit, and SEPTA), and the city has encouraged a spate of transit-oriented development since 2010.\\nTrenton dates back at least to June 3, 1719, when mention was made of a constable being appointed for Trenton while the area was still part of Hunterdon County. Boundaries were recorded for Trenton Township as of March 2, 1720. A courthouse and jail were constructed in Trenton around 1720, and the Freeholders of Hunterdon County met annually in Trenton.\\nAbraham Hunt was appointed in 1764 as Trenton's first Postmaster. On November 25, 1790, Trenton became New Jersey's capital, and by November 13, 1792, the City of Trenton was formed within Trenton Township. Trenton Township was incorporated as one of New Jersey's initial group of 104 townships by an act of the New Jersey Legislature on February 21, 1798. On February 22, 1834, portions of Trenton Township were taken to form Ewing Township. The remaining portion of Trenton Township was absorbed by the city on April 10, 1837. A series of annexations took place over a 50-year period with the city absorbing South Trenton (April 14, 1851), portions of Nottingham Township (April 14, 1856), Chambersburg Township and Millham Township (both on March 30, 1888), and Wilbur (February 28, 1898). Portions of Ewing Township and Hamilton Township were annexed to Trenton on March 23, 1900.\", 'source': 'https://en.wikipedia.org/wiki/Trenton,_New_Jersey'}, page_content='Trenton is the capital city of the U.S. state of New Jersey and the county seat of Mercer County. It was the capital of the United States from November 1 until December 24, 1784. Trenton and Princeton are the two principal cities of the Trenton–Princeton metropolitan statistical area, which encompasses those cities and all of Mercer County for statistical purposes and constitutes part of the New York combined statistical area by the U.S. Census Bureau. However, Trenton directly borders the Philadelphia metropolitan area to its west, and the city was part of the Philadelphia combined statistical area from 1990 until 2000.\\nIn the 2020 United States census, Trenton was the state\\'s 10th-most-populous municipality, with a population of 90,871, an increase of 5,958 (+7.0%) from the 2010 census count of 84,913, which in turn had reflected a decline of 490 (−0.6%) from the 85,403 counted in the 2000 census. The Census Bureau\\'s Population Estimates Program calculated that the city\\'s population was 89,661 in 2022, ranking the city the 382nd-most-populous in the country. Trenton is the only city in New Jersey that serves three separate commuter rail transit systems (Amtrak, NJ Transit, and SEPTA), and the city has encouraged a spate of transit-oriented development since 2010.\\nTrenton dates back at least to June 3, 1719, when mention was made of a constable being appointed for Trenton while the area was still part of Hunterdon County. Boundaries were recorded for Trenton Township as of March 2, 1720. A courthouse and jail were constructed in Trenton around 1720, and the Freeholders of Hunterdon County met annually in Trenton.\\nAbraham Hunt was appointed in 1764 as Trenton\\'s first Postmaster. On November 25, 1790, Trenton became New Jersey\\'s capital, and by November 13, 1792, the City of Trenton was formed within Trenton Township. Trenton Township was incorporated as one of New Jersey\\'s initial group of 104 townships by an act of the New Jersey Legislature on February 21, 1798. On February 22, 1834, portions of Trenton Township were taken to form Ewing Township. The remaining portion of Trenton Township was absorbed by the city on April 10, 1837. A series of annexations took place over a 50-year period with the city absorbing South Trenton (April 14, 1851), portions of Nottingham Township (April 14, 1856), Chambersburg Township and Millham Township (both on March 30, 1888), and Wilbur (February 28, 1898). Portions of Ewing Township and Hamilton Township were annexed to Trenton on March 23, 1900.\\n\\n\\n== History ==\\n\\nThe earliest known inhabitants of the area that is today Trenton were the Lenape Native Americans, specifically the Axion band who were the largest tribe on the Delaware River in the mid-17th century.\\nThe first European settlement in what would become Trenton was established by Quakers in 1679, in the region then called the Falls of the Delaware, led by Mahlon Stacy from Handsworth, Sheffield, England. Quakers were being persecuted in England at this time, and North America provided an opportunity to exercise their religious freedom.\\nBy 1719, the town adopted the name \"Trent-towne\", after William Trent, one of its leading landholders who purchased much of the surrounding land from Stacy\\'s family. This name was later shortened to \"Trenton\".\\nThe first municipal boundaries were recorded on March 2, 1720, and a courthouse and jail were constructed around the same time.\\nIn 1758, the Old Barracks were built to house British soldiers during the French and Indian War. On January 19, 1764, Benjamin Franklin, Postmaster General of the colonies, appointed Abraham Hunt, a Lieutenant Colonel in the New Jersey Hunterdon County militia and prominent merchant in Trenton, as the city\\'s first postmaster. Hunt was again appointed Trenton\\'s postmaster on October 13, 1775, shortly after the American Revolutionary War broke out.\\nDuring the American Revolutionary War, Trenton was the site of the Battle of Trenton. On December 25–26, 1776, George Washingto'),\n",
       " Document(metadata={'title': 'Province of New Jersey', 'summary': 'The Province of New Jersey was one of the Middle Colonies of Colonial America and became the U.S. state of New Jersey in 1776. The province had originally been settled by Europeans as part of New Netherland but came under English rule after the surrender of Fort Amsterdam in 1664, becoming a proprietary colony. The English renamed the province after the island of Jersey in the English Channel. The Dutch Republic reasserted control for a brief period in 1673–1674. After that it consisted of two political divisions, East Jersey and West Jersey, until they were united as a royal colony in 1702. The original boundaries of the province were slightly larger than the current state, extending into a part of the present state of New York, until the border was finalized in 1773.', 'source': 'https://en.wikipedia.org/wiki/Province_of_New_Jersey'}, page_content=\"The Province of New Jersey was one of the Middle Colonies of Colonial America and became the U.S. state of New Jersey in 1776. The province had originally been settled by Europeans as part of New Netherland but came under English rule after the surrender of Fort Amsterdam in 1664, becoming a proprietary colony. The English renamed the province after the island of Jersey in the English Channel. The Dutch Republic reasserted control for a brief period in 1673–1674. After that it consisted of two political divisions, East Jersey and West Jersey, until they were united as a royal colony in 1702. The original boundaries of the province were slightly larger than the current state, extending into a part of the present state of New York, until the border was finalized in 1773.\\n\\n\\n== Background ==\\n\\nThe Province of New Jersey was originally settled in the 1610s as part of the colony of New Netherland. The surrender of Fort Amsterdam in September 1664 gave control over the entire Mid-Atlantic region to the English as part of the Second Anglo-Dutch War. The English justified the seizure by claiming that John Cabot, an Italian under the sponsorship of the English King Henry VII, had been the first to discover the place, but it was probably to assert control over the profitable North Atlantic trade. Director-General of New Netherland Peter Stuyvesant, unable to rouse a military defense, relinquished control of the colony and was able in the articles of transfer to secure guarantees for property rights, laws of inheritance, and freedom of religion. After the surrender, Richard Nicolls took the position as deputy-governor of New Amsterdam and the rest of New Netherland, including those settlements on the west side of the North River (Hudson River) known as Bergen and those along the Delaware River that had been New Sweden.\\n\\n\\n== Proprietary government ==\\n\\nIn March 1664, King Charles II granted his brother, James, the Duke of York, a Royal colony that covered New Netherlands and present-day Maine. This charter also included parts of present-day Massachusetts, which conflicted with that colony's charter. The charter allowed James traditional propriety rights and imposed few restrictions upon his powers. In general terms, the charter was equivalent to a conveyance of land conferring on him the right of possession, control, and government, subject only to the limitation that the government must be consistent with the laws of England. The Duke of York never visited his colony and exercised little direct control of it. He elected to administer his government through governors, councils, and other officers appointed by himself. No provision was made for an elected assembly.\\n\\nLater in 1664, the Duke of York gave the part of his new possessions between the Hudson River and the Delaware River to Sir George Carteret in exchange for settlement of a debt. The territory was named after the island of Jersey, Carteret's ancestral home. The other section of New Jersey was sold to Lord Berkeley of Stratton, who was a close friend of the Duke. As a result, Carteret and Berkeley became the two English lords proprietors of New Jersey. The two proprietors of New Jersey attempted to attract more settlers to move to the province by granting sections of lands to settlers and by passing the Concession and Agreement, a 1665 document that granted religious freedom to all inhabitants of New Jersey; under the British government, there was no such religious freedom as the Church of England was the state church. In return for the land, the settlers were supposed to pay annual fees known as quit-rents.\\nIn 1665, Philip Carteret became the first governor of New Jersey, appointed by the two proprietors. He selected Elizabeth as the capital of New Jersey. Immediately, Carteret issued several additional grants of land to landowners. Towns were started and charters granted to Newark (1666), Piscataway (1666), Bergen (1668), Middletown (1693), Woodbridge (1669), and Shrewsbury.\\nThe i\"),\n",
       " Document(metadata={'title': 'Paterson, New Jersey', 'summary': \"Paterson ( PAT-ər-sən) is the largest city in and the county seat of Passaic County, in the U.S. state of New Jersey. As of the 2020 United States census, Paterson was the state's third-most-populous municipality, with a population of 159,732. an increase of 13,533 (+9.3%) from the 2010 census count of 146,199, which in turn reflected a decline of 3,023 (-2.0%) from the 149,222 counted in the 2000 census. The Census Bureau's Population Estimates Program calculated a population of 156,452 for 2023, making it the 168th-most populous municipality in the nation.\\nA prominent mill town within the New York–New Jersey metropolitan area, Paterson has been known as Silk City for its once-dominant role in silk production during the latter half of 19th century. It has since evolved into a major destination for Hispanic immigrants as well as for immigrants from Turkey, the Arab world, and South Asia. Paterson has the nation's second-largest per capita Muslim population.\", 'source': 'https://en.wikipedia.org/wiki/Paterson,_New_Jersey'}, page_content='Paterson ( PAT-ər-sən) is the largest city in and the county seat of Passaic County, in the U.S. state of New Jersey. As of the 2020 United States census, Paterson was the state\\'s third-most-populous municipality, with a population of 159,732. an increase of 13,533 (+9.3%) from the 2010 census count of 146,199, which in turn reflected a decline of 3,023 (-2.0%) from the 149,222 counted in the 2000 census. The Census Bureau\\'s Population Estimates Program calculated a population of 156,452 for 2023, making it the 168th-most populous municipality in the nation.\\nA prominent mill town within the New York–New Jersey metropolitan area, Paterson has been known as Silk City for its once-dominant role in silk production during the latter half of 19th century. It has since evolved into a major destination for Hispanic immigrants as well as for immigrants from Turkey, the Arab world, and South Asia. Paterson has the nation\\'s second-largest per capita Muslim population.\\n\\n\\n== History ==\\n\\nThe area of Paterson was inhabited by the Algonquian-speaking Native American Acquackanonk tribe of the Lenape, also known as the Delaware Indians. The land was known as the Lenapehoking. The Dutch claimed the land as New Netherlands, followed by the British as the Province of New Jersey.\\n\\n\\n=== Establishment ===\\nIn 1791, Alexander Hamilton (1755/57–1804), first United States Secretary of the Treasury,  helped found the Society for Establishing Useful Manufactures (S.U.M.), which helped encourage the harnessing of energy from the Great Falls of the Passaic River to secure economic independence from British manufacturers. The society founded Paterson, which became the cradle of the Industrial Revolution in America. Paterson was named for William Paterson, statesman, signer of the Constitution and Governor of New Jersey, who signed the 1792 charter that established the Town of Paterson.\\nArchitect, engineer, and city planner Pierre L\\'Enfant (1754–1825), who had earlier developed the initial plans for Washington, D.C., was the first planner for the S.U.M. project. His plan proposed to harness the power of the Great Falls through a channel in the rock and an aqueduct. The society\\'s directors felt he was taking too long and was over budget, and he was replaced by Peter Colt, who used a less complicated reservoir system to get the water flowing to factories in 1794. Eventually, Colt\\'s system developed some problems and a scheme resembling L\\'Enfant\\'s original plan was used after 1846.\\nPaterson was originally formed as a township from portions of Acquackanonk Township on April 11, 1831, while the area was still part of Essex County. It became part of the newly created Passaic County on February 7, 1837, and was incorporated as a city on April 14, 1851, based on the results of a referendum held that day. The city was reincorporated on March 14, 1861.\\n\\n\\n=== Industrial growth ===\\nThe 77-foot-high (23 m) Great Falls and a system of water raceways that harnessed the falls\\' power provided power for the mills in the area until 1914 and fostered growth of the city. The district originally included dozens of mill buildings and other manufacturing structures associated with the textile industry and, later, the firearms, silk, and railroad locomotive manufacturing industries. In the latter half of the 19th century, silk production became the dominant industry and formed the basis of Paterson\\'s most prosperous period, earning it the nickname \"Silk City.\"\\nIn 1835, Samuel Colt began producing firearms in Paterson, but within a few years he moved his business to Hartford, Connecticut. Later in the 19th century, Paterson was the site of early experiments with submarines by Irish-American inventor John Philip Holland. Two of Holland\\'s early models—one found at the bottom of the Passaic River—are on display in the Paterson Museum, housed in the former Rogers Locomotive and Machine Works near the Passaic Falls.\\nBehind Newark and New York, the brewing industry was booming in Paterson in'),\n",
       " Document(metadata={'title': 'List of municipalities in New Jersey', 'summary': 'New Jersey is a state located in the Northeastern United States. According to the 2020 United States Census, New Jersey is the 11th most populous state with 9,288,994 inhabitants but the fifth smallest by land area, spanning 7,354.76 square miles (19,048.7 km2). As of 2024, New Jersey is divided into 21 counties and contains 564 municipalities consisting of five types: 253 boroughs, 52 cities, 15 towns, 240 townships, and four villages. The largest municipality by population in New Jersey is Newark, with 311,549 residents, whereas the smallest is Walpack Township, with seven residents. New Jersey is the most populous U.S. state with no cities ranked in the top 50 most populous United States cities, with the next most populous being South Carolina.\\nAs in most Northeastern states, all territories within New Jersey are incorporated.', 'source': 'https://en.wikipedia.org/wiki/List_of_municipalities_in_New_Jersey'}, page_content=\"New Jersey is a state located in the Northeastern United States. According to the 2020 United States Census, New Jersey is the 11th most populous state with 9,288,994 inhabitants but the fifth smallest by land area, spanning 7,354.76 square miles (19,048.7 km2). As of 2024, New Jersey is divided into 21 counties and contains 564 municipalities consisting of five types: 253 boroughs, 52 cities, 15 towns, 240 townships, and four villages. The largest municipality by population in New Jersey is Newark, with 311,549 residents, whereas the smallest is Walpack Township, with seven residents. New Jersey is the most populous U.S. state with no cities ranked in the top 50 most populous United States cities, with the next most populous being South Carolina.\\nAs in most Northeastern states, all territories within New Jersey are incorporated.\\n\\n\\n== List of municipalities ==\\n\\n\\tLargest municipalities in New Jersey by population\\n\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\n\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\n\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\n\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\n\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\n\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\n\\n\\n== See also ==\\nList of census-designated places in New Jersey\\nList of counties in New Jersey\\n\\n\\n== Notes ==\\n\\n\\n== References ==\\n\\n\\n== External links ==\\nThe 10 tiniest towns in New Jersey (they're really small) November 1, 2016\"),\n",
       " Document(metadata={'title': 'New Jersey Turnpike', 'summary': \"The New Jersey Turnpike (NJTP) is a system of controlled-access highways in the U.S. state of New Jersey. The turnpike is maintained by the New Jersey Turnpike Authority. The 117.2-mile (188.6 km) mainline's southern terminus is at the Delaware Memorial Bridge on I-295 in Pennsville. Its northern terminus is at an interchange with I-80 and US 46 in Ridgefield Park. Construction of the mainline, from concept to completion, took a total of 22 months between 1950 and 1951. It was opened to traffic on November 5, 1951, between its southern terminus and exit 10.\\nThe turnpike is a major thoroughfare providing access to various localities in New Jersey, and the toll road provides a direct bypass southeast of Philadelphia for long-distance travelers between New York City and Washington, D.C. According to the International Bridge, Tunnel and Turnpike Association, the turnpike is the nation's sixth-busiest toll road, and one of the most heavily traveled highways in the nation.\\nThe northern part of the mainline turnpike, along with the entirety of its extensions and spurs, is a part of the Interstate Highway System designated as I-95 between exit 6 in Mansfield Township, and its northern end near New York City. South of exit 6, it has the unsigned Route 700 designation. There are three extensions and two spurs, including the Newark Bay Extension at exit 14, which carries I-78; the Pennsylvania Turnpike Extension, officially known as the Pearl Harbor Memorial Turnpike Extension, at exit 6, which carries I-95 off the mainline turnpike; the Eastern Spur and the Western Spur, which split traffic between Newark and Ridgefield; and the I-95 Extension, which continues the mainline to the George Washington Bridge in Fort Lee. All segments (excluding the I-95 Extension) are toll roads.\\nThe route is divided into four roadways between exit 6 and exit 14. The inner lanes are generally restricted to cars, while the outer lanes are open to cars, trucks, and buses. The turnpike has 12-foot-wide (3.7 m) lanes, 10-foot-wide (3.0 m) shoulders, and 13 of the highway's service areas are named after notable New Jersey residents. The Interstate Highway System took some of its design guidelines from those of the turnpike. The turnpike has been referenced many times in music, film, and television.\", 'source': 'https://en.wikipedia.org/wiki/New_Jersey_Turnpike'}, page_content=\"The New Jersey Turnpike (NJTP) is a system of controlled-access highways in the U.S. state of New Jersey. The turnpike is maintained by the New Jersey Turnpike Authority. The 117.2-mile (188.6 km) mainline's southern terminus is at the Delaware Memorial Bridge on I-295 in Pennsville. Its northern terminus is at an interchange with I-80 and US 46 in Ridgefield Park. Construction of the mainline, from concept to completion, took a total of 22 months between 1950 and 1951. It was opened to traffic on November 5, 1951, between its southern terminus and exit 10.\\nThe turnpike is a major thoroughfare providing access to various localities in New Jersey, and the toll road provides a direct bypass southeast of Philadelphia for long-distance travelers between New York City and Washington, D.C. According to the International Bridge, Tunnel and Turnpike Association, the turnpike is the nation's sixth-busiest toll road, and one of the most heavily traveled highways in the nation.\\nThe northern part of the mainline turnpike, along with the entirety of its extensions and spurs, is a part of the Interstate Highway System designated as I-95 between exit 6 in Mansfield Township, and its northern end near New York City. South of exit 6, it has the unsigned Route 700 designation. There are three extensions and two spurs, including the Newark Bay Extension at exit 14, which carries I-78; the Pennsylvania Turnpike Extension, officially known as the Pearl Harbor Memorial Turnpike Extension, at exit 6, which carries I-95 off the mainline turnpike; the Eastern Spur and the Western Spur, which split traffic between Newark and Ridgefield; and the I-95 Extension, which continues the mainline to the George Washington Bridge in Fort Lee. All segments (excluding the I-95 Extension) are toll roads.\\nThe route is divided into four roadways between exit 6 and exit 14. The inner lanes are generally restricted to cars, while the outer lanes are open to cars, trucks, and buses. The turnpike has 12-foot-wide (3.7 m) lanes, 10-foot-wide (3.0 m) shoulders, and 13 of the highway's service areas are named after notable New Jersey residents. The Interstate Highway System took some of its design guidelines from those of the turnpike. The turnpike has been referenced many times in music, film, and television.\\n\\n\\n== Route description ==\\n\\nThe mainline of the New Jersey Turnpike splits from I-295 in Pennsville Township and runs along a north-northeast route to I-80 and US 46 in Ridgefield Park, where it continues north as I-95. It is designated Route 700, an unsigned route, from exit 1 (Delaware Memorial Bridge) to exit 6, and as I-95 from exit 6 (Mansfield Township) to exit 18 (Secaucus–Carlstadt). The number of lanes ranges from four lanes south of exit 4 (Mount Laurel), six lanes between exit 4 and exit 6 (Mansfield Township), 12 lanes between exit 6 and exit 11 (Woodbridge Township), and 14 lanes between exit 11 and exit 14 (Newark). The default speed limit is 65 miles per hour (105 km/h) between the southern terminus and milepost 97, and 55 miles per hour (89 km/h) from there to the northern terminus. The Newark Bay Extension carries a 50-mile-per-hour (80 km/h) limit. The turnpike has variable speed limit signs allowing for the limit to be lowered temporarily during unusual road conditions.\\nBefore the advent of the Interstate Highway System, the entire Turnpike was designated by the New Jersey Department of Transportation (NJDOT) as Route 700. The Pearl Harbor Memorial Turnpike Extension was Route 700P, and the Newark Bay Extension was Route 700N. None of these state highway designations have been signed. The entire length of the New Jersey Turnpike is part of the National Highway System, a network of roads important to the country's economy, defense, and mobility.\\n\\n\\n=== Pennsville Township to Springfield Township ===\\n\\nThe turnpike's southern terminus lies at the Delaware Memorial Bridge in Pennsville Township, running concurrently with I-295 and US 40. Immediately after\"),\n",
       " Document(metadata={'title': 'Montclair, New Jersey', 'summary': \"Montclair is a township in Essex County in the U.S. state of New Jersey. Situated on the cliffs of the Watchung Mountains, Montclair is a commercial and cultural hub of North Jersey and a diverse bedroom community of New York City within the New York metropolitan area. The township is the home of Montclair State University, the state's second-largest university.\\nAs of the 2020 United States census, the township's population was 40,921, an increase of 3,252 (+8.6%) from the 2010 census count of 37,669, which in turn reflected a decline of 1,308 (−3.4%) from the 38,977 counted in the 2000 census. As of 2010, it was the 60th-most-populous municipality in New Jersey.\", 'source': 'https://en.wikipedia.org/wiki/Montclair,_New_Jersey'}, page_content='Montclair is a township in Essex County in the U.S. state of New Jersey. Situated on the cliffs of the Watchung Mountains, Montclair is a commercial and cultural hub of North Jersey and a diverse bedroom community of New York City within the New York metropolitan area. The township is the home of Montclair State University, the state\\'s second-largest university.\\nAs of the 2020 United States census, the township\\'s population was 40,921, an increase of 3,252 (+8.6%) from the 2010 census count of 37,669, which in turn reflected a decline of 1,308 (−3.4%) from the 38,977 counted in the 2000 census. As of 2010, it was the 60th-most-populous municipality in New Jersey.\\n\\n\\n== History ==\\nMontclair was initially formed as a township on April 15, 1868, from portions of Bloomfield Township, so that a second railroad could be built to Montclair. After a referendum held on February 21, 1894, Montclair was reincorporated as a town, effective February 24, 1894. It derives its name from the French mont clair, meaning \"clear mountain\" or \"bright mountain.\"\\nIn 1980, after multiple protests filed by Montclair officials regarding inequities built into the federal revenue-sharing system, Montclair passed a referendum changing its name to the \"Township of Montclair,\" becoming the third of more than a dozen Essex County municipalities to reclassify themselves as townships to take advantage of federal revenue sharing policies that allocated townships a greater share of government aid to municipalities on a per capita basis.\\nBefore cannabis was legalized for sale for both medical and recreational use in 2022, the state\\'s first marijuana dispensary opened in Montclair in December 2012, joining Bellmawr, Cranbury, Egg Harbor Township, and Woodbridge Township as one of the five municipalities that had authorized the sale of medical cannabis.\\n\\n\\n== Geography ==\\n\\nAccording to the U.S. Census Bureau, the township had a total area of 6.25 square miles (16.17 km2), including 6.24 square miles (16.16 km2) of land and 0.01 square miles (0.02 km2) of water (0.11%).\\nMontclair is on the east side of the First Mountain of the Watchung Mountains. Some higher locations in the township provide excellent views of the surrounding area and of the New York City skyline about 12 miles (19 km) away.\\nNamed localities in the township include Church Street, Frog Hollow, South End, Upper Montclair, and Watchung Plaza.\\nMontclair is split between two ZIP Codes. The central and southern parts of the township are designated 07042. Upper Montclair lies north of Watchung Avenue and has a separate ZIP code, 07043. Because the ZIP codes do not exactly match municipal boundaries, a few homes near the borders with neighboring towns fall into the ZIP codes for those communities. A few homes in some adjoining municipalities use one of the two ZIP codes assigned to Montclair, as does HackensackUMC Mountainside (07042, formerly known as Mountainside Hospital), whose campus straddles the border with Glen Ridge. Small areas in the southeast of the township fall into the Glen Ridge ZIP code 07028.\\nSeveral streams flow eastward through Montclair: Toney\\'s Brook in the center, Nishuane Brook in the southeast, Wigwam Brook in the southwest, Pearl Brook in the northwest, and Yantacaw Brook in the northeast—all in the Passaic River watershed. Yantacaw and Toney\\'s brooks are dammed in parks to create ponds. Wigwam, Nishuane, and Toney\\'s brooks flow into the Second River, and the others flow into the Third River. Montclair lies just north of the northernmost extent of the Rahway River watershed.\\nMontclair borders the municipalities of Bloomfield, Cedar Grove, Glen Ridge, Orange, Verona, and West Orange in Essex County; and Clifton and Little Falls in Passaic County.\\nThe southern border of Montclair is a straight line between Eagle Rock, on the ridge of the First Watchung Mountain, and the point where Orange Road begins at the foot of Ridgewood Avenue. The eastern border is roughly a straight line between'),\n",
       " Document(metadata={'title': 'Camden, New Jersey', 'summary': 'Camden is a city in Camden County, in the U.S. state of New Jersey. It is part of the Delaware Valley metropolitan region.  The city was incorporated on February 13, 1828. Camden has been the county seat of Camden County since the county\\'s formation on March 13, 1844. The city derives its name from Charles Pratt, 1st Earl Camden. Camden is made up of over 20 neighborhoods, and is part of the South Jersey region of the state. \\nThe initial growth of Camden industrially is often credited to the “big three” employers of Camden: RCA Victor, Campbell\\'s Soup Company and New York Shipbuilding Corporation.  As workers went from disorganized to unionized, labor costs increased locally to a point where the \"big three\" felt compelled to move away from Camden in the mid-to-late-20th century as they could find cheaper workers elsewhere. Though the city has declined in recent decades since the decline of heavy industry in the area and whiteflight to the suburbs, the city has made efforts to revitalize itself through various infrastructure and community projects.\\nProjects such as the redevelopment of the waterfront area brought three tourist attractions to the area: the USS New Jersey, the Freedom Mortgage Pavilion and the Adventure Aquarium. The city is the home of Rutgers University–Camden, which was founded as the South Jersey Law School in 1926, and Cooper Medical School of Rowan University, which opened in 2012. Camden also houses both Cooper University Hospital and Virtua Our Lady of Lourdes Hospital. Camden County College and Rowan University also have campuses in downtown Camden. The \"eds and meds\" institutions account for roughly 45% of Camden\\'s total employment.\\nOnce known for violent crime, the restructuring of the police force in 2013 has been credited for the decrease in that number. As of January 2021, violent crime was down 46% from its high in the 1990s and at the lowest level since the 1960s. Overall crime reports in 2020 were down 74% compared to 1974, the first year of uniform crime-reporting in the city.', 'source': 'https://en.wikipedia.org/wiki/Camden,_New_Jersey'}, page_content='Camden is a city in Camden County, in the U.S. state of New Jersey. It is part of the Delaware Valley metropolitan region.  The city was incorporated on February 13, 1828. Camden has been the county seat of Camden County since the county\\'s formation on March 13, 1844. The city derives its name from Charles Pratt, 1st Earl Camden. Camden is made up of over 20 neighborhoods, and is part of the South Jersey region of the state. \\nThe initial growth of Camden industrially is often credited to the “big three” employers of Camden: RCA Victor, Campbell\\'s Soup Company and New York Shipbuilding Corporation.  As workers went from disorganized to unionized, labor costs increased locally to a point where the \"big three\" felt compelled to move away from Camden in the mid-to-late-20th century as they could find cheaper workers elsewhere. Though the city has declined in recent decades since the decline of heavy industry in the area and whiteflight to the suburbs, the city has made efforts to revitalize itself through various infrastructure and community projects.\\nProjects such as the redevelopment of the waterfront area brought three tourist attractions to the area: the USS New Jersey, the Freedom Mortgage Pavilion and the Adventure Aquarium. The city is the home of Rutgers University–Camden, which was founded as the South Jersey Law School in 1926, and Cooper Medical School of Rowan University, which opened in 2012. Camden also houses both Cooper University Hospital and Virtua Our Lady of Lourdes Hospital. Camden County College and Rowan University also have campuses in downtown Camden. The \"eds and meds\" institutions account for roughly 45% of Camden\\'s total employment.\\nOnce known for violent crime, the restructuring of the police force in 2013 has been credited for the decrease in that number. As of January 2021, violent crime was down 46% from its high in the 1990s and at the lowest level since the 1960s. Overall crime reports in 2020 were down 74% compared to 1974, the first year of uniform crime-reporting in the city.\\n\\n\\n== History ==\\n\\n\\n=== Prehistory ===\\nThe city traces back to local indigenous Lenape, who are believed to have inhabited this area 13–15,000 years prior to the first European settlers. \\n\\n\\n=== Settlement years (1623–1701) ===\\nBetween 1623 and 1627, Captain Cornelius Jacobsen May, an officer with the Dutch West India Company and first director of New Netherland, established Fort Nassau, where the Delaware River meets Big Timber Creek, which is today known as Brooklawn. In 1633, David Pietersen De Vries, a Dutch commander, was sailing up the Delaware River when he came across Natives in control of the fort. The settlers that had been left at the fort had decided to return to New Amsterdam (Today Manhattan, New York). Wouter van Twiller, Governor of New Netherland, restored Fort Nassau. He was accused of extravagant spending in the fort\\'s reconstruction. The settlement subsequently sparked competition from European Settlers over control of the fur trade in the area.  The fort was used by the Dutch until around 1650 or 1651 when it was decided that it was far to up the river to be of any value. The buildings and stockades were demolished and Wouter van Twiller assigned Arent Corssen to find a place for another fort. \\nThe British first had a pressence in the area in 1634. On June 21, 1634, Sir Edmund Ployden was given a charter from King Charles I of England for all territory that lies between New England and Maryland. After the Restoration in 1660, previous claims were largely overwritten, the land around Camden was then controlled by different nobles serving under King Charles II that those associated with Sir Edmund Ployden. \\nIn 1664, the Duke of York had the King Charles II create the new colony for Lord John Berkeley and Sir George Carteret. It was named the Province of New Jersey after George Carteret; in 1649, he was Governor of the Isle of Jersey. Lord John Berkeley kept his share of New Jersey from 1664 until 1674, when'),\n",
       " Document(metadata={'title': '2020 United States presidential election in New Jersey', 'summary': \"The 2020 United States presidential election in New Jersey was held on Tuesday, November 3, 2020, as part of the 2020 United States presidential election in which all 50 states plus the District of Columbia participated. New Jersey voters chose electors to represent them in the Electoral College via a popular vote, pitting the Republican Party's nominee, incumbent President Donald Trump, and running mate Vice President Mike Pence against Democratic Party nominee, former Vice President Joe Biden, and his running mate California Senator Kamala Harris. New Jersey has 14 electoral votes in the Electoral College.\\nBiden carried New Jersey by 15.94%, making the state 11.49% more Democratic than the nation as a whole. Per exit polls by the Associated Press, Biden's victory came from a coalition of key Democratic constituencies, including 86% of Blacks, 76% of Asians, 72% of Hispanic and Latino Americans, and 50% of Whites. Biden's strength with Asian Americans was evident in New Jersey, where Asians constituted 10.0% of the population in 2019.\\nBiden flipped Gloucester County, which was reliably Democratic until Trump flipped it in 2016. He also became the first Democrat since Lyndon B. Johnson in 1964 to win Morris County, which Cory Booker won in the simultaneous senate election. This also became the first presidential election since 2000 in which Salem County did not vote for the national winner. Trump carried 255 of New Jersey's 565 municipalities, fewer than the 307 he carried in 2016, with Biden carrying the other 310. Biden's 2.6 million votes is the most received by any candidate of either party in a presidential election in the state's history.\", 'source': 'https://en.wikipedia.org/wiki/2020_United_States_presidential_election_in_New_Jersey'}, page_content=\"The 2020 United States presidential election in New Jersey was held on Tuesday, November 3, 2020, as part of the 2020 United States presidential election in which all 50 states plus the District of Columbia participated. New Jersey voters chose electors to represent them in the Electoral College via a popular vote, pitting the Republican Party's nominee, incumbent President Donald Trump, and running mate Vice President Mike Pence against Democratic Party nominee, former Vice President Joe Biden, and his running mate California Senator Kamala Harris. New Jersey has 14 electoral votes in the Electoral College.\\nBiden carried New Jersey by 15.94%, making the state 11.49% more Democratic than the nation as a whole. Per exit polls by the Associated Press, Biden's victory came from a coalition of key Democratic constituencies, including 86% of Blacks, 76% of Asians, 72% of Hispanic and Latino Americans, and 50% of Whites. Biden's strength with Asian Americans was evident in New Jersey, where Asians constituted 10.0% of the population in 2019.\\nBiden flipped Gloucester County, which was reliably Democratic until Trump flipped it in 2016. He also became the first Democrat since Lyndon B. Johnson in 1964 to win Morris County, which Cory Booker won in the simultaneous senate election. This also became the first presidential election since 2000 in which Salem County did not vote for the national winner. Trump carried 255 of New Jersey's 565 municipalities, fewer than the 307 he carried in 2016, with Biden carrying the other 310. Biden's 2.6 million votes is the most received by any candidate of either party in a presidential election in the state's history.\\n\\n\\n== Primary elections ==\\nThe primary elections were originally scheduled for June 2, 2020. In April, they were moved to July 7 due to concerns over the COVID-19 pandemic. On May 15, 2020, Governor Phil Murphy signed an executive order declaring the primary election to become a primarily vote-by-mail election. Democratic and Republican voters will automatically receive a vote-by-mail ballot while unaffiliated and inactive voters will get a vote-by-mail application. Unaffiliated voters must declare their party in the application and send in to their respective county board of elections in order to vote and receive their primary election ballot. A limited number of polling stations in each county were available on primary day for those who prefer to vote in person (including with provisional ballots if they're unable to obtain one) and for voters with disabilities.\\n\\n\\n=== Republican primary ===\\n\\nIncumbent President Donald Trump ran unopposed in the Republican primary. The state has 49 delegates to the 2020 Republican National Convention.\\n\\n\\n=== Democratic primary ===\\n\\n\\n=== Green primary ===\\n\\n\\n== General election ==\\n\\n\\n=== Predictions ===\\n\\n\\n=== Polling ===\\n\\n\\n==== Graphical summary ====\\n\\n\\n==== Aggregate polls ====\\n\\nPolls\\n\\n\\n=== Results ===\\n\\n\\n==== By county ====\\n\\nCounties that flipped from Republican to Democratic\\n\\nGloucester (largest municipality: Washington Township)\\nMorris (largest municipality: Parsippany)\\n\\n\\n==== By congressional district ====\\nBiden won 9 out of the 12 congressional districts in New Jersey. Trump won 3, including one that elected a Democrat.\\n\\n\\n== Analysis ==\\nAs the polls predicted, Joe Biden won New Jersey by a wide margin. Biden ran up huge margins in the state's major cities such as Newark, Jersey City, Paterson, Trenton, Atlantic City, Camden, and several others. In addition to carrying all the counties that Clinton won in 2016, Biden flipped Gloucester County, which was a reliably blue county before Trump won it in 2016. Biden also won Morris County, which had never voted Democratic in any presidential race since 1964; Senator Cory Booker concurrently won Morris County in his reelection victory as well. In neighboring Hunterdon County, Biden came within 4.4 points of victory despite the county being a reliably Republican stronghold as well. Biden recorded the highest sha\"),\n",
       " Document(metadata={'title': '2021 New Jersey gubernatorial election', 'summary': 'The 2021 New Jersey gubernatorial election was held on November 2, 2021, to elect the governor of New Jersey. Incumbent governor Phil Murphy was first elected in 2017 with 56% of the vote and won re-election to a second term. Murphy and his running mate, Lt. Gov. Sheila Oliver, defeated the Republican ticket of Jack Ciattarelli and Diane Allen, 51.2% to 48%.\\nMurphy formally announced his intention to run for a second term on October 1, 2020. Primaries were held on June 8, 2021. Murphy, who won the Democratic nomination unopposed after his two primary challengers were disqualified, faced Ciattarelli, Green nominee Madelyn Hoffman, Libertarian nominee Gregg Mele, and Socialist Workers Party nominee Joanne Kuniansky in the general election. The race was considered by many media outlets to be a \"safe\" or \"likely\" Democratic hold, as Murphy had led a majority of pre-election polls by double digits. However, Murphy defeated Ciattarelli by a much smaller margin than expected.\\nMurphy is the first Democratic governor of New Jersey to win re-election since Brendan Byrne in 1977, as well as the first candidate of the same party as the incumbent U.S. president to win since Thomas Kean in 1985. This is also the first New Jersey gubernatorial election since 2009 where both the Democratic and Republican nominees received more than one million votes each. It also was the first New Jersey gubernatorial election where the Green Party candidate placed third. Murphy also became the first Democrat to win a New Jersey gubernatorial election without carrying Gloucester and Cumberland Counties since Robert B. Meyner in 1953, and the first Democrat to win a gubernatorial election without carrying Atlantic County since Richard J. Hughes in 1961.\\nAtlantic County voted for the losing candidate for the first time since 1993. Also, this was the first New Jersey gubernatorial election in which Somerset County voted more Democratic than the state as a whole since 1910. Murphy became the first New Jersey Governor since Brendan Byrne to win both of his elections with a majority of the vote each time. It was the first single-digit Democratic win in a governor\\'s election since 1961. Murphy received the most votes for a Democrat or any governor since 1989, and Ciattarelli received the most for a Republican since 2013.', 'source': 'https://en.wikipedia.org/wiki/2021_New_Jersey_gubernatorial_election'}, page_content='The 2021 New Jersey gubernatorial election was held on November 2, 2021, to elect the governor of New Jersey. Incumbent governor Phil Murphy was first elected in 2017 with 56% of the vote and won re-election to a second term. Murphy and his running mate, Lt. Gov. Sheila Oliver, defeated the Republican ticket of Jack Ciattarelli and Diane Allen, 51.2% to 48%.\\nMurphy formally announced his intention to run for a second term on October 1, 2020. Primaries were held on June 8, 2021. Murphy, who won the Democratic nomination unopposed after his two primary challengers were disqualified, faced Ciattarelli, Green nominee Madelyn Hoffman, Libertarian nominee Gregg Mele, and Socialist Workers Party nominee Joanne Kuniansky in the general election. The race was considered by many media outlets to be a \"safe\" or \"likely\" Democratic hold, as Murphy had led a majority of pre-election polls by double digits. However, Murphy defeated Ciattarelli by a much smaller margin than expected.\\nMurphy is the first Democratic governor of New Jersey to win re-election since Brendan Byrne in 1977, as well as the first candidate of the same party as the incumbent U.S. president to win since Thomas Kean in 1985. This is also the first New Jersey gubernatorial election since 2009 where both the Democratic and Republican nominees received more than one million votes each. It also was the first New Jersey gubernatorial election where the Green Party candidate placed third. Murphy also became the first Democrat to win a New Jersey gubernatorial election without carrying Gloucester and Cumberland Counties since Robert B. Meyner in 1953, and the first Democrat to win a gubernatorial election without carrying Atlantic County since Richard J. Hughes in 1961.\\nAtlantic County voted for the losing candidate for the first time since 1993. Also, this was the first New Jersey gubernatorial election in which Somerset County voted more Democratic than the state as a whole since 1910. Murphy became the first New Jersey Governor since Brendan Byrne to win both of his elections with a majority of the vote each time. It was the first single-digit Democratic win in a governor\\'s election since 1961. Murphy received the most votes for a Democrat or any governor since 1989, and Ciattarelli received the most for a Republican since 2013.\\n\\n\\n== Democratic primary ==\\n\\n\\n=== Candidates ===\\n\\n\\n==== Nominee ====\\nPhil Murphy, incumbent governor (2018–present)\\n\\n\\n==== Disqualified ====\\nRoger Bacon, perennial candidate\\nLisa McCormick, candidate for U.S. Senate in 2018\\n\\n\\n==== Declined ====\\nJamel Holley, state assemblyman from the 20th district (ran for State Senate)\\nStephen M. Sweeney, President of the New Jersey Senate (running for re-election)\\n\\n\\n=== Fundraising ===\\n\\n\\n=== Lieutenant Governor nomination ===\\n\\n\\n==== Nominee ====\\nSheila Oliver, incumbent Lieutenant Governor (2018–2023)\\n\\n\\n=== Results ===\\n\\n\\n== Republican primary ==\\n\\n\\n=== Candidates ===\\n\\n\\n==== Nominee ====\\nJack Ciattarelli, former member of the New Jersey General Assembly from the 16th district (2011–2018) and candidate for governor in 2017\\n\\n\\n==== Eliminated in primary ====\\nBrian Levine, former Somerset County commissioner (2014–2020), former mayor of Franklin Township, Somerset County (2004–2014) and candidate for governor in 2009\\nPhil Rizzo, pastor\\nHirsh Singh, businessman, engineer, and perennial candidate\\n\\n\\n==== Withdrew ====\\nJoseph Rudy Rullo, businessman, actor and perennial candidate (endorsed Hirsh Singh)\\nDoug Steinhardt, chair of the Warren County Republican Committee (2004–present), former mayor of Lopatcong (1999–2014) and former Chair of the New Jersey Republican State Committee (2017–2020)\\nJoseph Vicari, Ocean County commissioner\\n\\n\\n==== Declined ====\\nJon Bramnick, minority leader of the New Jersey General Assembly (running for State Senate)\\nChris Christie, former governor of New Jersey (2010–2018)\\nJoe Kyrillos, former state senator and assemblyman from the 13th district, Republican nominee for New Jersey\\'s 6th congression'),\n",
       " Document(metadata={'title': 'Elizabeth, New Jersey', 'summary': \"Elizabeth is a city in and the county seat of Union County, in the U.S. state of New Jersey. As of the 2020 United States census, the city retained its ranking as the state's fourth-most-populous city behind neighboring Newark, Jersey City, and Paterson, with a population of 137,298, an increase of 12,329 (+9.9%) from the 2010 census count of 124,969, which in turn reflected an increase of 4,401 (3.7%) from the 120,568 counted in the 2000 census.\\nThe Population Estimates Program calculated a population of 135,829 for 2023, making it the 207th-most populous city in the nation and the fifth-most populous municipality of any type in the state, falling behind Lakewood Township, where the population that year was estimated to be 139,866.\\n\\n\", 'source': 'https://en.wikipedia.org/wiki/Elizabeth,_New_Jersey'}, page_content='Elizabeth is a city in and the county seat of Union County, in the U.S. state of New Jersey. As of the 2020 United States census, the city retained its ranking as the state\\'s fourth-most-populous city behind neighboring Newark, Jersey City, and Paterson, with a population of 137,298, an increase of 12,329 (+9.9%) from the 2010 census count of 124,969, which in turn reflected an increase of 4,401 (3.7%) from the 120,568 counted in the 2000 census.\\nThe Population Estimates Program calculated a population of 135,829 for 2023, making it the 207th-most populous city in the nation and the fifth-most populous municipality of any type in the state, falling behind Lakewood Township, where the population that year was estimated to be 139,866.\\n\\n\\n== History ==\\n\\nElizabeth, originally called \"Elizabethtown\" and part of the Elizabethtown Tract, was founded in 1664 by English settlers. The town was not named for Queen Elizabeth I as many people may assume, but rather for Elizabeth, wife of Sir George Carteret, one of the two original Proprietors of the colony of New Jersey. She was the daughter of Philippe de Carteret II, 3rd Seigneur de Sark and Anne Dowse. The town served as the first capital of New Jersey.\\nDuring the American Revolutionary War, Elizabethtown was continually attacked by British forces based on Manhattan and Staten Island, culminating in the Battle of Springfield which decisively defeated British attempts to gain New Jersey. After independence, it was from Elizabethtown that George Washington embarked by boat to Manhattan for his 1789 inauguration. There are numerous memorials and monuments of the American Revolution in Elizabeth.\\nOn March 13, 1855, the City of Elizabeth was created by an act of the New Jersey Legislature, combining and replacing both Elizabeth Borough (which dated back to 1740) and Elizabeth Township (which had been formed in 1693), subject to the results of a referendum held on March 27, 1855. On March 19, 1857, the city became part of the newly created Union County. Portions of the city were taken to form Linden Township on March 4, 1861.\\nThe first major industry, the Singer Sewing Machine Company came to Elizabeth and employed as many as 2,000 people. In 1895, it saw one of the first car companies, when Electric Carriage and Wagon Company was founded to manufacture the Electrobat, joined soon by another electric car builder, Andrew L. Riker. The Electric Boat Company got its start building submarines for the United States Navy in Elizabeth, beginning with the launch of USS Holland (SS-1) in 1897. These pioneering naval craft (known as A-Class) were developed at Lewis Nixon\\'s Crescent Shipyard in Elizabeth between the years 1896–1903. Elizabeth grew in parallel to its sister city of Newark for many years, but has been more successful in retaining a middle-class presence and was mostly spared riots in the 1960s.\\n\\n\\n== Geography ==\\nAccording to the U.S. Census Bureau, the city had a total area of 13.66 square miles (35.37 km2), including 12.32 square miles (31.91 km2) of land and 1.34 square miles (3.46 km2) of water (9.78%).\\nElizabeth is bordered to the southwest by Linden, to the west by Roselle and Roselle Park, to the northwest by Union and Hillside, to the north by Newark (in Essex County). To the east the city is across Newark Bay from Bayonne in Hudson County and the Arthur Kill from Staten Island, New York.\\nThe borders of Elizabeth, Bayonne, and Staten Island meet at one point on Shooters Island, of which 7.5 acres (3.0 ha) of the island is owned by Elizabeth, though the island is managed by the New York City Department of Parks and Recreation.\\nThe Elizabeth River is a waterway that courses through the city for 4.2 miles (6.8 km) and is largely channelized, before draining into the Arthur Kill.\\n\\n\\n== Districts and neighborhoods ==\\n\\n\\n=== Midtown / Uptown ===\\n\\nMidtown, also occasionally known as Uptown, is the main commercial district and a historic section as well. It includes the First Presbyterian Ch'),\n",
       " Document(metadata={'title': 'Rutgers University', 'summary': \"Rutgers University ( RUT-gərz), officially Rutgers, The State University of New Jersey, is a public land-grant research university consisting of three campuses in New Jersey. Chartered in 1766, Rutgers was originally called Queen's College, and was affiliated with the Dutch Reformed Church. It is the eighth-oldest college in the United States, the second-oldest in New Jersey (after Princeton University), and one of nine colonial colleges that were chartered before the American Revolution.\\nIn 1825, Queen's College was renamed Rutgers College in honor of Colonel Henry Rutgers, whose substantial gift to the school had stabilized its finances during a period of uncertainty. For most of its existence, Rutgers was a private liberal arts college. It has evolved into a coeducational public research university since being designated the State University of New Jersey by the state's legislature in 1945 and 1956.\\nRutgers has several distinct campuses. Since colonial times, its historic core has been situated along College Avenue in New Brunswick, New Jersey. Rutgers University–New Brunswick also includes the landscaped campus of Douglass College, a women's college that was traditionally paired with Rutgers, the College Farm, and additional grounds in adjacent Piscataway. Apart from the New Brunswick core, campuses at Rutgers University–Newark; Rutgers University–Camden; and Rutgers Biomedical and Health Sciences complete the university's main footprint. The university has additional facilities throughout the state, including oceanographic research facilities at the Jersey Shore.\\nRutgers is a land-grant, sea-grant, and space-grant university, as well as the largest university in the state. Instruction is offered by 9,000 faculty members in 175 academic departments to over 45,000 undergraduate students and more than 20,000 graduate and professional students. The university is accredited by the Middle States Commission on Higher Education and is a member of the Association of American Universities and the Universities Research Association.\", 'source': 'https://en.wikipedia.org/wiki/Rutgers_University'}, page_content='Rutgers University ( RUT-gərz), officially Rutgers, The State University of New Jersey, is a public land-grant research university consisting of three campuses in New Jersey. Chartered in 1766, Rutgers was originally called Queen\\'s College, and was affiliated with the Dutch Reformed Church. It is the eighth-oldest college in the United States, the second-oldest in New Jersey (after Princeton University), and one of nine colonial colleges that were chartered before the American Revolution.\\nIn 1825, Queen\\'s College was renamed Rutgers College in honor of Colonel Henry Rutgers, whose substantial gift to the school had stabilized its finances during a period of uncertainty. For most of its existence, Rutgers was a private liberal arts college. It has evolved into a coeducational public research university since being designated the State University of New Jersey by the state\\'s legislature in 1945 and 1956.\\nRutgers has several distinct campuses. Since colonial times, its historic core has been situated along College Avenue in New Brunswick, New Jersey. Rutgers University–New Brunswick also includes the landscaped campus of Douglass College, a women\\'s college that was traditionally paired with Rutgers, the College Farm, and additional grounds in adjacent Piscataway. Apart from the New Brunswick core, campuses at Rutgers University–Newark; Rutgers University–Camden; and Rutgers Biomedical and Health Sciences complete the university\\'s main footprint. The university has additional facilities throughout the state, including oceanographic research facilities at the Jersey Shore.\\nRutgers is a land-grant, sea-grant, and space-grant university, as well as the largest university in the state. Instruction is offered by 9,000 faculty members in 175 academic departments to over 45,000 undergraduate students and more than 20,000 graduate and professional students. The university is accredited by the Middle States Commission on Higher Education and is a member of the Association of American Universities and the Universities Research Association.\\n\\n\\n== History ==\\n\\n\\n=== 18th century ===\\nTwo decades after the College of New Jersey, which is now Princeton University, was established in 1746 by the New Light Presbyterians, ministers of the Dutch Reformed Church, seeking autonomy in ecclesiastical affairs in the Thirteen Colonies, sought to establish a college to train those who wanted to become ministers within the church. \\n\\n \\nThrough several years of effort by Theodorus Jacobus Frelinghuysen (1691–1747) and Jacob Rutsen Hardenbergh (1736–1790), later the college\\'s first president, Queen\\'s College received its charter on November 10, 1766, from New Jersey\\'s last royal governor, William Franklin (1730–1813), the son of Benjamin Franklin. The original charter established the college under the corporate name the trustees of Queen\\'s College, in New-Jersey, named in honor of Queen Charlotte (1744–1818), and created both the college and the Queen\\'s College Grammar School, intended to be a preparatory school affiliated and governed by the college. The Grammar School, today the private Rutgers Preparatory School, was a part of the college community until 1959. New Brunswick was chosen as the location over Hackensack because the New Brunswick Dutch had the support of the Anglican population, making the royal charter easier to obtain.\\n\\nThe original purpose of Queen\\'s College was to \"educate the youth in language, liberal, the divinity, and useful arts and sciences\" and for the training of future ministers for the Dutch Reformed Church.\\nIn 1771, the college admitted its first students, which included a single sophomore and a handful of first-year students taught by a lone instructor, and granted its first degree in 1774, to Matthew Leydt. Despite the religious nature of the early college, the first classes were held at a tavern called the Sign of the Red Lion. When the Revolutionary War broke out and taverns were suspected by the British as being hotbeds of rebel'),\n",
       " Document(metadata={'title': 'New Jersey (album)', 'summary': 'New Jersey is the fourth studio album by American rock band Bon Jovi, released on September 19, 1988, by Mercury Records. The album was produced by Bruce Fairbairn and recorded at Little Mountain Sound Studios in Vancouver, British Columbia, Canada. The album was the follow-up to the band\\'s third album, Slippery When Wet, and reached number one on the Billboard 200 chart in its second week of release after debuting at number eight. It remained at the top for four consecutive weeks and was Bon Jovi\\'s last album to do so until Lost Highway (2007). The album was named after the birth state of Jon Bon Jovi, New Jersey.\\nIt produced five Billboard Hot 100 top ten hits, the most top ten hits to date for any glam metal album, including \"Bad Medicine\" and \"I\\'ll Be There for You\", which both reached number one. The album was certified 7× platinum by the Recording Industry Association of America (RIAA). The album also debuted at number one in the UK and was the band\\'s first UK No. 1 album. New Jersey was released by the Soviet state-owned record label Melodiya, being the first American album to be officially released in the USSR. To celebrate the band\\'s 30th anniversary in 2014, the album was repackaged with bonus tracks.', 'source': 'https://en.wikipedia.org/wiki/New_Jersey_(album)'}, page_content='New Jersey is the fourth studio album by American rock band Bon Jovi, released on September 19, 1988, by Mercury Records. The album was produced by Bruce Fairbairn and recorded at Little Mountain Sound Studios in Vancouver, British Columbia, Canada. The album was the follow-up to the band\\'s third album, Slippery When Wet, and reached number one on the Billboard 200 chart in its second week of release after debuting at number eight. It remained at the top for four consecutive weeks and was Bon Jovi\\'s last album to do so until Lost Highway (2007). The album was named after the birth state of Jon Bon Jovi, New Jersey.\\nIt produced five Billboard Hot 100 top ten hits, the most top ten hits to date for any glam metal album, including \"Bad Medicine\" and \"I\\'ll Be There for You\", which both reached number one. The album was certified 7× platinum by the Recording Industry Association of America (RIAA). The album also debuted at number one in the UK and was the band\\'s first UK No. 1 album. New Jersey was released by the Soviet state-owned record label Melodiya, being the first American album to be officially released in the USSR. To celebrate the band\\'s 30th anniversary in 2014, the album was repackaged with bonus tracks.\\n\\n\\n== Background ==\\nThe album was recorded very shortly after the Slippery When Wet Tour, because the band wanted to prove that they were not just going to be a one hit wonder. The album was initially planned to be a double album; however, this idea was rejected by the record label because they were skeptical about the higher price point and decided they would only release a single album. One working title for the album was Sons of Beaches, which alluded to the title of Slippery When Wet.\\n\\n\\n== Recording and production ==\\nThe album was produced by Bruce Fairbairn like its predecessor and recorded at Little Mountain Sound Studios in Vancouver, British Columbia, Canada. It marked the final collaboration between Bon Jovi and producer Bruce Fairbairn.\\nWhen the Slippery When Wet Tour ended in October 1987, the band were inactive for about three to four weeks. Then Jon Bon Jovi and Richie Sambora began making demos for 17 songs which would make up the first batch of songs written for the album. However, they began to feel a high level of pressure because they did not feel as though they had \"the amazing song\". Jon Bon Jovi said that \"I really wanted to do it again, not for monetary reasons—I have plenty of money—but it was such an amazing feeling to have done what we\\'ve done. There was a real fear of not being able to write \\'You Give Love a Bad Name\\' again.\" Jon Bon Jovi and Richie Sambora sat together and wrote the song \"Love Is War\" but Jon Bon Jovi wanted to write a song that would prove to be just as successful as \"You Give Love a Bad Name\" so desperately that it came out with exactly the same chord progression. They later started on the second batch of songs and they wrote \"Bad Medicine\" and \"Born to Be My Baby\" with Desmond Child. \"Born to Be My Baby\" was originally recorded acoustically, however the producer Bruce Fairbairn persuaded them to re-record it with electric instruments in a much more metal style. Jon Bon Jovi has since said that he believed the song would have made number one on the charts if it had been released in its original form. This song has a similar theme to \"Livin\\' on a Prayer\", as it is about a young working class couple struggling to make ends meet.\\nAlthough the glossy production and anthems from Slippery When Wet remained, the band wished to show a level of diversity on the album. The album is much more experimental with a long, atmosphere-building intro on \"Lay Your Hands on Me\", harmonica and organ duels on \"Homebound Train\" and a flamenco guitar intro on \"Wild Is the Wind\". \"Ride Cowboy Ride\" is a short song functioning as an introduction to \"Stick to Your Guns\" and was recorded in mono. The song is credited to \"Captain Kidd and King of Swing\", the nicknames of Bon Jovi and Sambora.\\n\"Love for S'),\n",
       " Document(metadata={'title': 'New York metropolitan area', 'summary': \"The New York metropolitan area, broadly referred to as the Tri-State area and often also called Greater New York, is the largest metropolitan area in the world by urban landmass, encompassing 4,669.0 sq mi (12,093 km2). The New York metropolitan area is one of the most populous metropolitan areas in the world, the largest metropolitan area in the U.S., and the only U.S. metropolitan area home to more than 20 million residents as of the 2020 United States census.\\nThe vast metropolitan area includes New York City, the nation's most populous city, Long Island, the mid and lower Hudson Valley in New York state, fourteen counties, eleven of the largest cities in New Jersey, and six of the seven largest cities in Connecticut. The phrase Tri-State area is usually used to refer to New York, New Jersey, and Connecticut, although an increasing number of people who work in New York City commute from Pennsylvania, particularly from the Lehigh Valley, Bucks County, and Poconos regions in eastern Pennsylvania, making the metropolitan area span across four states. The New York metropolitan area is the geographic and demographic hub of the larger Northeast megalopolis.\\nThe New York metropolitan area is the most populous metropolitan statistical area in the United States with 20.1 million residents, or slightly over 6% of the nation's total population, as of 2020. The combined statistical area includes 23.6 million residents as of 2020. It is one of the largest urban agglomerations in the world. The New York metropolitan area continues to be the premier gateway for legal immigration to the United States, having the largest foreign-born population of any metropolitan region in the world. The metropolitan statistical area covers 6,720 sq mi (17,405 km2) while the combined statistical area is 13,318 sq mi (34,493 km2), encompassing an ethnically and geographically diverse region. The New York metropolitan area's population is larger than that of the state of New York, and the metropolitan airspace accommodated over 130 million passengers in 2016.\\nAs of 2022, the New York metropolitan area is the largest metropolitan economy in the world, with a gross metropolitan product of over US$2.5 trillion. Greater New York is the hub of multiple industries, including finance, health care, pharmaceuticals, and scientific output in life sciences, international trade, publishing, real estate, education, fashion, entertainment, tourism, law, and manufacturing; and if the New York metropolitan area were an independent sovereign state, it would constitute the eighth-largest economy in the world.  It is the most prominent financial, diplomatic, and media hub in the world.\\nAccording to Forbes, in 2014, the New York metropolitan area was home to eight of the top ten ZIP Codes in the United States by median housing price, with six in Manhattan alone. The New York metropolitan area is known for its varied landscape and natural beauty, and contains five of the top ten richest places in America, according to Bloomberg. These are Scarsdale, New York; Short Hills, New Jersey; Old Greenwich, Connecticut; Bronxville, New York; and Darien, Connecticut. The New York metropolitan region's higher education network comprises hundreds of colleges and universities, including campuses of four Ivy League universities: Columbia, Princeton, Yale, and Cornell (at Cornell Tech and Weill Cornell Medicine); the flagship campuses of the largest public universities systems at SUNY Stony Brook and Rutgers; and globally-ranked New York University, Rockefeller University, and Cold Spring Harbor Laboratory.\", 'source': 'https://en.wikipedia.org/wiki/New_York_metropolitan_area'}, page_content=\"The New York metropolitan area, broadly referred to as the Tri-State area and often also called Greater New York, is the largest metropolitan area in the world by urban landmass, encompassing 4,669.0 sq mi (12,093 km2). The New York metropolitan area is one of the most populous metropolitan areas in the world, the largest metropolitan area in the U.S., and the only U.S. metropolitan area home to more than 20 million residents as of the 2020 United States census.\\nThe vast metropolitan area includes New York City, the nation's most populous city, Long Island, the mid and lower Hudson Valley in New York state, fourteen counties, eleven of the largest cities in New Jersey, and six of the seven largest cities in Connecticut. The phrase Tri-State area is usually used to refer to New York, New Jersey, and Connecticut, although an increasing number of people who work in New York City commute from Pennsylvania, particularly from the Lehigh Valley, Bucks County, and Poconos regions in eastern Pennsylvania, making the metropolitan area span across four states. The New York metropolitan area is the geographic and demographic hub of the larger Northeast megalopolis.\\nThe New York metropolitan area is the most populous metropolitan statistical area in the United States with 20.1 million residents, or slightly over 6% of the nation's total population, as of 2020. The combined statistical area includes 23.6 million residents as of 2020. It is one of the largest urban agglomerations in the world. The New York metropolitan area continues to be the premier gateway for legal immigration to the United States, having the largest foreign-born population of any metropolitan region in the world. The metropolitan statistical area covers 6,720 sq mi (17,405 km2) while the combined statistical area is 13,318 sq mi (34,493 km2), encompassing an ethnically and geographically diverse region. The New York metropolitan area's population is larger than that of the state of New York, and the metropolitan airspace accommodated over 130 million passengers in 2016.\\nAs of 2022, the New York metropolitan area is the largest metropolitan economy in the world, with a gross metropolitan product of over US$2.5 trillion. Greater New York is the hub of multiple industries, including finance, health care, pharmaceuticals, and scientific output in life sciences, international trade, publishing, real estate, education, fashion, entertainment, tourism, law, and manufacturing; and if the New York metropolitan area were an independent sovereign state, it would constitute the eighth-largest economy in the world.  It is the most prominent financial, diplomatic, and media hub in the world.\\nAccording to Forbes, in 2014, the New York metropolitan area was home to eight of the top ten ZIP Codes in the United States by median housing price, with six in Manhattan alone. The New York metropolitan area is known for its varied landscape and natural beauty, and contains five of the top ten richest places in America, according to Bloomberg. These are Scarsdale, New York; Short Hills, New Jersey; Old Greenwich, Connecticut; Bronxville, New York; and Darien, Connecticut. The New York metropolitan region's higher education network comprises hundreds of colleges and universities, including campuses of four Ivy League universities: Columbia, Princeton, Yale, and Cornell (at Cornell Tech and Weill Cornell Medicine); the flagship campuses of the largest public universities systems at SUNY Stony Brook and Rutgers; and globally-ranked New York University, Rockefeller University, and Cold Spring Harbor Laboratory.\\n\\n\\n== Definitions ==\\n\\n\\n=== Metropolitan statistical area ===\\nThe counties and county groupings constituting the New York metropolitan area are listed below, with 2010 census figures:\\n\\nThe U.S. Office of Management and Budget utilizes two definitions of the urbanized area: the metropolitan statistical area (MSA) and the combined statistical area (CSA). The MSA definition is titled the New York\"),\n",
       " Document(metadata={'title': 'Edison, New Jersey', 'summary': \"Edison is a township located in Middlesex County, in the U.S. state of New Jersey. Situated in Central New Jersey within the core of the state's Raritan Valley region, Edison is a commercial hub (home to Menlo Park Mall and Little India) and is a bedroom community of New York City within the New York metropolitan area.\\nAs of the 2020 United States census, the township was the state's sixth-most-populous municipality, with a population of 107,588, an increase of 7,621 (+7.6%) from the 2010 census count of 99,967, which in turn reflected an increase of 2,280 (+2.3%) from the 97,687 counted in the 2000 census.\\nWhat is now Edison Township was originally incorporated as Raritan Township by an act of the New Jersey Legislature on March 17, 1870, from portions of both Piscataway and Woodbridge Township. The township got its original name from the Raritan indigenous people. Portions of the township were taken to form Metuchen on March 20, 1900, and Highland Park on March 15, 1905. The name was officially changed to Edison Township on November 10, 1954, in honor of inventor Thomas Edison, who had his main laboratory in the Menlo Park section of the township.\", 'source': 'https://en.wikipedia.org/wiki/Edison,_New_Jersey'}, page_content='Edison is a township located in Middlesex County, in the U.S. state of New Jersey. Situated in Central New Jersey within the core of the state\\'s Raritan Valley region, Edison is a commercial hub (home to Menlo Park Mall and Little India) and is a bedroom community of New York City within the New York metropolitan area.\\nAs of the 2020 United States census, the township was the state\\'s sixth-most-populous municipality, with a population of 107,588, an increase of 7,621 (+7.6%) from the 2010 census count of 99,967, which in turn reflected an increase of 2,280 (+2.3%) from the 97,687 counted in the 2000 census.\\nWhat is now Edison Township was originally incorporated as Raritan Township by an act of the New Jersey Legislature on March 17, 1870, from portions of both Piscataway and Woodbridge Township. The township got its original name from the Raritan indigenous people. Portions of the township were taken to form Metuchen on March 20, 1900, and Highland Park on March 15, 1905. The name was officially changed to Edison Township on November 10, 1954, in honor of inventor Thomas Edison, who had his main laboratory in the Menlo Park section of the township.\\n\\n\\n== History ==\\n\\n\\n=== Early history ===\\n\\nThe earliest residents of the area were the Raritan people of the Lenape Native Americans, who lived in the area and travelled through it to the shore. In 1646, Chief Matouchin led a group of 1,200 warriors.\\nEdison Township, which was formed from sections of Piscataway and Woodbridge townships, was settled (by Europeans) in the 17th century. The earliest village was Piscatawaytown, which is centered around St. James Church and the Piscatawaytown Common, near the intersection of Plainfield and Woodbridge Avenues in South Edison. The Laing House of Plainfield Plantation (listed on the National Register in 1988), the Benjamin Shotwell House (listed 1987) and the Homestead Farm at Oak Ridge (liste 1995), are buildings from the colonial era included in National Register of Historic Places listings in Middlesex County.\\nThe community was previously known as \"Raritan Township\", not to be confused with the current-day Raritan Township in Hunterdon County.\\n\\n\\n=== The Edison era ===\\n\\nIn 1876, Thomas Edison set up his home and research laboratory in New Jersey on the site of an unsuccessful real estate development in Raritan Township called \"Menlo Park\", (currently located in Edison State Park). While there he earned the nickname \"the Wizard of Menlo Park\". Before his death at age 83 in 1931, the prolific inventor amassed a record 1,093 patents for creations including the phonograph, a stock ticker, the motion-picture camera, the incandescent light bulb, a mechanical vote counter, the alkaline storage battery including one for an electric car, and the first commercial electric light.\\nThe Menlo Park lab was significant in that was one of the first laboratories to pursue practical, commercial applications of research. It was in his Menlo Park laboratory that Thomas Edison came up with the phonograph and a commercially viable incandescent light bulb filament. Christie Street was the first street in the world to use electric lights for illumination. Edison subsequently left Menlo Park and moved his home and laboratory to West Orange in 1886.\\n\\n\\n=== 20th century ===\\nNear Piscatawaytown village, a portion of the township was informally known as \"Nixon\", after Lewis Nixon, a manufacturer and community leader. Soon after the outbreak of World War I, Nixon established a massive volatile chemicals processing facility there, known as the Nixon Nitration Works. It was the site of the 1924 Nixon Nitration Works disaster, a massive explosion and resulting fire that killed 20 people and destroyed several square miles of the township.\\nIn 1954, the township\\'s name was changed to honor inventor Thomas A. Edison. Also on the ballot in 1954 was a failed proposal to change the community\\'s name to Nixon.\\nIn 1959, the Menlo Park Mall, a two-level super regional shopping mall, o'),\n",
       " Document(metadata={'title': 'Bayonne, New Jersey', 'summary': \"Bayonne ( bay-(Y)OHN) is a city in Hudson County in the U.S. state of New Jersey. Located in the Gateway Region, Bayonne is situated on a peninsula between Newark Bay to the west, the Kill Van Kull to the south, and New York Bay to the east. As of the 2020 United States census, the city was the state's 15th-most-populous municipality, surpassing 2010 #15 Passaic, with a population of 71,686, an increase of 8,662 (+13.7%) from the 2010 census count of 63,024, which in turn reflected an increase of 1,182 (+1.9%) from the 61,842 counted in the 2000 census. The Census Bureau's Population Estimates Program calculated a population of 70,300 for 2023, making it the 541st-most populous municipality in the nation.\\nBayonne was originally formed as a township on April 1, 1861, from portions of Bergen Township. Bayonne was reincorporated as a city by an act of the New Jersey Legislature on March 10, 1869, replacing Bayonne Township, subject to the results of a referendum held nine days later. At the time it was formed, Bayonne included the communities of Bergen Point, Constable Hook, Centreville, Pamrapo and Saltersville.\\nWhile somewhat diminished, traditional manufacturing, distribution, and maritime activities remain a driving force of the economy of the city. A portion of the Port of New York and New Jersey is located there, as is the Cape Liberty Cruise Port.\", 'source': 'https://en.wikipedia.org/wiki/Bayonne,_New_Jersey'}, page_content=\"Bayonne ( bay-(Y)OHN) is a city in Hudson County in the U.S. state of New Jersey. Located in the Gateway Region, Bayonne is situated on a peninsula between Newark Bay to the west, the Kill Van Kull to the south, and New York Bay to the east. As of the 2020 United States census, the city was the state's 15th-most-populous municipality, surpassing 2010 #15 Passaic, with a population of 71,686, an increase of 8,662 (+13.7%) from the 2010 census count of 63,024, which in turn reflected an increase of 1,182 (+1.9%) from the 61,842 counted in the 2000 census. The Census Bureau's Population Estimates Program calculated a population of 70,300 for 2023, making it the 541st-most populous municipality in the nation.\\nBayonne was originally formed as a township on April 1, 1861, from portions of Bergen Township. Bayonne was reincorporated as a city by an act of the New Jersey Legislature on March 10, 1869, replacing Bayonne Township, subject to the results of a referendum held nine days later. At the time it was formed, Bayonne included the communities of Bergen Point, Constable Hook, Centreville, Pamrapo and Saltersville.\\nWhile somewhat diminished, traditional manufacturing, distribution, and maritime activities remain a driving force of the economy of the city. A portion of the Port of New York and New Jersey is located there, as is the Cape Liberty Cruise Port.\\n\\n\\n== History ==\\nOriginally inhabited by Native Americans, the region presently known as Bayonne was claimed by the Netherlands after Henry Hudson explored the Hudson River, which is named after him. According to Royden Page Whitcomb's 1904 book, First History of Bayonne, New Jersey, the name Bayonne is speculated to have originated with Bayonne, France, from which Huguenots settled for a year before the founding of New Amsterdam. However, there is no empirical evidence for this notion. Whitcomb gives more credence to the idea that Erastus Randall, E.C. Bramhall and B.F. Woolsey, who bought the land owned by Jasper and William Cadmus for real estate speculation, named it Bayonne for purposes of real estate speculation, because it was located on the shores of two bays, Newark and New York.\\nBayonne became one of the largest centers in the nation for refining crude oil and Standard Oil of New Jersey's facility—which had grown from its original establishment in 1877—and its 6,000 employees made it the city's largest place of employment. Significant civil unrest arose during the Bayonne refinery strikes of 1915–1916, in which mostly Polish-American workers staged labor actions against Standard Oil of New Jersey and Tidewater Petroleum, seeking improved pay and working conditions. Four striking workers were killed when strikebreakers, allegedly protected by police, fired upon a violent crowd.\\nThe Cape Liberty Cruise Port is a cruise ship terminal that is on a 430-acre (170 ha) site that had been originally developed for industrial uses in the 1930s and then taken over by the U.S. government during World War II as the Military Ocean Terminal at Bayonne. Voyager of the Seas, departing from the cruise terminal in 2004, became the first passenger ship to depart from a port in New Jersey in almost 40 years.\\n\\n\\n== Geography and climate ==\\n\\n\\n=== Geography ===\\n\\nAccording to the United States Census Bureau, the city had a total area of 11.09 square miles (28.72 km2), including 5.82 square miles (15.08 km2) of land and 5.27 square miles (13.64 km2) of water (47.50%).\\nThe city is located on a peninsula earlier known as Bergen Neck surrounded by Upper New York Bay to the east, Newark Bay to the west, and Kill Van Kull to the south. Bayonne is east of Newark, the state's largest city, north of Elizabeth in Union County and west of Brooklyn. It shares a land border with Jersey City to the north and is connected to Staten Island by the Bayonne Bridge.\\nUnincorporated communities, localities and place names located partially or completely within the city include: Bergen Point, Constable Hook and Port Joh\"),\n",
       " Document(metadata={'title': 'Transportation in New Jersey', 'summary': \"Transportation in New Jersey utilizes a combination of road, rail, air, and water modes. New Jersey is situated between Philadelphia and New York City, two major metropolitan centers of the Boston-Washington megalopolis, making it a regional corridor for transportation. As a result, New Jersey's freeways carry high volumes of interstate traffic and products. The main thoroughfare for long distance travel is the New Jersey Turnpike, the nation's fifth-busiest toll road. The Garden State Parkway connects the state's densely populated north to its southern shore region. New Jersey has the 4th smallest area of U.S. states, but its population density of 1,196 persons per sq. mi (462 persons per km2) causes congestion to be a major issue for motorists.\\nNew Jersey has a statewide mass transit system, centered on transportation to New York City and Philadelphia. New Jersey Transit, the chief operator of intrastate public transportation, manages three separate light rail systems, eleven commuter rail lines, and a statewide bus system. The Port Authority Trans-Hudson (PATH) links transportation hubs in Manhattan and northeastern New Jersey, while the PATCO Speedline connects downtown Philadelphia to Camden County, New Jersey. Intercity rail is operated by Amtrak along the Northeast Corridor between the major population centers of the Northeastern United States. In addition, New Jersey is home to Newark Liberty International Airport, the nation's fifth-busiest international gateway, and the Port Newark-Elizabeth Marine Terminal, the principal container ship facility of the New York metropolitan area.\", 'source': 'https://en.wikipedia.org/wiki/Transportation_in_New_Jersey'}, page_content='Transportation in New Jersey utilizes a combination of road, rail, air, and water modes. New Jersey is situated between Philadelphia and New York City, two major metropolitan centers of the Boston-Washington megalopolis, making it a regional corridor for transportation. As a result, New Jersey\\'s freeways carry high volumes of interstate traffic and products. The main thoroughfare for long distance travel is the New Jersey Turnpike, the nation\\'s fifth-busiest toll road. The Garden State Parkway connects the state\\'s densely populated north to its southern shore region. New Jersey has the 4th smallest area of U.S. states, but its population density of 1,196 persons per sq. mi (462 persons per km2) causes congestion to be a major issue for motorists.\\nNew Jersey has a statewide mass transit system, centered on transportation to New York City and Philadelphia. New Jersey Transit, the chief operator of intrastate public transportation, manages three separate light rail systems, eleven commuter rail lines, and a statewide bus system. The Port Authority Trans-Hudson (PATH) links transportation hubs in Manhattan and northeastern New Jersey, while the PATCO Speedline connects downtown Philadelphia to Camden County, New Jersey. Intercity rail is operated by Amtrak along the Northeast Corridor between the major population centers of the Northeastern United States. In addition, New Jersey is home to Newark Liberty International Airport, the nation\\'s fifth-busiest international gateway, and the Port Newark-Elizabeth Marine Terminal, the principal container ship facility of the New York metropolitan area.\\n\\n\\n== Roadways ==\\n\\nNew Jersey has 38,131 miles (61,366 km) of roads managed by state, county, and municipal governments and toll road authorities. The major roadways fall under the jurisdiction of the New Jersey Department of Transportation (NJDOT), which operates the state highway system. State-owned highways and toll roads consist of 7% of road mileage and 66% of traffic volume. In contrast, county and municipal roads consist of 93% of road mileage and 34% of traffic volume.\\n\\nNew Jersey, along with Oregon, is one of only two states which prohibit customers from pumping gasoline at gas stations. (However, Oregon has recently changed the law, allowing self-service at night time in rural areas.) As a result, all gas stations are either full service or minimum service.\\n\\n\\n=== Distinctive features ===\\n\\n\\n==== Jughandles ====\\nAccording to the NJDOT, a jughandle is an \"at-grade ramp\" provided at or between intersections to permit motorists to make indirect left turns and/or U-turns. This design utilizes a setup that requires a motorist to use a ramp off the right lane of the main road in advance of the intersection or beyond the intersection. The NJDOT defines three types of jughandles in its design manual. \"Type A\" is the standard forward jughandle that intersects with a cross street. With forward ramps, all turning traffic (right and left) exit onto a jughandle ramp to the right. \"Type B\" is a variant with no cross-street intersected by the jughandle; it curves 90 degrees left to meet the main street, and is only used at a \"T\" intersection or a U-turn. \"Type C\" is the standard reverse jughandle; left-turning vehicles pass through the intersection and enter a ramp that loops roughly 270 degrees. Jughandles can cause motorist confusion because turning setups are inconsistent among intersections, and such an alignment is unfamiliar to motorists outside of the northeastern United States.\\n\\n\\n==== Traffic circles ====\\n\\nIn the 1920s and 1930s, traffic circles were built throughout the state because they were viewed as an efficient way to move traffic through three or more intersecting roads. As suburban and rural populations grew, the traffic circles became outdated because increased vehicle speed and traffic volume caused them to be more dangerous. Many traffic circles became notorious for having frequent accidents and being confusing, especially for non')]"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "66ac0cf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb1e60a",
   "metadata": {},
   "source": [
    "# Chroma DB Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "553e48b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "d8ce02d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client = chromadb.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "720a88ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chromadb.utils import embedding_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "1cf9d705",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_ef = embedding_functions.DefaultEmbeddingFunction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "75d5fffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "chromadb.utils.embedding_functions.ONNXMiniLM_L6_V2"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(default_ef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "94bcc776",
   "metadata": {},
   "outputs": [],
   "source": [
    "colection_name = \"test_collection\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "4084ff96",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = chroma_client.get_or_create_collection(\n",
    "    colection_name, embedding_function=default_ef\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "c0dd92d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define text documents\n",
    "documents = [\n",
    "    {\"id\": \"doc1\", \"text\": \"Hello, world!\"},\n",
    "    {\"id\": \"doc2\", \"text\": \"How are you today?\"},\n",
    "    {\"id\": \"doc3\", \"text\": \"Goodbye, see you later!\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "8c96fa8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in documents:\n",
    "    collection.upsert(ids=doc[\"id\"], documents=[doc[\"text\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "bb4aa7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a query text\n",
    "query_text = \"Hello, world\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "29e381ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_chroma_db(query: str):\n",
    "    results = collection.query(\n",
    "        query_texts=[query],  # Corrected the variable name\n",
    "        n_results=2,\n",
    "    )\n",
    "    \n",
    "    # Iterate over the results with proper indentation\n",
    "    for idx, document in enumerate(results[\"documents\"][0]):\n",
    "        doc_id = results[\"ids\"][0][idx]\n",
    "        distance = results[\"distances\"][0][idx]\n",
    "        print(\n",
    "            f\"For the query: {query}, \\n\"\n",
    "            f\"Found similar document: {document} (ID: {doc_id}, Distance: {distance})\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "ac214628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the query: Hello, world, \n",
      "Found similar document: Hello, world! (ID: doc1, Distance: 0.12731888890266418)\n",
      "For the query: Hello, world, \n",
      "Found similar document: How are you today? (ID: doc2, Distance: 1.263188362121582)\n"
     ]
    }
   ],
   "source": [
    "search_chroma_db(query_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "00095de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the query: age of earth, \n",
      "Found similar document: Hello, world! (ID: doc1, Distance: 1.6677895784378052)\n",
      "For the query: age of earth, \n",
      "Found similar document: Goodbye, see you later! (ID: doc3, Distance: 1.7939949035644531)\n"
     ]
    }
   ],
   "source": [
    "search_chroma_db(\"age of earth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "dada6dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the query: Hello, world, \n",
      "Found similar document: Hello, world! (ID: doc1, Distance: 0.12731888890266418)\n",
      "For the query: Hello, world, \n",
      "Found similar document: How are you today? (ID: doc2, Distance: 1.263188362121582)\n"
     ]
    }
   ],
   "source": [
    "search_chroma_db(\"Hello, world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "7d1dd604",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [    \n",
    "    {\n",
    "        \"id\": \"doc4\",\n",
    "        \"text\": \"Microsoft is a technology company that develops software. It was founded by Bill Gates and Paul Allen in 1975.\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "7cdb6b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in documents:\n",
    "    collection.upsert(ids=doc[\"id\"], documents=[doc[\"text\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "b886b49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_text = \"find document related to technology company\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "5f5b3e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the query: find document related to technology company, \n",
      "Found similar document: Microsoft is a technology company that develops software. It was founded by Bill Gates and Paul Allen in 1975. (ID: doc4, Distance: 1.3692371845245361)\n",
      "For the query: find document related to technology company, \n",
      "Found similar document: Goodbye, see you later! (ID: doc3, Distance: 1.9923689365386963)\n"
     ]
    }
   ],
   "source": [
    "search_chroma_db(query_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "5eab9c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chromadb.utils import embedding_functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "40ac0ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_ef = embedding_functions.DefaultEmbeddingFunction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "f3347d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Hello\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "bf92b0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = default_ef(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "452cc336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-0.057101599872112274,\n",
       "  0.09410139173269272,\n",
       "  -0.042961250990629196,\n",
       "  0.015190397389233112,\n",
       "  0.003590941894799471,\n",
       "  0.019870730116963387,\n",
       "  0.08121775090694427,\n",
       "  0.037185512483119965,\n",
       "  -0.01011547539383173,\n",
       "  -0.05368809401988983,\n",
       "  0.061433643102645874,\n",
       "  -0.09885642677545547,\n",
       "  -0.02234482765197754,\n",
       "  -0.06459888070821762,\n",
       "  -0.01261056587100029,\n",
       "  -0.0023362324573099613,\n",
       "  -0.07551310211420059,\n",
       "  -0.009480354376137257,\n",
       "  -0.059548620134592056,\n",
       "  -0.07525584846735,\n",
       "  -0.06103133037686348,\n",
       "  0.023791328072547913,\n",
       "  0.022302620112895966,\n",
       "  0.017092231661081314,\n",
       "  -0.0524519644677639,\n",
       "  0.05123633146286011,\n",
       "  0.008438421413302422,\n",
       "  0.062142882496118546,\n",
       "  -0.019462935626506805,\n",
       "  -0.09673572331666946,\n",
       "  -0.002981971949338913,\n",
       "  0.0025748549960553646,\n",
       "  0.1014222726225853,\n",
       "  -0.01917104236781597,\n",
       "  0.000771118386182934,\n",
       "  -0.025375474244356155,\n",
       "  -0.023148272186517715,\n",
       "  -0.10248353332281113,\n",
       "  -0.014852477237582207,\n",
       "  0.018474869430065155,\n",
       "  -0.03515508025884628,\n",
       "  -0.039103034883737564,\n",
       "  -0.00798714254051447,\n",
       "  0.047611527144908905,\n",
       "  0.016404222697019577,\n",
       "  -0.007175438571721315,\n",
       "  0.052973076701164246,\n",
       "  -0.022651351988315582,\n",
       "  -0.053060226142406464,\n",
       "  0.02168041653931141,\n",
       "  -0.02170492336153984,\n",
       "  -0.0390322208404541,\n",
       "  -0.003123730653896928,\n",
       "  -0.014141090214252472,\n",
       "  0.026870016008615494,\n",
       "  0.024879243224859238,\n",
       "  -0.004713570233434439,\n",
       "  0.024100080132484436,\n",
       "  0.022936321794986725,\n",
       "  -0.04010351747274399,\n",
       "  -0.11531778424978256,\n",
       "  0.014522910118103027,\n",
       "  -0.08280417323112488,\n",
       "  0.016517817974090576,\n",
       "  0.0508403405547142,\n",
       "  -0.0012755318311974406,\n",
       "  -0.006789376959204674,\n",
       "  -0.03063589334487915,\n",
       "  -0.044502951204776764,\n",
       "  0.03477824106812477,\n",
       "  0.041241440922021866,\n",
       "  -0.04102723300457001,\n",
       "  -0.04225902259349823,\n",
       "  -0.1104942187666893,\n",
       "  0.019330430775880814,\n",
       "  -0.09888938069343567,\n",
       "  0.019618064165115356,\n",
       "  -0.08531319350004196,\n",
       "  0.11856995522975922,\n",
       "  0.018448643386363983,\n",
       "  0.013308580033481121,\n",
       "  -0.0067839245311915874,\n",
       "  -0.028984859585762024,\n",
       "  0.09026149660348892,\n",
       "  0.006888445466756821,\n",
       "  0.054924458265304565,\n",
       "  -0.03518732264637947,\n",
       "  -0.02385326474905014,\n",
       "  -0.006462961435317993,\n",
       "  -0.011949506588280201,\n",
       "  -0.12386231124401093,\n",
       "  -0.06763093918561935,\n",
       "  -0.016301313415169716,\n",
       "  0.014269613660871983,\n",
       "  -0.1212967038154602,\n",
       "  0.02072855830192566,\n",
       "  0.06033787503838539,\n",
       "  0.03566567227244377,\n",
       "  -0.047034405171871185,\n",
       "  0.23194529116153717,\n",
       "  -0.013501545414328575,\n",
       "  -0.009213489480316639,\n",
       "  -0.020230941474437714,\n",
       "  0.08437562733888626,\n",
       "  -0.013293991796672344,\n",
       "  0.030246520414948463,\n",
       "  -0.024963144212961197,\n",
       "  0.093161940574646,\n",
       "  0.0643090158700943,\n",
       "  0.0329909510910511,\n",
       "  -0.04558416083455086,\n",
       "  0.002113018184900284,\n",
       "  -0.03087802231311798,\n",
       "  -0.012226429767906666,\n",
       "  0.03455318138003349,\n",
       "  -0.0005840446683578193,\n",
       "  0.025799956172704697,\n",
       "  -0.03928773105144501,\n",
       "  0.0012134751304984093,\n",
       "  -0.05738120153546333,\n",
       "  0.037459567189216614,\n",
       "  -0.01925063319504261,\n",
       "  0.042733509093523026,\n",
       "  0.00010614994971547276,\n",
       "  -0.013660947792232037,\n",
       "  -0.09473036974668503,\n",
       "  -0.02011360414326191,\n",
       "  -4.5756253522291855e-33,\n",
       "  0.023980313912034035,\n",
       "  -0.027398768812417984,\n",
       "  -0.0004339801089372486,\n",
       "  0.026821667328476906,\n",
       "  0.010937104932963848,\n",
       "  0.022311843931674957,\n",
       "  -0.08238247036933899,\n",
       "  0.01725919172167778,\n",
       "  -0.005531331989914179,\n",
       "  -0.006867786403745413,\n",
       "  -0.06279291212558746,\n",
       "  -0.06165233999490738,\n",
       "  -0.07787932455539703,\n",
       "  -0.04528333619236946,\n",
       "  0.011105249635875225,\n",
       "  -0.036036331206560135,\n",
       "  0.01715078391134739,\n",
       "  0.052576445043087006,\n",
       "  -0.04641800746321678,\n",
       "  0.031425684690475464,\n",
       "  -0.03278039023280144,\n",
       "  0.058319091796875,\n",
       "  -0.021886073052883148,\n",
       "  0.029704542830586433,\n",
       "  0.006169121712446213,\n",
       "  -0.08477264642715454,\n",
       "  0.002207857323810458,\n",
       "  -0.07319650053977966,\n",
       "  0.04720587283372879,\n",
       "  0.03576228395104408,\n",
       "  0.06052927300333977,\n",
       "  -0.020710580050945282,\n",
       "  0.007143753115087748,\n",
       "  -0.04296353459358215,\n",
       "  -0.04005533456802368,\n",
       "  0.0035678776912391186,\n",
       "  -0.01685299538075924,\n",
       "  0.031458642333745956,\n",
       "  -0.0150523129850626,\n",
       "  -0.08853255212306976,\n",
       "  0.01678825542330742,\n",
       "  0.04116538166999817,\n",
       "  0.03827618062496185,\n",
       "  -0.019870225340127945,\n",
       "  0.08163782954216003,\n",
       "  0.09932877123355865,\n",
       "  0.11280146986246109,\n",
       "  0.011497598141431808,\n",
       "  -0.030832890421152115,\n",
       "  0.011492892168462276,\n",
       "  -0.03033442795276642,\n",
       "  -0.019279055297374725,\n",
       "  -0.034647680819034576,\n",
       "  0.0017975126393139362,\n",
       "  0.04421455040574074,\n",
       "  -0.015982739627361298,\n",
       "  0.01166261825710535,\n",
       "  0.025140270590782166,\n",
       "  0.09481507539749146,\n",
       "  0.053898993879556656,\n",
       "  0.0548156276345253,\n",
       "  0.10935790091753006,\n",
       "  0.0008241100586019456,\n",
       "  0.0931815356016159,\n",
       "  -0.01645435392856598,\n",
       "  -0.0617666020989418,\n",
       "  -0.050922710448503494,\n",
       "  -0.048134252429008484,\n",
       "  0.032822877168655396,\n",
       "  0.023130977526307106,\n",
       "  -0.05299588665366173,\n",
       "  0.022545691579580307,\n",
       "  0.11254411935806274,\n",
       "  -0.0006435622344724834,\n",
       "  -0.07569669932126999,\n",
       "  -0.017046930268406868,\n",
       "  -0.036231230944395065,\n",
       "  0.006509589031338692,\n",
       "  -0.024340437725186348,\n",
       "  -0.025281621143221855,\n",
       "  -0.036635495722293854,\n",
       "  -0.01273028738796711,\n",
       "  0.0301851574331522,\n",
       "  0.019887343049049377,\n",
       "  0.04906637966632843,\n",
       "  -0.02600974217057228,\n",
       "  -0.04039008542895317,\n",
       "  -0.07056121528148651,\n",
       "  -0.035242579877376556,\n",
       "  0.003947531804442406,\n",
       "  -0.08423998206853867,\n",
       "  0.026786793023347855,\n",
       "  0.09666524082422256,\n",
       "  -0.06861123442649841,\n",
       "  -0.02327757701277733,\n",
       "  3.969274142006356e-33,\n",
       "  -0.045012280344963074,\n",
       "  0.06840187311172485,\n",
       "  -0.09376776963472366,\n",
       "  0.026704203337430954,\n",
       "  -0.016570422798395157,\n",
       "  0.07660296559333801,\n",
       "  0.017170879989862442,\n",
       "  0.036227691918611526,\n",
       "  -0.040505535900592804,\n",
       "  -0.03191552311182022,\n",
       "  0.047128550708293915,\n",
       "  -0.03176673501729965,\n",
       "  0.021140653640031815,\n",
       "  -0.05031100660562515,\n",
       "  0.023945944383740425,\n",
       "  0.05597139522433281,\n",
       "  0.004210072103887796,\n",
       "  -0.018325885757803917,\n",
       "  -0.0811300128698349,\n",
       "  0.07353798300027847,\n",
       "  -0.035978060215711594,\n",
       "  -0.05355408415198326,\n",
       "  -0.0633278340101242,\n",
       "  0.04657234996557236,\n",
       "  0.00442356476560235,\n",
       "  0.06494923681020737,\n",
       "  0.05818591266870499,\n",
       "  0.09626732021570206,\n",
       "  0.04435727745294571,\n",
       "  0.05746598169207573,\n",
       "  0.01976499892771244,\n",
       "  -0.03358987718820572,\n",
       "  -0.0670095756649971,\n",
       "  0.012891639955341816,\n",
       "  0.02841787599027157,\n",
       "  0.07100873440504074,\n",
       "  0.014105204492807388,\n",
       "  0.07723357528448105,\n",
       "  0.0057245418429374695,\n",
       "  -0.030606798827648163,\n",
       "  0.02439035475254059,\n",
       "  -0.06264092028141022,\n",
       "  0.07391219586133957,\n",
       "  0.10155420005321503,\n",
       "  0.014630235731601715,\n",
       "  0.06682660430669785,\n",
       "  -0.07468672096729279,\n",
       "  0.003634978551417589,\n",
       "  -0.05821507051587105,\n",
       "  0.052618253976106644,\n",
       "  -0.060615424066782,\n",
       "  -0.06255665421485901,\n",
       "  -0.04436402767896652,\n",
       "  -0.04083038493990898,\n",
       "  -0.03980914130806923,\n",
       "  0.055231839418411255,\n",
       "  -0.025152554735541344,\n",
       "  0.0742335170507431,\n",
       "  -0.002103830222040415,\n",
       "  0.014180063270032406,\n",
       "  0.0064979721792042255,\n",
       "  0.07913756370544434,\n",
       "  0.009674206376075745,\n",
       "  0.11580558866262436,\n",
       "  -0.07880311459302902,\n",
       "  -0.02555243857204914,\n",
       "  -0.02435653656721115,\n",
       "  -0.04761212691664696,\n",
       "  -0.035457536578178406,\n",
       "  -0.033068325370550156,\n",
       "  0.09798815846443176,\n",
       "  0.0441441610455513,\n",
       "  0.0010037256870418787,\n",
       "  -0.008229212835431099,\n",
       "  -0.02321751043200493,\n",
       "  -0.05955180898308754,\n",
       "  -0.00436005275696516,\n",
       "  0.020492153242230415,\n",
       "  0.003267605323344469,\n",
       "  -0.015329662710428238,\n",
       "  -0.06241380795836449,\n",
       "  0.07348652184009552,\n",
       "  -0.010514995083212852,\n",
       "  0.003319562878459692,\n",
       "  0.008013518527150154,\n",
       "  -0.047257911413908005,\n",
       "  -0.016264792531728745,\n",
       "  -0.035962335765361786,\n",
       "  0.015926826745271683,\n",
       "  -0.0033836006186902523,\n",
       "  0.030168980360031128,\n",
       "  0.08681318908929825,\n",
       "  0.06900852918624878,\n",
       "  -0.04578911140561104,\n",
       "  0.01904691569507122,\n",
       "  -1.336698307596862e-08,\n",
       "  0.00975171197205782,\n",
       "  -0.09547001868486404,\n",
       "  0.07617330551147461,\n",
       "  -0.011770113371312618,\n",
       "  0.11781103163957596,\n",
       "  0.0529048852622509,\n",
       "  -0.009852686896920204,\n",
       "  0.01151205413043499,\n",
       "  0.010884004645049572,\n",
       "  0.08178164064884186,\n",
       "  0.038341015577316284,\n",
       "  0.033838216215372086,\n",
       "  0.0129002146422863,\n",
       "  -0.031525660306215286,\n",
       "  -0.0034941518679261208,\n",
       "  -0.08643679320812225,\n",
       "  -0.06015578284859657,\n",
       "  0.018638350069522858,\n",
       "  -0.02893148735165596,\n",
       "  -0.06242663785815239,\n",
       "  -0.002517238026484847,\n",
       "  -0.004757234826683998,\n",
       "  -0.006527971476316452,\n",
       "  0.04354116693139076,\n",
       "  -0.01524011418223381,\n",
       "  -0.015876529738307,\n",
       "  -0.03182457387447357,\n",
       "  -0.02635413408279419,\n",
       "  0.06471499800682068,\n",
       "  -0.04407351091504097,\n",
       "  0.02908606082201004,\n",
       "  0.15741626918315887,\n",
       "  -0.0031368343625217676,\n",
       "  0.010616754181683064,\n",
       "  0.06530516594648361,\n",
       "  -0.014646596275269985,\n",
       "  0.02534162998199463,\n",
       "  0.0939142182469368,\n",
       "  -0.026180047541856766,\n",
       "  0.0853218138217926,\n",
       "  0.0031590701546519995,\n",
       "  0.00794202834367752,\n",
       "  0.03889121115207672,\n",
       "  -0.029187651351094246,\n",
       "  0.035182636231184006,\n",
       "  0.011342891491949558,\n",
       "  -0.06913056969642639,\n",
       "  0.032017674297094345,\n",
       "  0.02326871082186699,\n",
       "  -0.044522177428007126,\n",
       "  -0.028845151886343956,\n",
       "  -0.001113766455091536,\n",
       "  0.04584403708577156,\n",
       "  0.03917678818106651,\n",
       "  0.058882251381874084,\n",
       "  0.025637660175561905,\n",
       "  0.06737833470106125,\n",
       "  -0.020057382062077522,\n",
       "  -0.010681630112230778,\n",
       "  -0.018690239638090134,\n",
       "  0.19257129728794098,\n",
       "  0.05559209734201431,\n",
       "  0.01427934318780899,\n",
       "  0.049306537955999374],\n",
       " [-0.01528916321694851,\n",
       "  0.052264146506786346,\n",
       "  0.04121923819184303,\n",
       "  0.05939606577157974,\n",
       "  -0.03604060038924217,\n",
       "  -0.009499766863882542,\n",
       "  0.1322360336780548,\n",
       "  0.03249482810497284,\n",
       "  0.024453705176711082,\n",
       "  0.007388410624116659,\n",
       "  0.029245983809232712,\n",
       "  -0.12305192649364471,\n",
       "  -0.0009322963887825608,\n",
       "  0.0500282347202301,\n",
       "  0.0013556050835177302,\n",
       "  0.01643039844930172,\n",
       "  -0.05047090724110603,\n",
       "  -0.04722829535603523,\n",
       "  -0.10079920291900635,\n",
       "  -0.04846803843975067,\n",
       "  -0.03400041535496712,\n",
       "  -0.010491529479622841,\n",
       "  0.03028017468750477,\n",
       "  0.023427873849868774,\n",
       "  -0.050212424248456955,\n",
       "  -0.00259088771417737,\n",
       "  0.022762659937143326,\n",
       "  0.08005520701408386,\n",
       "  -0.05276620760560036,\n",
       "  -0.11778128892183304,\n",
       "  0.028008323162794113,\n",
       "  0.021962035447359085,\n",
       "  0.06121442839503288,\n",
       "  0.003465940011665225,\n",
       "  0.005394040606915951,\n",
       "  -0.07024959474802017,\n",
       "  0.019926052540540695,\n",
       "  -0.06271391361951828,\n",
       "  -0.03060361184179783,\n",
       "  0.007687403820455074,\n",
       "  -0.07309124618768692,\n",
       "  -0.06422434002161026,\n",
       "  0.0717550590634346,\n",
       "  -0.0004293532983865589,\n",
       "  0.05425773188471794,\n",
       "  -0.039094772189855576,\n",
       "  0.00276442663744092,\n",
       "  0.016942525282502174,\n",
       "  -0.030964083969593048,\n",
       "  -0.10143613815307617,\n",
       "  0.039068300276994705,\n",
       "  -0.030924949795007706,\n",
       "  -0.10945397615432739,\n",
       "  -0.05427585542201996,\n",
       "  0.03653718903660774,\n",
       "  -0.024103932082653046,\n",
       "  -0.02575174905359745,\n",
       "  -0.02837578020989895,\n",
       "  0.007056586444377899,\n",
       "  0.03119766339659691,\n",
       "  -0.016835089772939682,\n",
       "  -0.028903894126415253,\n",
       "  -0.12173476070165634,\n",
       "  0.0560012012720108,\n",
       "  -0.028273621574044228,\n",
       "  -0.012333650141954422,\n",
       "  0.059929072856903076,\n",
       "  -0.0591156929731369,\n",
       "  -0.050111304968595505,\n",
       "  -0.006011870224028826,\n",
       "  -0.00046039806329645216,\n",
       "  -0.046612102538347244,\n",
       "  -0.08088693767786026,\n",
       "  -0.0071166628040373325,\n",
       "  0.06175893917679787,\n",
       "  0.02542661502957344,\n",
       "  2.7831682018586434e-05,\n",
       "  -0.0058602686040103436,\n",
       "  0.0083137983456254,\n",
       "  0.08911764621734619,\n",
       "  -0.028650671243667603,\n",
       "  -0.04216400161385536,\n",
       "  -0.04751210659742355,\n",
       "  -0.017447544261813164,\n",
       "  -0.02026667445898056,\n",
       "  0.043806981295347214,\n",
       "  0.016914252191781998,\n",
       "  0.03219149634242058,\n",
       "  0.028922658413648605,\n",
       "  0.023889558389782906,\n",
       "  -0.06092369928956032,\n",
       "  -0.06417816132307053,\n",
       "  0.09943558275699615,\n",
       "  0.061623308807611465,\n",
       "  0.007984628900885582,\n",
       "  0.026637643575668335,\n",
       "  0.009793346747756004,\n",
       "  -0.034891627728939056,\n",
       "  -0.07444504648447037,\n",
       "  0.24253548681735992,\n",
       "  -0.010016669519245625,\n",
       "  0.0672236979007721,\n",
       "  -0.027669943869113922,\n",
       "  0.07208635658025742,\n",
       "  -0.019244123250246048,\n",
       "  -0.015124152414500713,\n",
       "  0.06371122598648071,\n",
       "  0.014282913878560066,\n",
       "  -0.0036761495284736156,\n",
       "  0.020516565069556236,\n",
       "  -0.04808531329035759,\n",
       "  -0.09649728983640671,\n",
       "  -0.05809357762336731,\n",
       "  -0.051430635154247284,\n",
       "  -0.041007161140441895,\n",
       "  0.04702521115541458,\n",
       "  -0.0030103777535259724,\n",
       "  0.00030181516194716096,\n",
       "  0.03961419686675072,\n",
       "  0.03402077034115791,\n",
       "  0.041723888367414474,\n",
       "  0.027821224182844162,\n",
       "  -0.03175493702292442,\n",
       "  0.06685733795166016,\n",
       "  0.020543547347187996,\n",
       "  -0.09164596349000931,\n",
       "  0.05898972600698471,\n",
       "  -3.7599854543661095e-33,\n",
       "  0.030257930979132652,\n",
       "  -0.03546449914574623,\n",
       "  0.013183224014937878,\n",
       "  -0.01223787385970354,\n",
       "  0.03781327232718468,\n",
       "  0.12842883169651031,\n",
       "  -0.07259517908096313,\n",
       "  -0.02158503234386444,\n",
       "  -0.06290730834007263,\n",
       "  -0.08350524306297302,\n",
       "  -0.08580528944730759,\n",
       "  0.055147286504507065,\n",
       "  0.007106615696102381,\n",
       "  0.0618753507733345,\n",
       "  0.10168537497520447,\n",
       "  -0.009043358266353607,\n",
       "  0.05563591048121452,\n",
       "  0.03713392838835716,\n",
       "  -0.024374984204769135,\n",
       "  -0.05634399875998497,\n",
       "  0.007772074081003666,\n",
       "  0.02077588066458702,\n",
       "  0.033552225679159164,\n",
       "  0.031690653413534164,\n",
       "  -0.040792252868413925,\n",
       "  -0.09412398189306259,\n",
       "  -0.023175768554210663,\n",
       "  -0.0634402334690094,\n",
       "  0.02022034488618374,\n",
       "  0.017279403284192085,\n",
       "  -0.013305955566465855,\n",
       "  0.016719665378332138,\n",
       "  -0.031560808420181274,\n",
       "  0.023006994277238846,\n",
       "  -0.02548501081764698,\n",
       "  -0.0630374625325203,\n",
       "  0.08202365785837173,\n",
       "  0.004592126701027155,\n",
       "  0.025362789630889893,\n",
       "  -0.007799255196005106,\n",
       "  -0.018773153424263,\n",
       "  0.0396752692759037,\n",
       "  -0.010112205520272255,\n",
       "  0.01701100915670395,\n",
       "  0.033549778163433075,\n",
       "  0.07156988978385925,\n",
       "  0.048241026699543,\n",
       "  -0.02616279013454914,\n",
       "  0.048690833151340485,\n",
       "  0.03401225805282593,\n",
       "  0.01243001502007246,\n",
       "  -0.019054502248764038,\n",
       "  -0.04423564672470093,\n",
       "  -0.004105695988982916,\n",
       "  -0.0328950509428978,\n",
       "  0.004819283727556467,\n",
       "  -0.0003340210241731256,\n",
       "  0.04825245961546898,\n",
       "  0.06317293643951416,\n",
       "  -0.03382208198308945,\n",
       "  0.10358484834432602,\n",
       "  0.1470172107219696,\n",
       "  0.01972932741045952,\n",
       "  -0.0106862373650074,\n",
       "  -0.02237868867814541,\n",
       "  -0.04030165821313858,\n",
       "  0.007112372666597366,\n",
       "  -0.037821900099515915,\n",
       "  0.027895597741007805,\n",
       "  -0.027204953134059906,\n",
       "  -0.049675993621349335,\n",
       "  -0.0007770964875817299,\n",
       "  0.14445805549621582,\n",
       "  -0.03587488830089569,\n",
       "  -0.009092288091778755,\n",
       "  -0.04018207639455795,\n",
       "  -0.05644017457962036,\n",
       "  0.015974136069417,\n",
       "  0.01288231648504734,\n",
       "  0.01907539740204811,\n",
       "  -0.06486118584871292,\n",
       "  -0.019494887441396713,\n",
       "  -0.05491671338677406,\n",
       "  0.0523274727165699,\n",
       "  0.020605316385626793,\n",
       "  -0.014460546895861626,\n",
       "  -0.02298852615058422,\n",
       "  -0.02505600079894066,\n",
       "  0.03479481860995293,\n",
       "  -0.010077309794723988,\n",
       "  -0.03859817981719971,\n",
       "  -0.004017723258584738,\n",
       "  -0.015729717910289764,\n",
       "  -0.002535776933655143,\n",
       "  0.01796458475291729,\n",
       "  2.709432010369823e-33,\n",
       "  0.0038843629881739616,\n",
       "  0.06719676405191422,\n",
       "  -0.04541197046637535,\n",
       "  0.11405421048402786,\n",
       "  -0.004357371479272842,\n",
       "  0.04133017733693123,\n",
       "  0.0463084951043129,\n",
       "  0.004587309435009956,\n",
       "  -0.008216666989028454,\n",
       "  0.062331315129995346,\n",
       "  0.023686597123742104,\n",
       "  -0.0549340583384037,\n",
       "  0.07182057201862335,\n",
       "  -0.04160413518548012,\n",
       "  0.01811358518898487,\n",
       "  0.017167583107948303,\n",
       "  0.011091522872447968,\n",
       "  -0.001975737977772951,\n",
       "  0.01823459006845951,\n",
       "  0.05884309858083725,\n",
       "  0.004345666151493788,\n",
       "  -0.03639429435133934,\n",
       "  -0.007598055060952902,\n",
       "  0.028991403058171272,\n",
       "  0.029803523793816566,\n",
       "  0.09257173538208008,\n",
       "  0.020941058173775673,\n",
       "  0.05978478491306305,\n",
       "  -0.08122568577528,\n",
       "  0.02580084465444088,\n",
       "  0.020275453105568886,\n",
       "  -0.05451415106654167,\n",
       "  -0.025862371549010277,\n",
       "  0.03778025880455971,\n",
       "  -0.012760736979544163,\n",
       "  0.1268511861562729,\n",
       "  0.06652574241161346,\n",
       "  -0.04896164312958717,\n",
       "  -0.015287677757441998,\n",
       "  -0.03342787176370621,\n",
       "  0.04058156907558441,\n",
       "  0.03699370473623276,\n",
       "  0.05875760316848755,\n",
       "  0.13738864660263062,\n",
       "  0.02473788522183895,\n",
       "  -0.0005298710311762989,\n",
       "  -0.054580334573984146,\n",
       "  0.09167392551898956,\n",
       "  0.05982588976621628,\n",
       "  0.026891695335507393,\n",
       "  -0.07127152383327484,\n",
       "  0.004532730206847191,\n",
       "  -0.12719018757343292,\n",
       "  -0.06562875956296921,\n",
       "  -0.05287662893533707,\n",
       "  0.05502995103597641,\n",
       "  -0.0033297166228294373,\n",
       "  0.01260562427341938,\n",
       "  -0.00715065049007535,\n",
       "  -0.04904112592339516,\n",
       "  0.06959971785545349,\n",
       "  0.04013688489794731,\n",
       "  0.029979348182678223,\n",
       "  0.002949897665530443,\n",
       "  -0.05232258513569832,\n",
       "  -0.03259766101837158,\n",
       "  -0.05123103782534599,\n",
       "  -0.031021827831864357,\n",
       "  -0.01931740902364254,\n",
       "  -0.022550441324710846,\n",
       "  0.14692899584770203,\n",
       "  -0.02354069985449314,\n",
       "  -0.11175405979156494,\n",
       "  -0.062109604477882385,\n",
       "  -0.0377470962703228,\n",
       "  -0.00638879369944334,\n",
       "  -0.04206068813800812,\n",
       "  -0.051765356212854385,\n",
       "  0.016226744279265404,\n",
       "  -0.03775409236550331,\n",
       "  -0.10068561136722565,\n",
       "  -0.0012107519432902336,\n",
       "  0.007352974731475115,\n",
       "  0.023526189848780632,\n",
       "  0.023350434377789497,\n",
       "  -0.013452633284032345,\n",
       "  -0.02806662954390049,\n",
       "  -0.0006871393998153508,\n",
       "  0.018404915928840637,\n",
       "  -0.024048175662755966,\n",
       "  0.028444824740290642,\n",
       "  0.069053515791893,\n",
       "  0.07986601442098618,\n",
       "  0.010906549170613289,\n",
       "  0.09737736731767654,\n",
       "  -1.5029678834821425e-08,\n",
       "  0.05222446843981743,\n",
       "  0.014810686931014061,\n",
       "  0.051615770906209946,\n",
       "  0.0022532467264682055,\n",
       "  0.1042991504073143,\n",
       "  -0.07874099165201187,\n",
       "  -0.012502225115895271,\n",
       "  -0.02099038101732731,\n",
       "  0.0047953189350664616,\n",
       "  -0.025529388338327408,\n",
       "  0.05455473065376282,\n",
       "  0.008104131557047367,\n",
       "  0.041415974497795105,\n",
       "  0.07706019282341003,\n",
       "  -0.010101121850311756,\n",
       "  -0.062303803861141205,\n",
       "  0.0017798912012949586,\n",
       "  0.03965195640921593,\n",
       "  -0.011026554740965366,\n",
       "  -0.017165714874863625,\n",
       "  -0.02071659453213215,\n",
       "  -0.0011506552109494805,\n",
       "  0.0113664036616683,\n",
       "  -0.07270997762680054,\n",
       "  -0.07050923258066177,\n",
       "  0.016195710748434067,\n",
       "  -0.018611446022987366,\n",
       "  0.06601633131504059,\n",
       "  0.012306977063417435,\n",
       "  -0.017130045220255852,\n",
       "  -0.03481781482696533,\n",
       "  0.0004574860795401037,\n",
       "  0.01331008318811655,\n",
       "  -0.04399699345231056,\n",
       "  -0.03268464282155037,\n",
       "  -0.00787897128611803,\n",
       "  -0.006077377125620842,\n",
       "  -0.004088658839464188,\n",
       "  -0.06251543015241623,\n",
       "  0.125512033700943,\n",
       "  -0.01676669716835022,\n",
       "  -0.08166208118200302,\n",
       "  0.0637408196926117,\n",
       "  -0.05958402529358864,\n",
       "  -0.041349172592163086,\n",
       "  0.029607579112052917,\n",
       "  -0.03216784819960594,\n",
       "  -0.0115894116461277,\n",
       "  0.01681160368025303,\n",
       "  -0.09783093631267548,\n",
       "  -0.04399559646844864,\n",
       "  -0.042040638625621796,\n",
       "  0.0428287535905838,\n",
       "  0.024225112050771713,\n",
       "  0.021756796166300774,\n",
       "  -0.024489009752869606,\n",
       "  -0.012173761613667011,\n",
       "  0.028692202642560005,\n",
       "  -0.04224763810634613,\n",
       "  0.02198834903538227,\n",
       "  0.17061860859394073,\n",
       "  -0.011161291971802711,\n",
       "  -0.00367528828792274,\n",
       "  0.012628123164176941],\n",
       " [-0.029210345819592476,\n",
       "  -0.008136079646646976,\n",
       "  0.03420504927635193,\n",
       "  0.040295638144016266,\n",
       "  0.07426188886165619,\n",
       "  0.05922502279281616,\n",
       "  0.08180953562259674,\n",
       "  0.037137407809495926,\n",
       "  0.03291481360793114,\n",
       "  -0.031437069177627563,\n",
       "  0.06003862991929054,\n",
       "  -0.07254356890916824,\n",
       "  0.024705301970243454,\n",
       "  -0.004340925253927708,\n",
       "  -0.013213634490966797,\n",
       "  0.01841089315712452,\n",
       "  -0.0830569714307785,\n",
       "  -0.014857972972095013,\n",
       "  -0.12271389365196228,\n",
       "  0.0023262533359229565,\n",
       "  -0.033769749104976654,\n",
       "  0.027208684012293816,\n",
       "  -0.02078929729759693,\n",
       "  0.02001940831542015,\n",
       "  -0.01195460557937622,\n",
       "  -0.016626928001642227,\n",
       "  -0.021979203447699547,\n",
       "  -0.0048761810176074505,\n",
       "  0.0012886925833299756,\n",
       "  -0.08734933286905289,\n",
       "  0.007423582021147013,\n",
       "  0.11303859204053879,\n",
       "  0.05859524756669998,\n",
       "  -0.019217269495129585,\n",
       "  0.017139490693807602,\n",
       "  -0.07475004345178604,\n",
       "  -0.07950093597173691,\n",
       "  -0.058088261634111404,\n",
       "  0.03741072118282318,\n",
       "  0.05945615470409393,\n",
       "  -0.08294060826301575,\n",
       "  -0.0891818106174469,\n",
       "  0.03647366911172867,\n",
       "  -0.029225805774331093,\n",
       "  -0.0008361548534594476,\n",
       "  -0.026880696415901184,\n",
       "  -0.03130786493420601,\n",
       "  -0.009517751634120941,\n",
       "  -0.03412143886089325,\n",
       "  0.02407819591462612,\n",
       "  0.01013795007020235,\n",
       "  -0.007920147851109505,\n",
       "  -0.039895687252283096,\n",
       "  0.008829214610159397,\n",
       "  -0.0834297463297844,\n",
       "  -0.009849640540778637,\n",
       "  -0.07375919073820114,\n",
       "  0.03378712385892868,\n",
       "  0.05167929455637932,\n",
       "  0.026601599529385567,\n",
       "  -0.041304826736450195,\n",
       "  0.08046966046094894,\n",
       "  -0.11150691658258438,\n",
       "  0.07736308127641678,\n",
       "  -0.02570829913020134,\n",
       "  0.047470398247241974,\n",
       "  0.029889818280935287,\n",
       "  -0.009334547445178032,\n",
       "  -0.0023373544681817293,\n",
       "  0.03722880408167839,\n",
       "  -0.006874643731862307,\n",
       "  -0.029843822121620178,\n",
       "  -0.00025061596534214914,\n",
       "  -0.037283755838871,\n",
       "  0.08152831345796585,\n",
       "  -0.008404563181102276,\n",
       "  0.05313148722052574,\n",
       "  -0.0691046416759491,\n",
       "  0.009290182963013649,\n",
       "  0.00986396986991167,\n",
       "  0.00040824757888913155,\n",
       "  0.02940952219069004,\n",
       "  -0.09752608090639114,\n",
       "  0.02366202138364315,\n",
       "  -0.08437427133321762,\n",
       "  -0.019076097756624222,\n",
       "  -0.032881781458854675,\n",
       "  0.061567798256874084,\n",
       "  0.029156535863876343,\n",
       "  -0.019742436707019806,\n",
       "  -0.013563971035182476,\n",
       "  -0.053020648658275604,\n",
       "  -0.01327479723840952,\n",
       "  0.039495620876550674,\n",
       "  -0.04668426141142845,\n",
       "  0.01330205611884594,\n",
       "  0.08526203781366348,\n",
       "  -0.060894060879945755,\n",
       "  -0.07038620114326477,\n",
       "  0.26119372248649597,\n",
       "  0.03365139290690422,\n",
       "  0.05668490007519722,\n",
       "  -0.008424963802099228,\n",
       "  0.06896039098501205,\n",
       "  -0.04096302390098572,\n",
       "  -0.014684862457215786,\n",
       "  -0.02363336831331253,\n",
       "  0.029228568077087402,\n",
       "  -0.0003930261009372771,\n",
       "  -0.05965803191065788,\n",
       "  0.032574281096458435,\n",
       "  -0.0002906881563831121,\n",
       "  0.025960301980376244,\n",
       "  0.026114419102668762,\n",
       "  0.007866919972002506,\n",
       "  -0.04794005677103996,\n",
       "  0.026390770450234413,\n",
       "  -0.08495408296585083,\n",
       "  0.007937341928482056,\n",
       "  -0.01850290223956108,\n",
       "  0.10609831660985947,\n",
       "  -0.04497348517179489,\n",
       "  -0.05770345404744148,\n",
       "  -0.0002425768761895597,\n",
       "  -0.03897979110479355,\n",
       "  -0.07212404161691666,\n",
       "  0.017694924026727676,\n",
       "  -4.757851955861595e-33,\n",
       "  0.0326862633228302,\n",
       "  -0.003990126773715019,\n",
       "  0.03518329933285713,\n",
       "  -0.005888605955988169,\n",
       "  0.04369904473423958,\n",
       "  0.05856825038790703,\n",
       "  -0.059868186712265015,\n",
       "  0.011806056834757328,\n",
       "  -0.0812859833240509,\n",
       "  0.055700093507766724,\n",
       "  -0.054146550595760345,\n",
       "  0.046555470675230026,\n",
       "  -0.06937884539365768,\n",
       "  0.0034098217729479074,\n",
       "  0.0645420253276825,\n",
       "  0.06285574287176132,\n",
       "  0.05009740591049194,\n",
       "  0.022991729900240898,\n",
       "  -0.033388737589120865,\n",
       "  0.012444930151104927,\n",
       "  -0.026966817677021027,\n",
       "  0.03426383063197136,\n",
       "  0.0031661642715334892,\n",
       "  0.04734795168042183,\n",
       "  -0.014649293385446072,\n",
       "  -0.03517652675509453,\n",
       "  0.06358019262552261,\n",
       "  -0.07909435778856277,\n",
       "  -0.002110628178343177,\n",
       "  0.03638938441872597,\n",
       "  0.009964332915842533,\n",
       "  0.016645826399326324,\n",
       "  0.040115512907505035,\n",
       "  0.058785878121852875,\n",
       "  -0.018296733498573303,\n",
       "  -0.031625863164663315,\n",
       "  0.03883501514792442,\n",
       "  -0.030148588120937347,\n",
       "  0.043630167841911316,\n",
       "  -0.074160136282444,\n",
       "  0.07785223424434662,\n",
       "  0.026526333764195442,\n",
       "  -0.048230405896902084,\n",
       "  0.03181445598602295,\n",
       "  -0.0224197618663311,\n",
       "  0.09804701805114746,\n",
       "  0.022285139188170433,\n",
       "  0.025921594351530075,\n",
       "  0.004656237084418535,\n",
       "  0.023183973506093025,\n",
       "  0.04034779593348503,\n",
       "  -0.01775350421667099,\n",
       "  -0.13538077473640442,\n",
       "  -0.02396964095532894,\n",
       "  0.0294943954795599,\n",
       "  -0.025871025398373604,\n",
       "  -0.04335460811853409,\n",
       "  4.29329666076228e-05,\n",
       "  0.006625962909311056,\n",
       "  0.010291347280144691,\n",
       "  0.13956184685230255,\n",
       "  0.06382035464048386,\n",
       "  0.0002689908433239907,\n",
       "  0.08216540515422821,\n",
       "  -0.019922591745853424,\n",
       "  -0.0931570753455162,\n",
       "  -0.0006491044186986983,\n",
       "  -0.04719299077987671,\n",
       "  0.04688327759504318,\n",
       "  -0.062774159014225,\n",
       "  -0.11858249455690384,\n",
       "  -0.03693750128149986,\n",
       "  0.17148900032043457,\n",
       "  -0.004931367002427578,\n",
       "  0.01735043153166771,\n",
       "  -0.011145730502903461,\n",
       "  -0.06700137257575989,\n",
       "  0.015793537721037865,\n",
       "  0.01616648957133293,\n",
       "  0.0054008797742426395,\n",
       "  -0.007780839689075947,\n",
       "  -0.031003465875983238,\n",
       "  -0.0068158796057105064,\n",
       "  0.02102671004831791,\n",
       "  0.08655799925327301,\n",
       "  -0.06657485663890839,\n",
       "  -0.0027479822747409344,\n",
       "  -0.10672418773174286,\n",
       "  0.007250218652188778,\n",
       "  -0.04092572256922722,\n",
       "  -0.1715986728668213,\n",
       "  0.009248815476894379,\n",
       "  0.08610720932483673,\n",
       "  0.00524441571906209,\n",
       "  -0.04761037603020668,\n",
       "  3.3292273862172054e-33,\n",
       "  -0.0244298055768013,\n",
       "  0.023424485698342323,\n",
       "  -0.006907290779054165,\n",
       "  0.0755055770277977,\n",
       "  -0.049470316618680954,\n",
       "  -0.019292814657092094,\n",
       "  0.06310193240642548,\n",
       "  0.013151578605175018,\n",
       "  0.0570688359439373,\n",
       "  0.10065632313489914,\n",
       "  -0.015888312831521034,\n",
       "  -0.030347390100359917,\n",
       "  -0.002834292594343424,\n",
       "  -0.014990663155913353,\n",
       "  0.059522125869989395,\n",
       "  0.011444113217294216,\n",
       "  0.10625562071800232,\n",
       "  -0.0419095978140831,\n",
       "  -0.09881610423326492,\n",
       "  0.02525504305958748,\n",
       "  -0.038518331944942474,\n",
       "  -0.042768191546201706,\n",
       "  0.01524658128619194,\n",
       "  0.03915449231863022,\n",
       "  0.003962579648941755,\n",
       "  0.07259885221719742,\n",
       "  0.040078118443489075,\n",
       "  0.0865790843963623,\n",
       "  -0.01695418730378151,\n",
       "  -0.031391728669404984,\n",
       "  0.04334656894207001,\n",
       "  -0.017177319154143333,\n",
       "  -0.018453797325491905,\n",
       "  -0.060514532029628754,\n",
       "  -0.008318343199789524,\n",
       "  0.06895868480205536,\n",
       "  0.057587169110774994,\n",
       "  0.023476677015423775,\n",
       "  0.012361904606223106,\n",
       "  -0.009343752637505531,\n",
       "  0.02333183027803898,\n",
       "  -0.04632142558693886,\n",
       "  0.04289312660694122,\n",
       "  0.07788213342428207,\n",
       "  0.0605025552213192,\n",
       "  -0.11907380819320679,\n",
       "  -0.029774878174066544,\n",
       "  -0.09598385542631149,\n",
       "  0.025796111673116684,\n",
       "  0.029758954420685768,\n",
       "  -0.04765913262963295,\n",
       "  -0.04485540837049484,\n",
       "  -0.06442589312791824,\n",
       "  -0.03778041899204254,\n",
       "  -0.03522342070937157,\n",
       "  0.07677456736564636,\n",
       "  -0.03939252719283104,\n",
       "  0.010675753466784954,\n",
       "  -0.013037433847784996,\n",
       "  -0.014824904501438141,\n",
       "  0.00238590594381094,\n",
       "  0.05096963047981262,\n",
       "  -0.06430263072252274,\n",
       "  0.032869596034288406,\n",
       "  -0.029107417911291122,\n",
       "  -0.0015676114708185196,\n",
       "  0.00021431567438412458,\n",
       "  -0.0363471582531929,\n",
       "  -0.04258284717798233,\n",
       "  -0.037751566618680954,\n",
       "  0.12357202172279358,\n",
       "  0.06216402351856232,\n",
       "  -0.04995362460613251,\n",
       "  0.02614581026136875,\n",
       "  -0.08762507140636444,\n",
       "  -0.05153869092464447,\n",
       "  -0.09033851325511932,\n",
       "  -0.005692804232239723,\n",
       "  0.007502274587750435,\n",
       "  -0.03376210108399391,\n",
       "  -0.048197776079177856,\n",
       "  -0.03877517580986023,\n",
       "  0.02954215370118618,\n",
       "  -0.014373154379427433,\n",
       "  -0.027795249596238136,\n",
       "  -0.046486664563417435,\n",
       "  0.0012082861503586173,\n",
       "  0.04862271994352341,\n",
       "  0.02261059358716011,\n",
       "  -0.02955515682697296,\n",
       "  4.334831828600727e-05,\n",
       "  0.00946276355534792,\n",
       "  0.020911451429128647,\n",
       "  -0.08296166360378265,\n",
       "  0.07607715576887131,\n",
       "  -1.472095334520418e-08,\n",
       "  -0.005594480782747269,\n",
       "  -0.024874834343791008,\n",
       "  -0.01694396138191223,\n",
       "  0.017673881724476814,\n",
       "  0.11267835646867752,\n",
       "  -0.022055771201848984,\n",
       "  -0.037674982100725174,\n",
       "  0.02356979437172413,\n",
       "  0.03026457317173481,\n",
       "  0.032670412212610245,\n",
       "  0.08075079321861267,\n",
       "  0.006948627065867186,\n",
       "  -0.006521731149405241,\n",
       "  -0.00868767499923706,\n",
       "  0.02532387524843216,\n",
       "  -0.0385630838572979,\n",
       "  -0.07914956659078598,\n",
       "  0.06244741752743721,\n",
       "  -0.026907196268439293,\n",
       "  0.03029465116560459,\n",
       "  0.024573560804128647,\n",
       "  0.005553271621465683,\n",
       "  -0.043635036796331406,\n",
       "  -0.055842287838459015,\n",
       "  -0.02299022674560547,\n",
       "  0.0056071048602461815,\n",
       "  -0.07304450124502182,\n",
       "  0.03713006153702736,\n",
       "  0.06021140143275261,\n",
       "  0.0038932226598262787,\n",
       "  0.013997427187860012,\n",
       "  0.06263937056064606,\n",
       "  0.00780866015702486,\n",
       "  -0.05584344267845154,\n",
       "  -0.03746933117508888,\n",
       "  -0.03026176616549492,\n",
       "  -0.021359005942940712,\n",
       "  0.0005941882263869047,\n",
       "  0.00491974176838994,\n",
       "  0.12389961630105972,\n",
       "  -0.005280758254230022,\n",
       "  0.02198789268732071,\n",
       "  0.018020885065197945,\n",
       "  0.002145572332665324,\n",
       "  -0.06062082573771477,\n",
       "  -0.025410540401935577,\n",
       "  0.01163552701473236,\n",
       "  0.03888377919793129,\n",
       "  0.025019248947501183,\n",
       "  -0.04326601326465607,\n",
       "  -0.033164363354444504,\n",
       "  -0.026664642617106438,\n",
       "  0.001293438719585538,\n",
       "  0.02114483155310154,\n",
       "  0.07621995359659195,\n",
       "  0.0257958322763443,\n",
       "  0.04077168181538582,\n",
       "  0.05098893120884895,\n",
       "  -0.02293216437101364,\n",
       "  0.008091234602034092,\n",
       "  0.10233396291732788,\n",
       "  0.07332275062799454,\n",
       "  0.04099217429757118,\n",
       "  -0.005412295460700989],\n",
       " [-0.029210345819592476,\n",
       "  -0.008136079646646976,\n",
       "  0.03420504927635193,\n",
       "  0.040295638144016266,\n",
       "  0.07426188886165619,\n",
       "  0.05922502279281616,\n",
       "  0.08180953562259674,\n",
       "  0.037137407809495926,\n",
       "  0.03291481360793114,\n",
       "  -0.031437069177627563,\n",
       "  0.06003862991929054,\n",
       "  -0.07254356890916824,\n",
       "  0.024705301970243454,\n",
       "  -0.004340925253927708,\n",
       "  -0.013213634490966797,\n",
       "  0.01841089315712452,\n",
       "  -0.0830569714307785,\n",
       "  -0.014857972972095013,\n",
       "  -0.12271389365196228,\n",
       "  0.0023262533359229565,\n",
       "  -0.033769749104976654,\n",
       "  0.027208684012293816,\n",
       "  -0.02078929729759693,\n",
       "  0.02001940831542015,\n",
       "  -0.01195460557937622,\n",
       "  -0.016626928001642227,\n",
       "  -0.021979203447699547,\n",
       "  -0.0048761810176074505,\n",
       "  0.0012886925833299756,\n",
       "  -0.08734933286905289,\n",
       "  0.007423582021147013,\n",
       "  0.11303859204053879,\n",
       "  0.05859524756669998,\n",
       "  -0.019217269495129585,\n",
       "  0.017139490693807602,\n",
       "  -0.07475004345178604,\n",
       "  -0.07950093597173691,\n",
       "  -0.058088261634111404,\n",
       "  0.03741072118282318,\n",
       "  0.05945615470409393,\n",
       "  -0.08294060826301575,\n",
       "  -0.0891818106174469,\n",
       "  0.03647366911172867,\n",
       "  -0.029225805774331093,\n",
       "  -0.0008361548534594476,\n",
       "  -0.026880696415901184,\n",
       "  -0.03130786493420601,\n",
       "  -0.009517751634120941,\n",
       "  -0.03412143886089325,\n",
       "  0.02407819591462612,\n",
       "  0.01013795007020235,\n",
       "  -0.007920147851109505,\n",
       "  -0.039895687252283096,\n",
       "  0.008829214610159397,\n",
       "  -0.0834297463297844,\n",
       "  -0.009849640540778637,\n",
       "  -0.07375919073820114,\n",
       "  0.03378712385892868,\n",
       "  0.05167929455637932,\n",
       "  0.026601599529385567,\n",
       "  -0.041304826736450195,\n",
       "  0.08046966046094894,\n",
       "  -0.11150691658258438,\n",
       "  0.07736308127641678,\n",
       "  -0.02570829913020134,\n",
       "  0.047470398247241974,\n",
       "  0.029889818280935287,\n",
       "  -0.009334547445178032,\n",
       "  -0.0023373544681817293,\n",
       "  0.03722880408167839,\n",
       "  -0.006874643731862307,\n",
       "  -0.029843822121620178,\n",
       "  -0.00025061596534214914,\n",
       "  -0.037283755838871,\n",
       "  0.08152831345796585,\n",
       "  -0.008404563181102276,\n",
       "  0.05313148722052574,\n",
       "  -0.0691046416759491,\n",
       "  0.009290182963013649,\n",
       "  0.00986396986991167,\n",
       "  0.00040824757888913155,\n",
       "  0.02940952219069004,\n",
       "  -0.09752608090639114,\n",
       "  0.02366202138364315,\n",
       "  -0.08437427133321762,\n",
       "  -0.019076097756624222,\n",
       "  -0.032881781458854675,\n",
       "  0.061567798256874084,\n",
       "  0.029156535863876343,\n",
       "  -0.019742436707019806,\n",
       "  -0.013563971035182476,\n",
       "  -0.053020648658275604,\n",
       "  -0.01327479723840952,\n",
       "  0.039495620876550674,\n",
       "  -0.04668426141142845,\n",
       "  0.01330205611884594,\n",
       "  0.08526203781366348,\n",
       "  -0.060894060879945755,\n",
       "  -0.07038620114326477,\n",
       "  0.26119372248649597,\n",
       "  0.03365139290690422,\n",
       "  0.05668490007519722,\n",
       "  -0.008424963802099228,\n",
       "  0.06896039098501205,\n",
       "  -0.04096302390098572,\n",
       "  -0.014684862457215786,\n",
       "  -0.02363336831331253,\n",
       "  0.029228568077087402,\n",
       "  -0.0003930261009372771,\n",
       "  -0.05965803191065788,\n",
       "  0.032574281096458435,\n",
       "  -0.0002906881563831121,\n",
       "  0.025960301980376244,\n",
       "  0.026114419102668762,\n",
       "  0.007866919972002506,\n",
       "  -0.04794005677103996,\n",
       "  0.026390770450234413,\n",
       "  -0.08495408296585083,\n",
       "  0.007937341928482056,\n",
       "  -0.01850290223956108,\n",
       "  0.10609831660985947,\n",
       "  -0.04497348517179489,\n",
       "  -0.05770345404744148,\n",
       "  -0.0002425768761895597,\n",
       "  -0.03897979110479355,\n",
       "  -0.07212404161691666,\n",
       "  0.017694924026727676,\n",
       "  -4.757851955861595e-33,\n",
       "  0.0326862633228302,\n",
       "  -0.003990126773715019,\n",
       "  0.03518329933285713,\n",
       "  -0.005888605955988169,\n",
       "  0.04369904473423958,\n",
       "  0.05856825038790703,\n",
       "  -0.059868186712265015,\n",
       "  0.011806056834757328,\n",
       "  -0.0812859833240509,\n",
       "  0.055700093507766724,\n",
       "  -0.054146550595760345,\n",
       "  0.046555470675230026,\n",
       "  -0.06937884539365768,\n",
       "  0.0034098217729479074,\n",
       "  0.0645420253276825,\n",
       "  0.06285574287176132,\n",
       "  0.05009740591049194,\n",
       "  0.022991729900240898,\n",
       "  -0.033388737589120865,\n",
       "  0.012444930151104927,\n",
       "  -0.026966817677021027,\n",
       "  0.03426383063197136,\n",
       "  0.0031661642715334892,\n",
       "  0.04734795168042183,\n",
       "  -0.014649293385446072,\n",
       "  -0.03517652675509453,\n",
       "  0.06358019262552261,\n",
       "  -0.07909435778856277,\n",
       "  -0.002110628178343177,\n",
       "  0.03638938441872597,\n",
       "  0.009964332915842533,\n",
       "  0.016645826399326324,\n",
       "  0.040115512907505035,\n",
       "  0.058785878121852875,\n",
       "  -0.018296733498573303,\n",
       "  -0.031625863164663315,\n",
       "  0.03883501514792442,\n",
       "  -0.030148588120937347,\n",
       "  0.043630167841911316,\n",
       "  -0.074160136282444,\n",
       "  0.07785223424434662,\n",
       "  0.026526333764195442,\n",
       "  -0.048230405896902084,\n",
       "  0.03181445598602295,\n",
       "  -0.0224197618663311,\n",
       "  0.09804701805114746,\n",
       "  0.022285139188170433,\n",
       "  0.025921594351530075,\n",
       "  0.004656237084418535,\n",
       "  0.023183973506093025,\n",
       "  0.04034779593348503,\n",
       "  -0.01775350421667099,\n",
       "  -0.13538077473640442,\n",
       "  -0.02396964095532894,\n",
       "  0.0294943954795599,\n",
       "  -0.025871025398373604,\n",
       "  -0.04335460811853409,\n",
       "  4.29329666076228e-05,\n",
       "  0.006625962909311056,\n",
       "  0.010291347280144691,\n",
       "  0.13956184685230255,\n",
       "  0.06382035464048386,\n",
       "  0.0002689908433239907,\n",
       "  0.08216540515422821,\n",
       "  -0.019922591745853424,\n",
       "  -0.0931570753455162,\n",
       "  -0.0006491044186986983,\n",
       "  -0.04719299077987671,\n",
       "  0.04688327759504318,\n",
       "  -0.062774159014225,\n",
       "  -0.11858249455690384,\n",
       "  -0.03693750128149986,\n",
       "  0.17148900032043457,\n",
       "  -0.004931367002427578,\n",
       "  0.01735043153166771,\n",
       "  -0.011145730502903461,\n",
       "  -0.06700137257575989,\n",
       "  0.015793537721037865,\n",
       "  0.01616648957133293,\n",
       "  0.0054008797742426395,\n",
       "  -0.007780839689075947,\n",
       "  -0.031003465875983238,\n",
       "  -0.0068158796057105064,\n",
       "  0.02102671004831791,\n",
       "  0.08655799925327301,\n",
       "  -0.06657485663890839,\n",
       "  -0.0027479822747409344,\n",
       "  -0.10672418773174286,\n",
       "  0.007250218652188778,\n",
       "  -0.04092572256922722,\n",
       "  -0.1715986728668213,\n",
       "  0.009248815476894379,\n",
       "  0.08610720932483673,\n",
       "  0.00524441571906209,\n",
       "  -0.04761037603020668,\n",
       "  3.3292273862172054e-33,\n",
       "  -0.0244298055768013,\n",
       "  0.023424485698342323,\n",
       "  -0.006907290779054165,\n",
       "  0.0755055770277977,\n",
       "  -0.049470316618680954,\n",
       "  -0.019292814657092094,\n",
       "  0.06310193240642548,\n",
       "  0.013151578605175018,\n",
       "  0.0570688359439373,\n",
       "  0.10065632313489914,\n",
       "  -0.015888312831521034,\n",
       "  -0.030347390100359917,\n",
       "  -0.002834292594343424,\n",
       "  -0.014990663155913353,\n",
       "  0.059522125869989395,\n",
       "  0.011444113217294216,\n",
       "  0.10625562071800232,\n",
       "  -0.0419095978140831,\n",
       "  -0.09881610423326492,\n",
       "  0.02525504305958748,\n",
       "  -0.038518331944942474,\n",
       "  -0.042768191546201706,\n",
       "  0.01524658128619194,\n",
       "  0.03915449231863022,\n",
       "  0.003962579648941755,\n",
       "  0.07259885221719742,\n",
       "  0.040078118443489075,\n",
       "  0.0865790843963623,\n",
       "  -0.01695418730378151,\n",
       "  -0.031391728669404984,\n",
       "  0.04334656894207001,\n",
       "  -0.017177319154143333,\n",
       "  -0.018453797325491905,\n",
       "  -0.060514532029628754,\n",
       "  -0.008318343199789524,\n",
       "  0.06895868480205536,\n",
       "  0.057587169110774994,\n",
       "  0.023476677015423775,\n",
       "  0.012361904606223106,\n",
       "  -0.009343752637505531,\n",
       "  0.02333183027803898,\n",
       "  -0.04632142558693886,\n",
       "  0.04289312660694122,\n",
       "  0.07788213342428207,\n",
       "  0.0605025552213192,\n",
       "  -0.11907380819320679,\n",
       "  -0.029774878174066544,\n",
       "  -0.09598385542631149,\n",
       "  0.025796111673116684,\n",
       "  0.029758954420685768,\n",
       "  -0.04765913262963295,\n",
       "  -0.04485540837049484,\n",
       "  -0.06442589312791824,\n",
       "  -0.03778041899204254,\n",
       "  -0.03522342070937157,\n",
       "  0.07677456736564636,\n",
       "  -0.03939252719283104,\n",
       "  0.010675753466784954,\n",
       "  -0.013037433847784996,\n",
       "  -0.014824904501438141,\n",
       "  0.00238590594381094,\n",
       "  0.05096963047981262,\n",
       "  -0.06430263072252274,\n",
       "  0.032869596034288406,\n",
       "  -0.029107417911291122,\n",
       "  -0.0015676114708185196,\n",
       "  0.00021431567438412458,\n",
       "  -0.0363471582531929,\n",
       "  -0.04258284717798233,\n",
       "  -0.037751566618680954,\n",
       "  0.12357202172279358,\n",
       "  0.06216402351856232,\n",
       "  -0.04995362460613251,\n",
       "  0.02614581026136875,\n",
       "  -0.08762507140636444,\n",
       "  -0.05153869092464447,\n",
       "  -0.09033851325511932,\n",
       "  -0.005692804232239723,\n",
       "  0.007502274587750435,\n",
       "  -0.03376210108399391,\n",
       "  -0.048197776079177856,\n",
       "  -0.03877517580986023,\n",
       "  0.02954215370118618,\n",
       "  -0.014373154379427433,\n",
       "  -0.027795249596238136,\n",
       "  -0.046486664563417435,\n",
       "  0.0012082861503586173,\n",
       "  0.04862271994352341,\n",
       "  0.02261059358716011,\n",
       "  -0.02955515682697296,\n",
       "  4.334831828600727e-05,\n",
       "  0.00946276355534792,\n",
       "  0.020911451429128647,\n",
       "  -0.08296166360378265,\n",
       "  0.07607715576887131,\n",
       "  -1.472095334520418e-08,\n",
       "  -0.005594480782747269,\n",
       "  -0.024874834343791008,\n",
       "  -0.01694396138191223,\n",
       "  0.017673881724476814,\n",
       "  0.11267835646867752,\n",
       "  -0.022055771201848984,\n",
       "  -0.037674982100725174,\n",
       "  0.02356979437172413,\n",
       "  0.03026457317173481,\n",
       "  0.032670412212610245,\n",
       "  0.08075079321861267,\n",
       "  0.006948627065867186,\n",
       "  -0.006521731149405241,\n",
       "  -0.00868767499923706,\n",
       "  0.02532387524843216,\n",
       "  -0.0385630838572979,\n",
       "  -0.07914956659078598,\n",
       "  0.06244741752743721,\n",
       "  -0.026907196268439293,\n",
       "  0.03029465116560459,\n",
       "  0.024573560804128647,\n",
       "  0.005553271621465683,\n",
       "  -0.043635036796331406,\n",
       "  -0.055842287838459015,\n",
       "  -0.02299022674560547,\n",
       "  0.0056071048602461815,\n",
       "  -0.07304450124502182,\n",
       "  0.03713006153702736,\n",
       "  0.06021140143275261,\n",
       "  0.0038932226598262787,\n",
       "  0.013997427187860012,\n",
       "  0.06263937056064606,\n",
       "  0.00780866015702486,\n",
       "  -0.05584344267845154,\n",
       "  -0.03746933117508888,\n",
       "  -0.03026176616549492,\n",
       "  -0.021359005942940712,\n",
       "  0.0005941882263869047,\n",
       "  0.00491974176838994,\n",
       "  0.12389961630105972,\n",
       "  -0.005280758254230022,\n",
       "  0.02198789268732071,\n",
       "  0.018020885065197945,\n",
       "  0.002145572332665324,\n",
       "  -0.06062082573771477,\n",
       "  -0.025410540401935577,\n",
       "  0.01163552701473236,\n",
       "  0.03888377919793129,\n",
       "  0.025019248947501183,\n",
       "  -0.04326601326465607,\n",
       "  -0.033164363354444504,\n",
       "  -0.026664642617106438,\n",
       "  0.001293438719585538,\n",
       "  0.02114483155310154,\n",
       "  0.07621995359659195,\n",
       "  0.0257958322763443,\n",
       "  0.04077168181538582,\n",
       "  0.05098893120884895,\n",
       "  -0.02293216437101364,\n",
       "  0.008091234602034092,\n",
       "  0.10233396291732788,\n",
       "  0.07332275062799454,\n",
       "  0.04099217429757118,\n",
       "  -0.005412295460700989],\n",
       " [-0.0632946714758873,\n",
       "  -0.029084591194987297,\n",
       "  -0.035622041672468185,\n",
       "  0.005400789435952902,\n",
       "  0.04646555334329605,\n",
       "  -0.04406901076436043,\n",
       "  0.026927947998046875,\n",
       "  -0.003345321398228407,\n",
       "  -0.02970086596906185,\n",
       "  -0.03885641321539879,\n",
       "  -0.006651331204921007,\n",
       "  -0.009661762043833733,\n",
       "  0.036862727254629135,\n",
       "  0.011378278024494648,\n",
       "  -0.026957247406244278,\n",
       "  0.09104558080434799,\n",
       "  0.0016098112100735307,\n",
       "  0.005427334923297167,\n",
       "  -0.040282078087329865,\n",
       "  0.038787830621004105,\n",
       "  0.0037338538095355034,\n",
       "  0.04214751720428467,\n",
       "  0.00603968370705843,\n",
       "  0.02624625153839588,\n",
       "  -0.028445197269320488,\n",
       "  -0.04365674406290054,\n",
       "  0.04796856641769409,\n",
       "  0.1055292934179306,\n",
       "  0.02631913498044014,\n",
       "  -0.08107887208461761,\n",
       "  -0.03188517689704895,\n",
       "  0.13512000441551208,\n",
       "  0.08511951565742493,\n",
       "  0.04034976288676262,\n",
       "  -0.009754936210811138,\n",
       "  -0.06288851797580719,\n",
       "  -0.04760626703500748,\n",
       "  -0.02250632829964161,\n",
       "  -0.040648382157087326,\n",
       "  0.04391476511955261,\n",
       "  -0.006360866129398346,\n",
       "  -0.0010547322453930974,\n",
       "  0.0400259792804718,\n",
       "  0.045240119099617004,\n",
       "  0.04883534088730812,\n",
       "  -0.032244399189949036,\n",
       "  0.03030046634376049,\n",
       "  -0.0389268733561039,\n",
       "  -0.014555537141859531,\n",
       "  0.0026252418756484985,\n",
       "  -0.012876464985311031,\n",
       "  -0.0007960845832712948,\n",
       "  -0.07344914227724075,\n",
       "  0.007235922385007143,\n",
       "  0.03524424508213997,\n",
       "  0.033723440021276474,\n",
       "  -0.007323778234422207,\n",
       "  -0.035033416002988815,\n",
       "  0.02095448039472103,\n",
       "  -0.02207990549504757,\n",
       "  -0.06082601472735405,\n",
       "  0.05299132689833641,\n",
       "  -0.11493781208992004,\n",
       "  0.09013019502162933,\n",
       "  0.011983523145318031,\n",
       "  0.02032211609184742,\n",
       "  0.028425410389900208,\n",
       "  8.760542550589889e-05,\n",
       "  -0.039000168442726135,\n",
       "  -0.008005271665751934,\n",
       "  0.027706265449523926,\n",
       "  0.010863784700632095,\n",
       "  -0.021035728976130486,\n",
       "  -0.07163020223379135,\n",
       "  0.009541970677673817,\n",
       "  -0.03360334038734436,\n",
       "  0.08087964355945587,\n",
       "  0.023500997573137283,\n",
       "  0.09731606394052505,\n",
       "  0.059328701347112656,\n",
       "  -0.043086398392915726,\n",
       "  -0.009734904393553734,\n",
       "  -0.0627952292561531,\n",
       "  0.006299341097474098,\n",
       "  -0.08168298006057739,\n",
       "  0.028740281239151955,\n",
       "  0.06054195761680603,\n",
       "  -0.005681200884282589,\n",
       "  -0.019495150074362755,\n",
       "  -0.018948756158351898,\n",
       "  -0.0706099197268486,\n",
       "  -0.08348861336708069,\n",
       "  0.06655945628881454,\n",
       "  -0.0196764525026083,\n",
       "  0.05008724704384804,\n",
       "  -0.04837844893336296,\n",
       "  0.022866588085889816,\n",
       "  0.031424276530742645,\n",
       "  -0.11799001693725586,\n",
       "  0.2338486611843109,\n",
       "  0.03878675028681755,\n",
       "  0.04347994551062584,\n",
       "  0.01712934672832489,\n",
       "  0.0008781995857134461,\n",
       "  0.03244972601532936,\n",
       "  -0.05792014300823212,\n",
       "  -0.04335387051105499,\n",
       "  0.019139882177114487,\n",
       "  0.03188691288232803,\n",
       "  0.019337845966219902,\n",
       "  0.00275334226898849,\n",
       "  -0.1002153679728508,\n",
       "  -0.023718060925602913,\n",
       "  0.009705883450806141,\n",
       "  -0.03099399246275425,\n",
       "  0.01847861520946026,\n",
       "  -0.029452994465827942,\n",
       "  0.040030281990766525,\n",
       "  0.004831552039831877,\n",
       "  0.03442322090268135,\n",
       "  -0.009862065315246582,\n",
       "  -0.024506570771336555,\n",
       "  -0.044952865689992905,\n",
       "  0.02001882903277874,\n",
       "  -0.019497623667120934,\n",
       "  -0.09456072747707367,\n",
       "  0.061928559094667435,\n",
       "  -2.7428735389537707e-33,\n",
       "  0.015307709574699402,\n",
       "  -0.054866135120391846,\n",
       "  0.002185505349189043,\n",
       "  -0.0578949898481369,\n",
       "  0.05821684002876282,\n",
       "  0.08604741096496582,\n",
       "  -0.0389251746237278,\n",
       "  -0.0576578825712204,\n",
       "  -0.05721420422196388,\n",
       "  -0.01006937026977539,\n",
       "  -0.04470309615135193,\n",
       "  0.021425548940896988,\n",
       "  -0.01895791105926037,\n",
       "  -0.020185476168990135,\n",
       "  0.13056328892707825,\n",
       "  0.010499236173927784,\n",
       "  0.07229845225811005,\n",
       "  -0.028380129486322403,\n",
       "  -0.021529829129576683,\n",
       "  0.045818693935871124,\n",
       "  0.019456464797258377,\n",
       "  -0.05817147344350815,\n",
       "  -0.007670664694160223,\n",
       "  0.03731902688741684,\n",
       "  -0.07287470996379852,\n",
       "  0.015077061951160431,\n",
       "  -0.04591125622391701,\n",
       "  -0.11117761582136154,\n",
       "  -0.05316159501671791,\n",
       "  0.04004092514514923,\n",
       "  0.042748793959617615,\n",
       "  0.055326465517282486,\n",
       "  -0.027612706646323204,\n",
       "  -0.024855583906173706,\n",
       "  0.005590554792433977,\n",
       "  -0.13302631676197052,\n",
       "  0.019695861265063286,\n",
       "  -0.09105837345123291,\n",
       "  -0.011482425965368748,\n",
       "  0.03282522037625313,\n",
       "  -0.016831040382385254,\n",
       "  -0.0026947895530611277,\n",
       "  -0.049212824553251266,\n",
       "  0.00030183736816979945,\n",
       "  -0.007122092414647341,\n",
       "  0.13329555094242096,\n",
       "  -0.023196710273623466,\n",
       "  0.014223511330783367,\n",
       "  0.050806306302547455,\n",
       "  0.03930504247546196,\n",
       "  0.006982649210840464,\n",
       "  -0.01452675461769104,\n",
       "  -0.11060043424367905,\n",
       "  0.06326603144407272,\n",
       "  -0.045166369527578354,\n",
       "  -0.06385655701160431,\n",
       "  -0.03833552077412605,\n",
       "  -0.003095888299867511,\n",
       "  0.03214368224143982,\n",
       "  -0.04407375305891037,\n",
       "  0.054991450160741806,\n",
       "  0.009817665442824364,\n",
       "  -0.023723244667053223,\n",
       "  -0.05900269001722336,\n",
       "  -0.06440649926662445,\n",
       "  -0.07831266522407532,\n",
       "  -0.04900196194648743,\n",
       "  0.01172249112278223,\n",
       "  0.041545845568180084,\n",
       "  -0.01094137318432331,\n",
       "  0.005588149651885033,\n",
       "  0.005816859658807516,\n",
       "  0.07531194388866425,\n",
       "  -0.05254737660288811,\n",
       "  0.0021241968497633934,\n",
       "  -0.060045406222343445,\n",
       "  0.0008410275913774967,\n",
       "  -0.018054446205496788,\n",
       "  0.04984172433614731,\n",
       "  -0.02272171899676323,\n",
       "  0.06009361892938614,\n",
       "  -0.04681053385138512,\n",
       "  0.0008284458890557289,\n",
       "  -0.008378882892429829,\n",
       "  0.056773215532302856,\n",
       "  0.04161929339170456,\n",
       "  -0.0008134115487337112,\n",
       "  -0.070949487388134,\n",
       "  -0.03848859295248985,\n",
       "  0.026522131636738777,\n",
       "  -0.07449985295534134,\n",
       "  -0.0034870447125285864,\n",
       "  -0.04274846985936165,\n",
       "  -0.07851018756628036,\n",
       "  0.00416209502145648,\n",
       "  1.4446742919659371e-33,\n",
       "  -0.011052408255636692,\n",
       "  -0.0011534147197380662,\n",
       "  -0.0016813140828162432,\n",
       "  -0.00026404327945783734,\n",
       "  -0.012874073348939419,\n",
       "  0.017763717100024223,\n",
       "  -0.02501821145415306,\n",
       "  0.056135933846235275,\n",
       "  -0.026796136051416397,\n",
       "  -0.02823006734251976,\n",
       "  -0.04467415064573288,\n",
       "  -0.02942780777812004,\n",
       "  0.0716358870267868,\n",
       "  -0.0015881758881732821,\n",
       "  0.024695368483662605,\n",
       "  0.03986778110265732,\n",
       "  0.040439147502183914,\n",
       "  0.041070468723773956,\n",
       "  -0.018267525359988213,\n",
       "  0.03706643730401993,\n",
       "  0.017697349190711975,\n",
       "  0.011258190497756004,\n",
       "  0.04408017918467522,\n",
       "  0.05068467557430267,\n",
       "  -0.01617049053311348,\n",
       "  0.09693515300750732,\n",
       "  0.012585555203258991,\n",
       "  0.052769068628549576,\n",
       "  -0.053056925535202026,\n",
       "  0.0363466702401638,\n",
       "  0.020415475592017174,\n",
       "  -0.07778414338827133,\n",
       "  -0.0712994709610939,\n",
       "  -0.015362918376922607,\n",
       "  0.04048725217580795,\n",
       "  0.17289723455905914,\n",
       "  0.008718710392713547,\n",
       "  -0.011596295982599258,\n",
       "  0.012245232239365578,\n",
       "  0.004340941086411476,\n",
       "  0.013187097385525703,\n",
       "  -0.040377240628004074,\n",
       "  0.09169550985097885,\n",
       "  0.09502425789833069,\n",
       "  -0.037522051483392715,\n",
       "  0.007698968052864075,\n",
       "  -0.03789100423455238,\n",
       "  0.023382924497127533,\n",
       "  0.01985209807753563,\n",
       "  0.08860360085964203,\n",
       "  -0.05157666280865669,\n",
       "  -0.04810187593102455,\n",
       "  -0.04262636601924896,\n",
       "  -0.09404066950082779,\n",
       "  -0.048373494297266006,\n",
       "  0.053073182702064514,\n",
       "  0.03178025782108307,\n",
       "  -0.004105713684111834,\n",
       "  0.011147730052471161,\n",
       "  -0.0708971843123436,\n",
       "  0.05389217287302017,\n",
       "  0.03450223058462143,\n",
       "  -0.07965955138206482,\n",
       "  0.06812734156847,\n",
       "  -0.04773929715156555,\n",
       "  -0.010421979241073132,\n",
       "  -0.004480925388634205,\n",
       "  0.019341392442584038,\n",
       "  -0.06478755176067352,\n",
       "  0.029336968436837196,\n",
       "  0.10299648344516754,\n",
       "  -0.03956732153892517,\n",
       "  -0.1294112354516983,\n",
       "  0.009138299152255058,\n",
       "  -0.05665421858429909,\n",
       "  -0.06888429075479507,\n",
       "  0.0008460114477202296,\n",
       "  0.045199573040008545,\n",
       "  0.053018342703580856,\n",
       "  -0.016062278300523758,\n",
       "  -0.1560525894165039,\n",
       "  -0.03234678879380226,\n",
       "  0.03198343887925148,\n",
       "  0.021963942795991898,\n",
       "  -0.015298399142920971,\n",
       "  0.011610444635152817,\n",
       "  0.05960087105631828,\n",
       "  -0.031183870509266853,\n",
       "  0.002943278755992651,\n",
       "  0.002758423564955592,\n",
       "  0.022127781063318253,\n",
       "  0.02110549807548523,\n",
       "  0.1656213253736496,\n",
       "  -0.00011024916602764279,\n",
       "  0.056176237761974335,\n",
       "  -1.672368554750392e-08,\n",
       "  0.03582767769694328,\n",
       "  0.010919087566435337,\n",
       "  0.08409047871828079,\n",
       "  -0.03083568438887596,\n",
       "  0.07685696333646774,\n",
       "  -0.010641233064234257,\n",
       "  -0.0015223935479298234,\n",
       "  -0.02251867949962616,\n",
       "  -0.031234120950102806,\n",
       "  0.06532157212495804,\n",
       "  0.09860116243362427,\n",
       "  0.003062136471271515,\n",
       "  0.04989081248641014,\n",
       "  0.021357284858822823,\n",
       "  0.05433797836303711,\n",
       "  0.01770547777414322,\n",
       "  -0.053699836134910583,\n",
       "  0.03402748331427574,\n",
       "  -0.009499257430434227,\n",
       "  -0.05892933905124664,\n",
       "  -0.04205026105046272,\n",
       "  0.08822806924581528,\n",
       "  0.02734873630106449,\n",
       "  -0.03305559605360031,\n",
       "  -0.03947911784052849,\n",
       "  0.026391886174678802,\n",
       "  0.006934433244168758,\n",
       "  0.11791746318340302,\n",
       "  0.02805541642010212,\n",
       "  -0.03347311168909073,\n",
       "  -0.0050417096354067326,\n",
       "  0.0004958240897394717,\n",
       "  0.037875186651945114,\n",
       "  -0.014347715303301811,\n",
       "  -0.0402347594499588,\n",
       "  -0.03774610161781311,\n",
       "  -0.025050431489944458,\n",
       "  0.005850170738995075,\n",
       "  0.029823027551174164,\n",
       "  0.11406707763671875,\n",
       "  -0.04640837386250496,\n",
       "  -0.053487300872802734,\n",
       "  0.04857463762164116,\n",
       "  0.027689065784215927,\n",
       "  -0.028209716081619263,\n",
       "  0.03977615013718605,\n",
       "  0.006884964648634195,\n",
       "  -0.09797028452157974,\n",
       "  -0.04543888568878174,\n",
       "  -0.057140249758958817,\n",
       "  -0.008769980631768703,\n",
       "  -0.04229525104165077,\n",
       "  0.05198730155825615,\n",
       "  0.0638110414147377,\n",
       "  0.05995265766978264,\n",
       "  -0.02171776071190834,\n",
       "  0.03810561075806618,\n",
       "  0.0019989842548966408,\n",
       "  -0.002937929006293416,\n",
       "  -0.0012609565164893866,\n",
       "  0.16832444071769714,\n",
       "  0.01235687080770731,\n",
       "  0.04910438507795334,\n",
       "  -0.014124798588454723]]"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "07aca213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAIEmbeddings\n",
    "emb = embeddings.embed_query(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "469ddc0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.02183269993388962,\n",
       " -0.007037575206172415,\n",
       " -0.02864325547344561,\n",
       " -0.024310444639069517,\n",
       " -0.02355804027321282,\n",
       " 0.0290583757658649,\n",
       " -0.01249250732429478,\n",
       " -0.0027242227280498345,\n",
       " -0.008198613668087017,\n",
       " -0.0051079175859896075,\n",
       " 0.02931782548296565,\n",
       " -0.003249608591443376,\n",
       " -0.01569671254120844,\n",
       " -0.0025685528512232538,\n",
       " 0.012155222319534758,\n",
       " -0.0009583426719376792,\n",
       " 0.03863207423843755,\n",
       " 0.005808431915293894,\n",
       " 0.01896577972173598,\n",
       " -0.013698948229416481,\n",
       " -0.019796018443929333,\n",
       " 0.01008611031342884,\n",
       " 0.005124133309723731,\n",
       " 0.008860210353561666,\n",
       " -0.008127264111127826,\n",
       " -0.0053219639285606414,\n",
       " 0.0025847685749573776,\n",
       " -0.012155222319534758,\n",
       " 0.0033760903518130565,\n",
       " -0.01569671254120844,\n",
       " 0.0038398568841121047,\n",
       " -0.016202638651364547,\n",
       " -0.01781122838750538,\n",
       " -0.012901140954691376,\n",
       " 0.004102549699393549,\n",
       " -0.016267501546301043,\n",
       " -0.0009129389481619826,\n",
       " -0.00976828436341429,\n",
       " 0.02149541399780698,\n",
       " -0.008458063385187767,\n",
       " 0.01303086581324175,\n",
       " -0.006473271931779892,\n",
       " 0.0035025721121827377,\n",
       " -0.006830015525624076,\n",
       " -0.02789085110758891,\n",
       " 0.013335719370533525,\n",
       " -0.012810333274309329,\n",
       " 0.0004605233759106905,\n",
       " -0.014957280568074518,\n",
       " 0.036011630419339274,\n",
       " 0.00922992587446732,\n",
       " 0.012868709507223129,\n",
       " -0.014762692814587648,\n",
       " -0.0004710635032056094,\n",
       " -0.006142473589042566,\n",
       " -0.014853500494969696,\n",
       " -0.007815924823135973,\n",
       " 0.006230037938413266,\n",
       " 0.0076213375353104094,\n",
       " -0.04379512565765223,\n",
       " 0.003105289674664551,\n",
       " 0.02412882927830542,\n",
       " -0.00599004681039668,\n",
       " 0.015061059709856725,\n",
       " -0.004452807096876345,\n",
       " 0.019977633804693428,\n",
       " 0.015320509426957474,\n",
       " 0.005088458996905444,\n",
       " 0.008445090061142375,\n",
       " 0.017837173172950933,\n",
       " 0.02303914083901132,\n",
       " 0.01936792669010988,\n",
       " 0.011993066013516136,\n",
       " -0.011286065487850463,\n",
       " 0.017110713592539788,\n",
       " -0.016630730405184,\n",
       " -0.011856855424265681,\n",
       " -0.003202583318577332,\n",
       " -0.013634086265802602,\n",
       " -0.00014300142997079163,\n",
       " 0.014555132668378,\n",
       " -0.016345335902637696,\n",
       " -0.01809662289005168,\n",
       " 0.016773429519102382,\n",
       " 0.023519122163721876,\n",
       " 0.011020130040049633,\n",
       " -0.01919928465339118,\n",
       " 0.029291880697520097,\n",
       " -0.013945425553794456,\n",
       " -0.03224960859005578,\n",
       " 0.01650100647795624,\n",
       " 0.019212256114791337,\n",
       " -0.00389499001884521,\n",
       " 0.027423843106923747,\n",
       " -0.015800491682990647,\n",
       " 0.002532878538404966,\n",
       " -0.02080787252688678,\n",
       " 0.02815030082468966,\n",
       " 0.011195257807468415,\n",
       " -0.006363006127974989,\n",
       " 0.009852605381773643,\n",
       " 0.019575486836319527,\n",
       " -0.0010102326502824273,\n",
       " -0.00392417813530211,\n",
       " -0.017616639702695894,\n",
       " -0.009158577248830744,\n",
       " -0.01910847697300913,\n",
       " -0.009197495358321688,\n",
       " 0.020418698882558272,\n",
       " 0.004945761745632293,\n",
       " -0.004439834238492262,\n",
       " 0.01676045619505699,\n",
       " -0.00954126609378179,\n",
       " -0.04688257561477044,\n",
       " -0.007394318800016599,\n",
       " -0.01059852401693026,\n",
       " -0.0020966786898877978,\n",
       " -0.005613844627468331,\n",
       " -0.009833147258350787,\n",
       " -0.01314761827906935,\n",
       " 0.02132677196108828,\n",
       " 0.01105904721821796,\n",
       " 0.0161118309709825,\n",
       " -0.001144822156103843,\n",
       " 0.016397227336174033,\n",
       " 0.0019864124204215868,\n",
       " -0.013621113873079826,\n",
       " -0.02071706484650473,\n",
       " 0.003661485087190012,\n",
       " -0.002265320959437154,\n",
       " 0.02968105620449384,\n",
       " -0.005717624700573154,\n",
       " -0.0079715944671319,\n",
       " -0.007446208836569011,\n",
       " -0.019588458297719685,\n",
       " 0.017850144634351094,\n",
       " -0.012278461447385054,\n",
       " 0.02828002661456265,\n",
       " -0.028228137043671546,\n",
       " -0.019458734370491927,\n",
       " -0.010442853441611718,\n",
       " 0.027683292824024496,\n",
       " 0.001032123621209775,\n",
       " -0.004092820172020812,\n",
       " -0.020730038170550125,\n",
       " 0.011072019610940736,\n",
       " -0.00507224327317132,\n",
       " -0.014425407809827626,\n",
       " 0.014503243097486898,\n",
       " -0.01484052810224692,\n",
       " 0.004721985875688523,\n",
       " 0.012220085214471254,\n",
       " 0.011941176442625032,\n",
       " 0.001379948520434061,\n",
       " 0.00233666958507373,\n",
       " 0.015865354577927142,\n",
       " -0.007452695032930399,\n",
       " 0.013737866338907424,\n",
       " -0.004543614311597085,\n",
       " -0.026347126129029803,\n",
       " -0.01607291472413679,\n",
       " 0.002330183388712342,\n",
       " 0.004929546021898169,\n",
       " -0.01229143384010783,\n",
       " -0.003661485087190012,\n",
       " 0.015437261892785074,\n",
       " 0.020340862663576383,\n",
       " 0.01848579653438019,\n",
       " -0.0012348187709023994,\n",
       " -0.0058992395956759406,\n",
       " 0.022455378509873326,\n",
       " 0.006460299539057116,\n",
       " -0.03572623591679297,\n",
       " 0.01725341084381294,\n",
       " -0.005639789878575191,\n",
       " 0.013199507849960454,\n",
       " 0.011357414113487037,\n",
       " 0.01796689710017869,\n",
       " -0.032301498160946886,\n",
       " -0.03850234844856456,\n",
       " -0.029291880697520097,\n",
       " 0.006817043132901301,\n",
       " 0.017123685053939946,\n",
       " 0.028695146906981942,\n",
       " -0.00014371086497377638,\n",
       " 0.009949899724178386,\n",
       " 0.012155222319534758,\n",
       " 0.005630060351202455,\n",
       " 0.014879445280415246,\n",
       " -0.01988682612431138,\n",
       " 0.017110713592539788,\n",
       " 0.02396018724158672,\n",
       " 0.02879892604876415,\n",
       " -0.015982107043754742,\n",
       " -0.7011370972872407,\n",
       " -0.00524412864090137,\n",
       " 0.025452024511899957,\n",
       " 0.009476403198845294,\n",
       " 0.018265264926770386,\n",
       " 0.04177141376644687,\n",
       " 0.024401252319451564,\n",
       " 0.017447997665977193,\n",
       " -0.01000827502576957,\n",
       " 0.03852829137136488,\n",
       " 0.016163722404518837,\n",
       " 0.018226346817279443,\n",
       " 0.007238649156020674,\n",
       " 0.000858616646181714,\n",
       " 0.013698948229416481,\n",
       " -0.002571795949403948,\n",
       " -0.006178147901860854,\n",
       " -0.0026301721823177473,\n",
       " 0.0033955491737278744,\n",
       " -0.0011059047451048615,\n",
       " -0.010851487072008314,\n",
       " 0.014568105061100777,\n",
       " -0.017655557812186837,\n",
       " 0.0016831805286354874,\n",
       " 0.008957503764643795,\n",
       " 0.006953254187813064,\n",
       " 0.015268619856066371,\n",
       " -0.0050268394329802965,\n",
       " -0.016877208660884588,\n",
       " 0.008873182746284443,\n",
       " -0.013673003443970929,\n",
       " 0.011292552149873158,\n",
       " 0.0035609483450965373,\n",
       " -0.006693804470712314,\n",
       " 0.05380988734544449,\n",
       " -0.0023739655633976914,\n",
       " 0.01068933076598969,\n",
       " 0.021430552965515718,\n",
       " 0.006174905036510815,\n",
       " 0.028435697189881193,\n",
       " -0.006106799276224279,\n",
       " -0.005548982198193143,\n",
       " 0.005863565282857653,\n",
       " -0.017603668241295736,\n",
       " 0.015268619856066371,\n",
       " 0.006489487655514016,\n",
       " -0.0043976737293125855,\n",
       " 0.004867926457973021,\n",
       " 0.004206329772498372,\n",
       " 0.00113103893062823,\n",
       " 0.01120174446949111,\n",
       " 0.005214940524444471,\n",
       " -0.019445761046446536,\n",
       " 0.020743009631950284,\n",
       " 0.003794453043921081,\n",
       " -0.0003569461565132354,\n",
       " 0.025075822328971608,\n",
       " -0.010209349441279136,\n",
       " 0.0021274882390197175,\n",
       " 0.014762692814587648,\n",
       " 0.003463654701183756,\n",
       " -0.00533169299027207,\n",
       " -0.019030642616672474,\n",
       " -0.0006802449074672851,\n",
       " -0.022714828226974074,\n",
       " 0.003642026265275194,\n",
       " -0.011999552675538832,\n",
       " -0.014996197746242846,\n",
       " -0.005938156773844268,\n",
       " 0.0030193469907995258,\n",
       " -0.00713486908291585,\n",
       " 0.0055619545909159195,\n",
       " -0.0146718851342056,\n",
       " -0.0043165955763032745,\n",
       " 0.019510623941383032,\n",
       " 0.031938267439418695,\n",
       " 0.01612480429502789,\n",
       " -0.025620666548618658,\n",
       " -0.011941176442625032,\n",
       " 0.00042890293581827025,\n",
       " 0.005733840424307278,\n",
       " -0.008237530846255345,\n",
       " -0.013621113873079826,\n",
       " -0.018498769858425582,\n",
       " 0.03079668942923349,\n",
       " -0.02988861448805825,\n",
       " -0.01755177867040463,\n",
       " -7.869639000551613e-05,\n",
       " 0.003911205742579334,\n",
       " 0.010929322359667586,\n",
       " 0.012687094146459034,\n",
       " 0.04039633082460647,\n",
       " 0.0047576606541681185,\n",
       " -0.017383134771040698,\n",
       " 0.007309997781657249,\n",
       " 0.0008326716279055083,\n",
       " -0.03123775450709834,\n",
       " 0.018771192899571725,\n",
       " 0.004063632055563913,\n",
       " -0.030666965502005733,\n",
       " 0.0032512300241183956,\n",
       " -0.0035577052469158432,\n",
       " -0.005844106228112181,\n",
       " -0.007601878946226246,\n",
       " 0.02396018724158672,\n",
       " 0.011253634040382213,\n",
       " -0.03616729913201258,\n",
       " 0.04340594828803326,\n",
       " 0.023648847953594867,\n",
       " -0.018836053931862988,\n",
       " -0.007601878946226246,\n",
       " 0.006972712776897228,\n",
       " -0.008866696084261747,\n",
       " 0.01925117422428228,\n",
       " 0.00902236665958029,\n",
       " -0.03045940535579609,\n",
       " -0.010390963870720613,\n",
       " 0.006739208310903338,\n",
       " 0.023233727661175575,\n",
       " -0.03180854537483617,\n",
       " -0.000739431914926258,\n",
       " 0.005908968657387368,\n",
       " 0.021391634856024775,\n",
       " -0.011169313022022863,\n",
       " -0.0013240046693634455,\n",
       " 0.022040260080099267,\n",
       " 0.001856687561871212,\n",
       " 0.006564079612161939,\n",
       " -0.020704093385104573,\n",
       " 0.008490493901333399,\n",
       " 0.018109594351451843,\n",
       " -0.007861328663326997,\n",
       " 0.009865577774496419,\n",
       " -0.009995302633046793,\n",
       " 0.016929098231775692,\n",
       " -0.012823305667032105,\n",
       " 0.01054014778401646,\n",
       " -0.02346723259283077,\n",
       " -0.008574815851015365,\n",
       " 0.00038795850114485965,\n",
       " 0.006914337009644736,\n",
       " 0.012816819005009408,\n",
       " -0.019290092333773226,\n",
       " -0.01609885950958234,\n",
       " -0.005915455319410064,\n",
       " -0.012109818479343734,\n",
       " -0.00902885239028037,\n",
       " -0.007874301056049771,\n",
       " -0.004942518414620945,\n",
       " 0.003079344656388345,\n",
       " 0.007822411485158668,\n",
       " 0.01172064390369261,\n",
       " -0.006064638767044603,\n",
       " 0.01755177867040463,\n",
       " 0.027242227746159652,\n",
       " -0.009956385454878466,\n",
       " 0.0051662938189034075,\n",
       " -0.011986580282816055,\n",
       " -0.04210870156517474,\n",
       " -0.005497092161640732,\n",
       " -0.008678594992797573,\n",
       " 0.02973294577538494,\n",
       " -0.01033907429982951,\n",
       " -0.00011239445805983828,\n",
       " -0.012051442246429935,\n",
       " -0.024193692173241917,\n",
       " -0.002185864471933517,\n",
       " 0.005584656511011431,\n",
       " -0.0013888670986386329,\n",
       " -0.04156385548288245,\n",
       " 0.02159919500223442,\n",
       " -0.01936792669010988,\n",
       " -0.025672556119509762,\n",
       " 0.011156340629300087,\n",
       " 0.019860881338865828,\n",
       " -0.0027047639061350166,\n",
       " -0.009145604856107969,\n",
       " 0.005467904045183832,\n",
       " 0.0017902034670903505,\n",
       " -0.02109326702943308,\n",
       " 0.025283382475181252,\n",
       " -0.010825542286562762,\n",
       " -0.006726235918180562,\n",
       " 0.01306978299141008,\n",
       " 0.021534332107297924,\n",
       " -0.0004994408451173357,\n",
       " 0.019329008580618937,\n",
       " 0.024803399287825465,\n",
       " -0.016799374304547934,\n",
       " 0.008490493901333399,\n",
       " 0.01303735154394183,\n",
       " 0.008860210353561666,\n",
       " -0.022675911980128364,\n",
       " 0.0023269402905316478,\n",
       " 0.01007962458272876,\n",
       " 0.006528405299343652,\n",
       " 0.00624949652749743,\n",
       " -0.0018956049728701934,\n",
       " 0.008723998832988597,\n",
       " 0.020301946416730672,\n",
       " 0.02786490632214336,\n",
       " 0.0031296130274350827,\n",
       " 0.02737195167338741,\n",
       " -0.024725564931488808,\n",
       " -0.013102214438878327,\n",
       " -0.012648176968290707,\n",
       " -0.003434466584726856,\n",
       " -0.010053678865960593,\n",
       " 0.023895324346650225,\n",
       " 0.017953925638778533,\n",
       " -0.0014748098989189851,\n",
       " -0.018226346817279443,\n",
       " -0.011350928382786958,\n",
       " 0.005873294344569081,\n",
       " 0.018317154497661487,\n",
       " 0.027060612385395557,\n",
       " -0.0021615411191629854,\n",
       " -0.0007580798458805754,\n",
       " -0.016864235336839197,\n",
       " -0.009281816376681039,\n",
       " -0.002665846495136035,\n",
       " -0.010656900249844059,\n",
       " 0.0029334040741038465,\n",
       " -0.004481995213333245,\n",
       " 0.0061911202945836305,\n",
       " 0.0290583757658649,\n",
       " 0.011273093095127687,\n",
       " 0.033728470673678394,\n",
       " -0.000313974785476891,\n",
       " -0.007199731512191038,\n",
       " -0.009275329714658343,\n",
       " 0.011266607364427606,\n",
       " 0.0008172668533395484,\n",
       " 0.006281927974965677,\n",
       " -0.0017756095252772276,\n",
       " -0.010942294752390362,\n",
       " 0.008542384403547118,\n",
       " -0.024569894356170265,\n",
       " 0.028695146906981942,\n",
       " -0.01739610809508609,\n",
       " -0.005610601762118291,\n",
       " 0.022364570829491278,\n",
       " 0.028695146906981942,\n",
       " -0.025854171480273854,\n",
       " 0.012057928908452632,\n",
       " 0.013582196694911498,\n",
       " 0.0051306195060851194,\n",
       " -0.0005391690888691544,\n",
       " 0.02355804027321282,\n",
       " 0.025322298722026963,\n",
       " 0.004014985350022849,\n",
       " 0.0033760903518130565,\n",
       " 0.0005894374599158919,\n",
       " -0.00435227035478287,\n",
       " 0.002117758944477636,\n",
       " -0.013478416621806676,\n",
       " -0.01808364956600629,\n",
       " 0.011895772602434008,\n",
       " 0.014062178019622054,\n",
       " 0.025854171480273854,\n",
       " -0.009197495358321688,\n",
       " 0.018109594351451843,\n",
       " 0.0007848355804942912,\n",
       " -0.003108532772845245,\n",
       " 0.008795347458625171,\n",
       " -0.005604115565756904,\n",
       " -0.009327220216872063,\n",
       " -0.019056587402118026,\n",
       " 0.01006665125868337,\n",
       " -0.0045079399987787965,\n",
       " 0.013426526119592955,\n",
       " 0.0012177924472460925,\n",
       " 0.030537239712132742,\n",
       " -0.017266382305213098,\n",
       " 0.020820845850932173,\n",
       " 0.017759336953969047,\n",
       " 0.0022280249811131927,\n",
       " 0.007543502713312447,\n",
       " -0.016968016341266635,\n",
       " -0.011694699118247059,\n",
       " -0.024258555068178412,\n",
       " -0.029655109556403055,\n",
       " 0.009074256230471393,\n",
       " 0.012194139497703087,\n",
       " -0.0036517557926479304,\n",
       " -0.005853835755484917,\n",
       " -0.043924847722234754,\n",
       " -0.0007519990076879425,\n",
       " 0.007945649681686347,\n",
       " 0.020198165412303234,\n",
       " 0.005052784684087156,\n",
       " 0.002998266503379034,\n",
       " 0.013374636548701852,\n",
       " -0.017123685053939946,\n",
       " -0.013724893946184648,\n",
       " 0.012667636023036178,\n",
       " 0.03393603268253327,\n",
       " -0.0029334040741038465,\n",
       " -0.013711921553461874,\n",
       " 0.006304629895061189,\n",
       " 0.009787743418159764,\n",
       " 0.008678594992797573,\n",
       " 0.010851487072008314,\n",
       " -0.01988682612431138,\n",
       " -0.003210691180444394,\n",
       " 0.013108700169578406,\n",
       " -0.020768954417395836,\n",
       " -0.018732274790080782,\n",
       " -0.0007061898675358273,\n",
       " -1.4581381690728858e-05,\n",
       " 0.005000894647534744,\n",
       " 0.007141355279277238,\n",
       " -0.007705658553669761,\n",
       " 0.003415007762812038,\n",
       " 0.0056203308238297195,\n",
       " 0.01978304698252917,\n",
       " -0.02092462499271438,\n",
       " -0.009456945075422439,\n",
       " 0.013017893420518975,\n",
       " -0.01925117422428228,\n",
       " -0.010060165527983288,\n",
       " -0.014607023170591722,\n",
       " -0.0052181838554558185,\n",
       " 0.0049911651201620085,\n",
       " 0.08535898114053468,\n",
       " 0.022040260080099267,\n",
       " -0.006583538201246103,\n",
       " -0.012810333274309329,\n",
       " 0.007991053521877371,\n",
       " 0.020885706883223436,\n",
       " -0.0059219415157714525,\n",
       " -0.013802728302521303,\n",
       " -0.003826884258558675,\n",
       " -0.01441243541710485,\n",
       " 0.000757269071335402,\n",
       " -0.002408018210710305,\n",
       " -0.02026302830723973,\n",
       " 0.03370252775087808,\n",
       " 0.00948288986086799,\n",
       " -0.012674121753736257,\n",
       " -0.0016385875211973008,\n",
       " -0.0030663722636655693,\n",
       " -0.0005553846961879512,\n",
       " 0.007569447498757998,\n",
       " -0.006281927974965677,\n",
       " -0.010851487072008314,\n",
       " 0.0038139118658358988,\n",
       " 0.01857660421476224,\n",
       " 0.024777454502379913,\n",
       " -0.014036233234176501,\n",
       " 0.007705658553669761,\n",
       " 0.03437709589775288,\n",
       " 0.00029127292358904273,\n",
       " -0.001718854841453775,\n",
       " -0.004313352710953235,\n",
       " 0.005918698184760105,\n",
       " 0.00696622658053584,\n",
       " 0.011396332222977982,\n",
       " 0.025049877543526056,\n",
       " 0.007160813868361402,\n",
       " -0.020120331055966577,\n",
       " 0.019834936553420276,\n",
       " 0.008639677814629244,\n",
       " -0.006495973851875404,\n",
       " 0.008081861202259418,\n",
       " 0.003226906671347864,\n",
       " 0.012116305141366432,\n",
       " -0.01845985174893464,\n",
       " -3.2526235465058918e-06,\n",
       " -0.017863117958396485,\n",
       " -0.01080608323181729,\n",
       " 0.019419816261000984,\n",
       " -0.004741444930433995,\n",
       " -0.00227667191948491,\n",
       " 0.026982778029058904,\n",
       " 0.0018680384055036407,\n",
       " -0.020743009631950284,\n",
       " -0.016137775756428052,\n",
       " -0.0045728024280539846,\n",
       " 0.012751957041395529,\n",
       " -0.011506598026782885,\n",
       " -5.9034961765900174e-05,\n",
       " -0.016046969938691237,\n",
       " -0.0003632297028940776,\n",
       " -0.006609483452352963,\n",
       " -0.019808991767974723,\n",
       " -0.005652762271297967,\n",
       " 0.009716394792523187,\n",
       " -0.0277351823949156,\n",
       " -0.04581883382356712,\n",
       " -0.01818743057043373,\n",
       " -0.0026301721823177473,\n",
       " -0.011266607364427606,\n",
       " 0.007614851338949022,\n",
       " -0.009353165002317615,\n",
       " -0.007037575206172415,\n",
       " 0.0004905222669127638,\n",
       " -0.0022442407048473166,\n",
       " 0.007076492850002051,\n",
       " 0.02067814859965902,\n",
       " -0.0010353668358057961,\n",
       " -0.02137866153197938,\n",
       " 0.01792798085333298,\n",
       " -0.0016896667249968753,\n",
       " 0.0019264146384174402,\n",
       " -0.026269289910047917,\n",
       " 0.007764034786583561,\n",
       " -0.016578840834292896,\n",
       " -0.002844218292058127,\n",
       " 0.003434466584726856,\n",
       " -0.0134654442290839,\n",
       " 0.0023350481523987097,\n",
       " -0.005578170314650043,\n",
       " 0.01791500752928759,\n",
       " 0.026126592658774764,\n",
       " 0.007329456370741412,\n",
       " 0.004303623183580498,\n",
       " 0.007828897215858747,\n",
       " 0.00896399042666649,\n",
       " -0.0035836502651920487,\n",
       " 0.01585238125388175,\n",
       " -0.00018627683418561813,\n",
       " -0.020003578590138977,\n",
       " -0.00555871172556588,\n",
       " 0.00934667834029492,\n",
       " -0.017318273738749435,\n",
       " -0.004884142181707145,\n",
       " -0.011104451058408984,\n",
       " 0.0256595846581096,\n",
       " 0.002894486663104865,\n",
       " 0.0076861999645855975,\n",
       " 0.013660031051248153,\n",
       " 0.006680832077989538,\n",
       " 0.002281536450340624,\n",
       " 0.02458286768021566,\n",
       " -0.02397316056563211,\n",
       " 0.0060386939815990515,\n",
       " -0.0013085998947974856,\n",
       " 0.0015485909063987446,\n",
       " 0.011136882505877231,\n",
       " 0.00856832918899267,\n",
       " 0.02970700098993939,\n",
       " -0.03728293421939747,\n",
       " -0.01804473331916058,\n",
       " 0.004190114048764248,\n",
       " -0.03979959889671354,\n",
       " 0.007374860210932436,\n",
       " 0.01014448654634264,\n",
       " 0.004319838907314622,\n",
       " -0.0070635204572792746,\n",
       " 0.01014448654634264,\n",
       " -0.005967344890301168,\n",
       " 0.010695817428012388,\n",
       " -0.0017950682307767184,\n",
       " -0.007582419891480774,\n",
       " 0.026878997024631462,\n",
       " -0.008756430280456844,\n",
       " -0.014788637600033199,\n",
       " -0.0261784840923111,\n",
       " -0.0021469470609345354,\n",
       " -0.004147953539584572,\n",
       " -0.001722097939634469,\n",
       " -0.02149541399780698,\n",
       " -0.032093939877382474,\n",
       " -0.03157504044318098,\n",
       " -0.005857079086496265,\n",
       " 0.008555356796269894,\n",
       " -0.025724445690400864,\n",
       " -0.014853500494969696,\n",
       " -0.05227913196564032,\n",
       " -0.00876291694247954,\n",
       " 0.00435551322013291,\n",
       " -0.0016766942158587725,\n",
       " 0.003312849355212889,\n",
       " -0.01048825728180274,\n",
       " 0.012991947703750808,\n",
       " -0.02410288449285987,\n",
       " -0.028850815619655253,\n",
       " -0.010942294752390362,\n",
       " -0.02043167034395843,\n",
       " -0.0039436367243862736,\n",
       " 0.0018810109146417437,\n",
       " 0.03772399743461708,\n",
       " 0.025490940758745667,\n",
       " 0.013569223370866105,\n",
       " 0.004245246950666699,\n",
       " 0.011740102958438083,\n",
       " -0.009268843983958264,\n",
       " 0.00842563193771952,\n",
       " 0.005146835229819243,\n",
       " 0.004773875912240934,\n",
       " -0.008185640344041624,\n",
       " -0.008691567385520349,\n",
       " 0.014347573453490971,\n",
       " 0.012680608415758955,\n",
       " 0.03619324578010336,\n",
       " -0.0035285171304589432,\n",
       " -0.011396332222977982,\n",
       " 0.0040020129573000735,\n",
       " 0.014114068521835773,\n",
       " -0.006356519931613601,\n",
       " -0.0029350257396095207,\n",
       " -0.009859092043796338,\n",
       " -0.011616863830587788,\n",
       " -0.004913330298164045,\n",
       " -0.010112055098874391,\n",
       " -0.0017107469795867131,\n",
       " 0.00962558711214114,\n",
       " 0.012985461973050727,\n",
       " -0.017175576487476283,\n",
       " 0.031497204224199084,\n",
       " 0.016254528222255652,\n",
       " 0.02799463211201635,\n",
       " 0.0022247818829324987,\n",
       " 0.030952360004552034,\n",
       " -0.012226570945171334,\n",
       " 0.031860434945727274,\n",
       " 0.01900469596858169,\n",
       " 0.014191902878172428,\n",
       " 0.023648847953594867,\n",
       " -0.011221203524236582,\n",
       " -0.02289644358773817,\n",
       " -0.007342428763464188,\n",
       " 0.018109594351451843,\n",
       " -0.006408409502504704,\n",
       " 0.025983895407501616,\n",
       " -0.029758890560830493,\n",
       " -0.005763028540764178,\n",
       " -0.006502460048236791,\n",
       " 0.03271661845336618,\n",
       " -0.009534779431759094,\n",
       " -0.004271192201773559,\n",
       " -0.001043474581257531,\n",
       " 0.0019280361875077872,\n",
       " -0.0021096510826105735,\n",
       " -0.02593200583661051,\n",
       " -0.022675911980128364,\n",
       " -0.01013800081564256,\n",
       " 0.006314358956772617,\n",
       " -0.007919704896240795,\n",
       " -0.010592037354907564,\n",
       " 0.037775887005508185,\n",
       " -0.016630730405184,\n",
       " -0.012550883557208578,\n",
       " -0.008659136869374718,\n",
       " -0.008587788243738141,\n",
       " 0.02119704803386052,\n",
       " -0.003664728185370706,\n",
       " 0.014114068521835773,\n",
       " 0.018122567675497234,\n",
       " -0.014658912741482824,\n",
       " -0.027346006887941858,\n",
       " -0.0005801135235425649,\n",
       " -0.015463207609553243,\n",
       " -0.01595616225830919,\n",
       " 0.026282263234093307,\n",
       " -0.002231268079293887,\n",
       " 0.010300156190338566,\n",
       " -0.025439051187854562,\n",
       " -0.002193972333800579,\n",
       " -0.008840751298816195,\n",
       " -0.013854618804735024,\n",
       " -0.01120174446949111,\n",
       " 0.01261574552082246,\n",
       " 0.023078058948502265,\n",
       " -0.003554462148735149,\n",
       " -0.020353835987621777,\n",
       " 0.002769626568240858,\n",
       " -0.013906508375626127,\n",
       " 0.02335048012700317,\n",
       " 0.00490035790544127,\n",
       " -0.01756475013180479,\n",
       " -0.017772310278014437,\n",
       " 0.0050203532366189085,\n",
       " -0.011733616296415386,\n",
       " 0.013737866338907424,\n",
       " -0.009242898267190096,\n",
       " 0.01172064390369261,\n",
       " 0.028513531546217847,\n",
       " -0.012447103484103756,\n",
       " -0.015917244148818246,\n",
       " 0.0011926582617227237,\n",
       " -0.0015291322008992537,\n",
       " 0.006080854490778728,\n",
       " -0.008951018033943714,\n",
       " 0.015489152394998793,\n",
       " -0.009074256230471393,\n",
       " 0.005140349033457855,\n",
       " 0.003079344656388345,\n",
       " -0.014191902878172428,\n",
       " -0.03694565014596006,\n",
       " -0.014191902878172428,\n",
       " 0.0034279803883654684,\n",
       " 0.026619547307530713,\n",
       " -0.02502393089543527,\n",
       " 0.019510623941383032,\n",
       " 0.005600872234745555,\n",
       " 0.006868933169453712,\n",
       " 0.019925744233802323,\n",
       " -0.0011432006070134961,\n",
       " -0.012810333274309329,\n",
       " -0.025854171480273854,\n",
       " -0.018667411895144287,\n",
       " -0.007537016051289751,\n",
       " 0.03559651012691998,\n",
       " -0.0010904998541235746,\n",
       " -0.006817043132901301,\n",
       " -0.006680832077989538,\n",
       " -0.014503243097486898,\n",
       " -0.02503690421948066,\n",
       " -0.03315768166858579,\n",
       " 0.005801945718932506,\n",
       " 0.008607246367160997,\n",
       " -0.014127040914558549,\n",
       " -0.015216730285175268,\n",
       " -0.017863117958396485,\n",
       " 0.001957224303964687,\n",
       " 0.017214492734321993,\n",
       " 0.0071154104938316864,\n",
       " -0.029136210122201554,\n",
       " 0.03131558886343499,\n",
       " 0.019860881338865828,\n",
       " -0.019458734370491927,\n",
       " -0.001501565633532701,\n",
       " 0.0068754193658151,\n",
       " -0.005428986867015505,\n",
       " -0.028435697189881193,\n",
       " 0.01341355372687018,\n",
       " 0.006583538201246103,\n",
       " -0.019056587402118026,\n",
       " 0.00948288986086799,\n",
       " -0.0143864906316593,\n",
       " -0.01805770478056074,\n",
       " 0.009521807039036318,\n",
       " 0.00458253195542672,\n",
       " 0.00928830210738112,\n",
       " 0.00368094390910483,\n",
       " 0.010611496409653035,\n",
       " -0.0029090807213333148,\n",
       " 0.017045850697603292,\n",
       " 0.005662491798670703,\n",
       " 0.001151308468880558,\n",
       " -0.0146718851342056,\n",
       " 0.009405054573208718,\n",
       " -0.0036679712835514,\n",
       " 0.013711921553461874,\n",
       " -0.01126012070240491,\n",
       " -0.014140013307281325,\n",
       " 0.01845985174893464,\n",
       " -0.016799374304547934,\n",
       " 0.016799374304547934,\n",
       " 0.010883918519476562,\n",
       " -0.019160366543900232,\n",
       " 0.017992841885624243,\n",
       " 0.01013800081564256,\n",
       " -0.002662603396955341,\n",
       " -0.009385596449785863,\n",
       " -0.019549542050873975,\n",
       " -0.0021210020426583294,\n",
       " -0.009722880523223268,\n",
       " -0.024375307534006012,\n",
       " -0.0047868487706250185,\n",
       " 0.017175576487476283,\n",
       " -0.011247148309682134,\n",
       " 0.010987698592581384,\n",
       " -0.007160813868361402,\n",
       " -0.0025539587929948038,\n",
       " 0.018109594351451843,\n",
       " -0.000459712601365517,\n",
       " -0.001255899141907564,\n",
       " -0.0024680161091297785,\n",
       " -0.008004025914600147,\n",
       " -0.007264593941466225,\n",
       " -0.006726235918180562,\n",
       " -0.01821337535587928,\n",
       " 0.03391008603444249,\n",
       " 0.025439051187854562,\n",
       " -0.0161118309709825,\n",
       " -0.012044956515729855,\n",
       " 0.008775889335202316,\n",
       " -0.01054014778401646,\n",
       " 0.005941400104855617,\n",
       " -0.004225788361582535,\n",
       " -0.0030663722636655693,\n",
       " 0.009995302633046793,\n",
       " 0.015930217472863637,\n",
       " 0.0074072911927393756,\n",
       " 0.021404608180070166,\n",
       " -0.02121001949526068,\n",
       " 0.012966002918305256,\n",
       " -0.02175486371490773,\n",
       " -0.014542160275655226,\n",
       " 0.007070006653640663,\n",
       " 0.004932788887248209,\n",
       " 0.016682621838720334,\n",
       " -0.0159431889342638,\n",
       " -0.012382240589167261,\n",
       " -0.021884589504780724,\n",
       " 0.005127376175073772,\n",
       " 0.0037458063383800175,\n",
       " -0.02460881246566121,\n",
       " 0.012881681899945905,\n",
       " -0.012310891963530685,\n",
       " -0.012771416096141,\n",
       " -0.016929098231775692,\n",
       " 0.00982666059632809,\n",
       " -0.030978304789997586,\n",
       " -0.00825050323897812,\n",
       " 0.034221427185079575,\n",
       " -0.014632967956037272,\n",
       " -0.003228528336853538,\n",
       " 0.0073489149598255765,\n",
       " -0.026619547307530713,\n",
       " 0.005831133835389406,\n",
       " -0.02613956598282016,\n",
       " 0.002529635440224272,\n",
       " -0.005422500670654117,\n",
       " 0.01578752022159049,\n",
       " -0.001259953072841095,\n",
       " 0.004848467868888858,\n",
       " 0.016578840834292896,\n",
       " -0.028124356039244108,\n",
       " 0.015566986751335448,\n",
       " 0.01165578194007873,\n",
       " -0.008925072317175547,\n",
       " 0.03525922605348258,\n",
       " -0.007031089009811027,\n",
       " 0.005626817020191107,\n",
       " -0.011552001866973909,\n",
       " 0.008561842526969973,\n",
       " -0.00696622658053584,\n",
       " -0.006363006127974989,\n",
       " 0.018836053931862988,\n",
       " -0.017357189985595146,\n",
       " -0.012816819005009408,\n",
       " -0.03224960859005578,\n",
       " -0.02157325021678887,\n",
       " -0.02672332831195815,\n",
       " 0.004696041090242971,\n",
       " -0.02252024140480982,\n",
       " -0.008821292244070723,\n",
       " -0.013647058658525377,\n",
       " 0.019341981904664327,\n",
       " -0.005104674720639568,\n",
       " -0.014036233234176501,\n",
       " -0.007815924823135973,\n",
       " -0.017227466058367388,\n",
       " -0.015891299363372694,\n",
       " 8.908451526310985e-05,\n",
       " -0.02185864471933517,\n",
       " 0.017123685053939946,\n",
       " 0.008561842526969973,\n",
       " 0.006178147901860854,\n",
       " 0.012622232182845155,\n",
       " -0.019277119009727832,\n",
       " -0.01360814148035705,\n",
       " 0.004589018151788108,\n",
       " 0.00830887947189192,\n",
       " 0.0007329456603572067,\n",
       " 0.02239051561493683,\n",
       " 0.22665532948363004,\n",
       " -0.022468351833918716,\n",
       " -0.013647058658525377,\n",
       " 0.05095593859469101,\n",
       " 0.018226346817279443,\n",
       " 0.018148512460942786,\n",
       " 0.018135539136897395,\n",
       " 0.006324088484145353,\n",
       " -0.0020156005368784863,\n",
       " 0.026100647873329212,\n",
       " -0.0133486917632563,\n",
       " -0.00019803315240212902,\n",
       " -0.012849250452477656,\n",
       " 0.010183403724510967,\n",
       " 0.006953254187813064,\n",
       " -0.0009859091810965684,\n",
       " -0.02462178392706137,\n",
       " -0.02289644358773817,\n",
       " -0.021521358783252533,\n",
       " -0.013225452635406004,\n",
       " -0.005292775812103742,\n",
       " -0.010650413587821364,\n",
       " -0.02306508562445687,\n",
       " -0.00299340197252332,\n",
       " 0.036867813926978174,\n",
       " 0.005140349033457855,\n",
       " -0.02499798610998972,\n",
       " 0.005630060351202455,\n",
       " 0.010034220742537736,\n",
       " -0.004858197396261594,\n",
       " -0.017733392168523494,\n",
       " -0.02916215677029234,\n",
       " 0.008944531371921019,\n",
       " 0.014827554778201527,\n",
       " -0.006791098347455749,\n",
       " -0.005403041615908645,\n",
       " 0.0049100869671526975,\n",
       " 0.005941400104855617,\n",
       " 0.02223484690226352,\n",
       " 0.01197360789009328,\n",
       " -0.005707895173200419,\n",
       " -0.007342428763464188,\n",
       " -0.007245135352382061,\n",
       " -0.01486647288769247,\n",
       " -0.005656005136648007,\n",
       " -0.0017739878597715535,\n",
       " ...]"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "aba1201a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Collection(name=test_collection)"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0f9e2a",
   "metadata": {},
   "source": [
    "# ChromaDB file peristence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "d50a43ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = TextLoader(\"constitution.txt\")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "5b890ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 970, which is longer than the specified 500\n",
      "Created a chunk of size 5997, which is longer than the specified 500\n",
      "Created a chunk of size 1702, which is longer than the specified 500\n",
      "Created a chunk of size 684, which is longer than the specified 500\n",
      "Created a chunk of size 578, which is longer than the specified 500\n",
      "Created a chunk of size 667, which is longer than the specified 500\n",
      "Created a chunk of size 645, which is longer than the specified 500\n",
      "Created a chunk of size 653, which is longer than the specified 500\n",
      "Created a chunk of size 709, which is longer than the specified 500\n",
      "Created a chunk of size 635, which is longer than the specified 500\n",
      "Created a chunk of size 596, which is longer than the specified 500\n",
      "Created a chunk of size 528, which is longer than the specified 500\n",
      "Created a chunk of size 650, which is longer than the specified 500\n",
      "Created a chunk of size 510, which is longer than the specified 500\n",
      "Created a chunk of size 638, which is longer than the specified 500\n",
      "Created a chunk of size 545, which is longer than the specified 500\n",
      "Created a chunk of size 4364, which is longer than the specified 500\n",
      "Created a chunk of size 1175, which is longer than the specified 500\n",
      "Created a chunk of size 10177, which is longer than the specified 500\n",
      "Created a chunk of size 3126, which is longer than the specified 500\n",
      "Created a chunk of size 3050, which is longer than the specified 500\n",
      "Created a chunk of size 913, which is longer than the specified 500\n",
      "Created a chunk of size 587, which is longer than the specified 500\n",
      "Created a chunk of size 1777, which is longer than the specified 500\n",
      "Created a chunk of size 3242, which is longer than the specified 500\n",
      "Created a chunk of size 2515, which is longer than the specified 500\n",
      "Created a chunk of size 1742, which is longer than the specified 500\n",
      "Created a chunk of size 1605, which is longer than the specified 500\n",
      "Created a chunk of size 1127, which is longer than the specified 500\n",
      "Created a chunk of size 1879, which is longer than the specified 500\n",
      "Created a chunk of size 8056, which is longer than the specified 500\n",
      "Created a chunk of size 1005, which is longer than the specified 500\n",
      "Created a chunk of size 4574, which is longer than the specified 500\n",
      "Created a chunk of size 6829, which is longer than the specified 500\n",
      "Created a chunk of size 3161, which is longer than the specified 500\n",
      "Created a chunk of size 514, which is longer than the specified 500\n",
      "Created a chunk of size 2755, which is longer than the specified 500\n",
      "Created a chunk of size 844, which is longer than the specified 500\n"
     ]
    }
   ],
   "source": [
    "# split it into chunks\n",
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(chunk_size=500)\n",
    "docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "bc806217",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_function = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "ce1fc15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load it into Chroma\n",
    "db = Chroma.from_documents(docs, embedding_function,persist_directory='chroma_db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "44c937e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jimmy\\AppData\\Local\\Temp\\ipykernel_18800\\3220725503.py:2: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  db.persist()\n"
     ]
    }
   ],
   "source": [
    "# Helpful to force a save\n",
    "db.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "4eaf0532",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jimmy\\AppData\\Local\\Temp\\ipykernel_18800\\2668171911.py:1: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  db_connection = Chroma(persist_directory='chroma_db/',embedding_function=embedding_function)\n"
     ]
    }
   ],
   "source": [
    "db_connection = Chroma(persist_directory='chroma_db/',embedding_function=embedding_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "3810c833",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_doc = \"How many amendments are there?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "20c772bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = db_connection.similarity_search(new_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "fea94a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Congress shall make no law respecting an establishment of \n",
      "religion, or prohibiting the free exercise thereof; or \n",
      "abridging the freedom of speech, or of the press; of the right \n",
      "of the people peaceably to assemble, and to petition the \n",
      "Government for a redress of grievances.\n",
      "---------------------------------------------------------------------------\n",
      "                                   * * * * *                              \n",
      "\\12\\The first ten amendments of the Constitution of the United States \n",
      "(and two others, one of which failed of ratification and the other \n",
      "which later became the 27th amendment) were proposed to the \n",
      "legislatures of the several States by the First Congress on September \n",
      "25, 1789. The first ten amendments were ratified by the following \n",
      "States, and the notifications of ratification by the Governors thereof \n",
      "were successively communicated by the President to Congress: New \n",
      "Jersey, November 20, 1789; Maryland, December 19, 1789; North Carolina, \n",
      "December 22, 1789; South Carolina, January 19, 1790; New Hampshire, \n",
      "January 25, 1790; Delaware, January 28, 1790; New York, February 24, \n",
      "1790; Pennsylvania, March 10, 1790; Rhode Island, June 7, 1790; \n",
      "Vermont, November 3, 1791; and Virginia, December 15, 1791.\n",
      "                                   * * * * *                              \n",
      "Ratification was completed on December 15, 1791.\n",
      "                                   * * * * *                              \n",
      "The amendments were subsequently ratified by the legislatures of \n",
      "Massachusetts, March 2, 1939; Georgia, March 18, 1939; and Connecticut, \n",
      "April 19, 1939.\n",
      "                                   * * * * *                              \n",
      "\\13\\Only the 13th, 14th, 15th, and 16th articles of amendment had \n",
      "numbers assigned to them at the time of ratification.\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "bcc0028d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a new document\n",
    "loader = TextLoader(\"custom_text_data.txt\")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "9f7ba138",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(chunk_size=500)\n",
    "docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "ad8d9269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load it into Chroma\n",
    "db = Chroma.from_documents(docs, embedding_function,persist_directory='chroma_db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "b7ca2f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = db.similarity_search('asdfg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "e16d0301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'asdfg: testing data'"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "759688ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = db.similarity_search('zzzz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "117e01de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q'"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "da35960c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'constitution.txt'}, page_content='Q'),\n",
       " Document(metadata={'source': 'constitution.txt'}, page_content='J'),\n",
       " Document(metadata={'source': 'constitution.txt'}, page_content='J'),\n",
       " Document(metadata={'source': 'constitution.txt'}, page_content='J')]"
      ]
     },
     "execution_count": 492,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9096af24",
   "metadata": {},
   "source": [
    "# Create Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "fe883057",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.9)\n",
    "prompt = \"Brooklyn bridge in the night\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "19385fa4",
   "metadata": {},
   "outputs": [
    {
     "ename": "AuthenticationError",
     "evalue": "Error code: 401 - {'error': {'code': 'invalid_api_key', 'message': 'Incorrect API key provided: **********. You can find your API key at https://platform.openai.com/account/api-keys.', 'param': None, 'type': 'invalid_request_error'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[495], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m image_url \u001b[38;5;241m=\u001b[39m DallEAPIWrapper()\u001b[38;5;241m.\u001b[39mrun(prompt)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_community\\utilities\\dalle_image_generator.py:143\u001b[0m, in \u001b[0;36mDallEAPIWrapper.run\u001b[1;34m(self, query)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run query through OpenAI and parse result.\"\"\"\u001b[39;00m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_openai_v1():\n\u001b[1;32m--> 143\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[0;32m    144\u001b[0m         prompt\u001b[38;5;241m=\u001b[39mquery,\n\u001b[0;32m    145\u001b[0m         n\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn,\n\u001b[0;32m    146\u001b[0m         size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize,\n\u001b[0;32m    147\u001b[0m         model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_name,\n\u001b[0;32m    148\u001b[0m         quality\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquality,\n\u001b[0;32m    149\u001b[0m     )\n\u001b[0;32m    150\u001b[0m     image_urls \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseparator\u001b[38;5;241m.\u001b[39mjoin([item\u001b[38;5;241m.\u001b[39murl \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m response\u001b[38;5;241m.\u001b[39mdata])\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\openai\\resources\\images.py:264\u001b[0m, in \u001b[0;36mImages.generate\u001b[1;34m(self, prompt, model, n, quality, response_format, size, style, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate\u001b[39m(\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    221\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    222\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ImagesResponse:\n\u001b[0;32m    223\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;124;03m    Creates an image given a prompt.\u001b[39;00m\n\u001b[0;32m    225\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;124;03m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 264\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[0;32m    265\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/images/generations\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    266\u001b[0m         body\u001b[38;5;241m=\u001b[39mmaybe_transform(\n\u001b[0;32m    267\u001b[0m             {\n\u001b[0;32m    268\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt,\n\u001b[0;32m    269\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[0;32m    270\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m: n,\n\u001b[0;32m    271\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquality\u001b[39m\u001b[38;5;124m\"\u001b[39m: quality,\n\u001b[0;32m    272\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_format\u001b[39m\u001b[38;5;124m\"\u001b[39m: response_format,\n\u001b[0;32m    273\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m\"\u001b[39m: size,\n\u001b[0;32m    274\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstyle\u001b[39m\u001b[38;5;124m\"\u001b[39m: style,\n\u001b[0;32m    275\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m: user,\n\u001b[0;32m    276\u001b[0m             },\n\u001b[0;32m    277\u001b[0m             image_generate_params\u001b[38;5;241m.\u001b[39mImageGenerateParams,\n\u001b[0;32m    278\u001b[0m         ),\n\u001b[0;32m    279\u001b[0m         options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[0;32m    280\u001b[0m             extra_headers\u001b[38;5;241m=\u001b[39mextra_headers, extra_query\u001b[38;5;241m=\u001b[39mextra_query, extra_body\u001b[38;5;241m=\u001b[39mextra_body, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[0;32m    281\u001b[0m         ),\n\u001b[0;32m    282\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mImagesResponse,\n\u001b[0;32m    283\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\openai\\_base_client.py:1277\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1263\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1264\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1265\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1272\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1273\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1274\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1275\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1276\u001b[0m     )\n\u001b[1;32m-> 1277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\openai\\_base_client.py:954\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    951\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    952\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 954\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[0;32m    955\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m    956\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m    957\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m    958\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m    959\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[0;32m    960\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\openai\\_base_client.py:1058\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1055\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1057\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1058\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1060\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m   1061\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1062\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1066\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[0;32m   1067\u001b[0m )\n",
      "\u001b[1;31mAuthenticationError\u001b[0m: Error code: 401 - {'error': {'code': 'invalid_api_key', 'message': 'Incorrect API key provided: **********. You can find your API key at https://platform.openai.com/account/api-keys.', 'param': None, 'type': 'invalid_request_error'}}"
     ]
    }
   ],
   "source": [
    "image_url = DallEAPIWrapper().run(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759e9f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1115351",
   "metadata": {},
   "outputs": [],
   "source": [
    "!(image_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "7ebb2d14",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image_url' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[496], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m display(Image(url\u001b[38;5;241m=\u001b[39mimage_url))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'image_url' is not defined"
     ]
    }
   ],
   "source": [
    "display(Image(url=image_url))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b327ba9",
   "metadata": {},
   "source": [
    "# LLMChains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "4fd3dc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_message_prompt = HumanMessagePromptTemplate.from_template(\n",
    "        \"Tell me 3 things about {place}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "080cfc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt_template = ChatPromptTemplate.from_messages([human_message_prompt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "id": "7a648e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "fce967b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(llm=chat, prompt=chat_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "0249d16c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"1. Piscataway is located in Middlesex County, New Jersey and is known for its diverse population and strong sense of community.\\n\\n2. Piscataway is home to Rutgers University's main campus, which is one of the oldest and largest universities in the United States.\\n\\n3. Piscataway has a rich history, with landmarks such as the East Jersey Olde Towne Village, which showcases life in colonial New Jersey, and the Cornelius Low House, a historic home dating back to the 18th century.\""
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(place=\"Piscataway, NJ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53469ce",
   "metadata": {},
   "source": [
    "## Simple Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "61d17a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"Give me a simple bullet point outline for a blog post on {topic}\"\n",
    "first_prompt = ChatPromptTemplate.from_template(template)\n",
    "chain_one = LLMChain(llm=llm,prompt=first_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "5a6726c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"Write a blog post using this outline: {outline}\"\n",
    "second_prompt = ChatPromptTemplate.from_template(template)\n",
    "chain_two = LLMChain(llm=llm,prompt=second_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "0ff722e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_chain = SimpleSequentialChain(chains=[chain_one,chain_two],\n",
    "                                  verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "f5e05e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3m\n",
      "\n",
      "- Introduction to data science and its role in today's world\n",
      "- Definition of data science and its key principles\n",
      "- Importance of data science in decision making and problem solving\n",
      "- Key skills required for a career in data science\n",
      "- Overview of the data science process: data collection, cleaning, analysis, and visualization\n",
      "- Discussion on popular tools and technologies used in data science, such as Python, R, SQL, and Tableau\n",
      "- Real-life examples of how data science is used in various industries, such as finance, healthcare, and marketing\n",
      "- Challenges and limitations of data science, including privacy concerns and bias in data\n",
      "- Future trends and advancements in the field of data science\n",
      "- Conclusion highlighting the growing demand for data scientists and the endless possibilities of using data for better decision making.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m \n",
      "\n",
      "Data Science: Unlocking the Power of Data in Today’s World\n",
      "\n",
      "In today’s digital age, the amount of data being generated is growing exponentially. It is estimated that the amount of data created from the beginning of civilization until 2003 was 5 exabytes (5 billion gigabytes), while the same amount of data is now created every two days. With this vast amount of data, the role of data science has become increasingly important in various industries. From business to healthcare, data science is revolutionizing the way decisions are made and problems are solved. In this blog post, we will explore the world of data science, its core principles, and its impact on our daily lives.\n",
      "\n",
      "What is Data Science?\n",
      "\n",
      "Data science is a multidisciplinary field that uses scientific methods, processes, algorithms, and systems to extract knowledge and insights from data in various forms such as structured, unstructured, and semi-structured. It combines elements from mathematics, statistics, computer science, and programming to analyze and interpret vast amounts of data. The core principles of data science include data understanding, data preparation, data exploration, data modeling, and data evaluation.\n",
      "\n",
      "The Importance of Data Science\n",
      "\n",
      "Data has become the driving force behind decision making and problem solving in today’s world. With the help\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " \n",
      "\n",
      "Data Science: Unlocking the Power of Data in Today’s World\n",
      "\n",
      "In today’s digital age, the amount of data being generated is growing exponentially. It is estimated that the amount of data created from the beginning of civilization until 2003 was 5 exabytes (5 billion gigabytes), while the same amount of data is now created every two days. With this vast amount of data, the role of data science has become increasingly important in various industries. From business to healthcare, data science is revolutionizing the way decisions are made and problems are solved. In this blog post, we will explore the world of data science, its core principles, and its impact on our daily lives.\n",
      "\n",
      "What is Data Science?\n",
      "\n",
      "Data science is a multidisciplinary field that uses scientific methods, processes, algorithms, and systems to extract knowledge and insights from data in various forms such as structured, unstructured, and semi-structured. It combines elements from mathematics, statistics, computer science, and programming to analyze and interpret vast amounts of data. The core principles of data science include data understanding, data preparation, data exploration, data modeling, and data evaluation.\n",
      "\n",
      "The Importance of Data Science\n",
      "\n",
      "Data has become the driving force behind decision making and problem solving in today’s world. With the help\n"
     ]
    }
   ],
   "source": [
    "result = full_chain.run(\"Data Science\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ac1fc7",
   "metadata": {},
   "source": [
    "## Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "76ee6ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "template1 = \"Give a summary of this employee's performance review:\\n{review}\"\n",
    "prompt1 = ChatPromptTemplate.from_template(template1)\n",
    "chain_1 = LLMChain(llm=llm,\n",
    "                     prompt=prompt1,\n",
    "                     output_key=\"review_summary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "3118a73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "template2 = \"Identify key employee weaknesses in this review summary:\\n{review_summary}\"\n",
    "prompt2 = ChatPromptTemplate.from_template(template2)\n",
    "chain_2 = LLMChain(llm=llm,\n",
    "                     prompt=prompt2,\n",
    "                     output_key=\"weaknesses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "cd011b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "template3 = \"Create a personalized plan to help address and fix these weaknesses:\\n{weaknesses}\"\n",
    "prompt3 = ChatPromptTemplate.from_template(template3)\n",
    "chain_3 = LLMChain(llm=llm,\n",
    "                     prompt=prompt3,\n",
    "                     output_key=\"final_plan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "1b50d50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_chain = SequentialChain(chains=[chain_1,chain_2,chain_3],\n",
    "                            input_variables=['review'],\n",
    "                            output_variables=['review_summary','weaknesses','final_plan'],\n",
    "                            verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "id": "4c9c4085",
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_review = '''\n",
    "Employee Information:\n",
    "Name: Joe Schmo\n",
    "Position: Software Engineer\n",
    "Date of Review: July 14, 2023\n",
    "\n",
    "Strengths:\n",
    "Joe is a highly skilled software engineer with a deep understanding of programming languages, algorithms, and software development best practices. His technical expertise shines through in his ability to efficiently solve complex problems and deliver high-quality code.\n",
    "\n",
    "One of Joe's greatest strengths is his collaborative nature. He actively engages with cross-functional teams, contributing valuable insights and seeking input from others. His open-mindedness and willingness to learn from colleagues make him a true team player.\n",
    "\n",
    "Joe consistently demonstrates initiative and self-motivation. He takes the lead in seeking out new projects and challenges, and his proactive attitude has led to significant improvements in existing processes and systems. His dedication to self-improvement and growth is commendable.\n",
    "\n",
    "Another notable strength is Joe's adaptability. He has shown great flexibility in handling changing project requirements and learning new technologies. This adaptability allows him to seamlessly transition between different projects and tasks, making him a valuable asset to the team.\n",
    "\n",
    "Joe's problem-solving skills are exceptional. He approaches issues with a logical mindset and consistently finds effective solutions, often thinking outside the box. His ability to break down complex problems into manageable parts is key to his success in resolving issues efficiently.\n",
    "\n",
    "Weaknesses:\n",
    "While Joe possesses numerous strengths, there are a few areas where he could benefit from improvement. One such area is time management. Occasionally, Joe struggles with effectively managing his time, resulting in missed deadlines or the need for additional support to complete tasks on time. Developing better prioritization and time management techniques would greatly enhance his efficiency.\n",
    "\n",
    "Another area for improvement is Joe's written communication skills. While he communicates well verbally, there have been instances where his written documentation lacked clarity, leading to confusion among team members. Focusing on enhancing his written communication abilities will help him effectively convey ideas and instructions.\n",
    "\n",
    "Additionally, Joe tends to take on too many responsibilities and hesitates to delegate tasks to others. This can result in an excessive workload and potential burnout. Encouraging him to delegate tasks appropriately will not only alleviate his own workload but also foster a more balanced and productive team environment.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "0bae576e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jimmy\\AppData\\Local\\Temp\\ipykernel_18800\\2927280498.py:1: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  results = seq_chain(employee_review)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "results = seq_chain(employee_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "a19b3d6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'review': \"\\nEmployee Information:\\nName: Joe Schmo\\nPosition: Software Engineer\\nDate of Review: July 14, 2023\\n\\nStrengths:\\nJoe is a highly skilled software engineer with a deep understanding of programming languages, algorithms, and software development best practices. His technical expertise shines through in his ability to efficiently solve complex problems and deliver high-quality code.\\n\\nOne of Joe's greatest strengths is his collaborative nature. He actively engages with cross-functional teams, contributing valuable insights and seeking input from others. His open-mindedness and willingness to learn from colleagues make him a true team player.\\n\\nJoe consistently demonstrates initiative and self-motivation. He takes the lead in seeking out new projects and challenges, and his proactive attitude has led to significant improvements in existing processes and systems. His dedication to self-improvement and growth is commendable.\\n\\nAnother notable strength is Joe's adaptability. He has shown great flexibility in handling changing project requirements and learning new technologies. This adaptability allows him to seamlessly transition between different projects and tasks, making him a valuable asset to the team.\\n\\nJoe's problem-solving skills are exceptional. He approaches issues with a logical mindset and consistently finds effective solutions, often thinking outside the box. His ability to break down complex problems into manageable parts is key to his success in resolving issues efficiently.\\n\\nWeaknesses:\\nWhile Joe possesses numerous strengths, there are a few areas where he could benefit from improvement. One such area is time management. Occasionally, Joe struggles with effectively managing his time, resulting in missed deadlines or the need for additional support to complete tasks on time. Developing better prioritization and time management techniques would greatly enhance his efficiency.\\n\\nAnother area for improvement is Joe's written communication skills. While he communicates well verbally, there have been instances where his written documentation lacked clarity, leading to confusion among team members. Focusing on enhancing his written communication abilities will help him effectively convey ideas and instructions.\\n\\nAdditionally, Joe tends to take on too many responsibilities and hesitates to delegate tasks to others. This can result in an excessive workload and potential burnout. Encouraging him to delegate tasks appropriately will not only alleviate his own workload but also foster a more balanced and productive team environment.\\n\",\n",
       " 'review_summary': '\\nOverall, Joe is a highly skilled and valuable member of the team. His technical expertise, collaborative nature, initiative, adaptability, and problem-solving skills make him a top performer. With some improvements in time management and written communication, Joe has the potential to excel even further in his role. ',\n",
       " 'weaknesses': '\\n\\nWeaknesses: \\n1. Time management \\n2. Written communication',\n",
       " 'final_plan': ' skills \\n3. Procrastination\\n\\n1. Time management:\\n- Start by analyzing and prioritizing your tasks. Make a list of all the tasks that need to be accomplished and categorize them into urgent, important, and non-urgent.\\n- Set realistic and achievable goals for each day and week. This will help you stay focused and motivated.\\n- Use a planner or calendar to schedule your tasks and allocate specific time slots for each task.\\n- Set deadlines for yourself and stick to them. This will help you stay organized and avoid last-minute rushes.\\n- Eliminate distractions during your scheduled work time. This includes turning off your phone, finding a quiet place to work, and avoiding social media.\\n- Take short breaks in between tasks to avoid burnout and stay energized.\\n- Reflect on your progress at the end of each day and make necessary adjustments to your schedule for the next day.\\n\\n2. Written communication skills:\\n- Read and practice writing regularly. This could include reading articles, books, and blogs on a variety of topics, and actively practicing writing in different styles.\\n- Use online resources such as grammar and style guides to improve your writing skills.\\n- Get feedback from others on your writing. This could be from friends, family, or even a writing tutor.\\n-'}"
      ]
     },
     "execution_count": 512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "cec87b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " skills \n",
      "3. Procrastination\n",
      "\n",
      "1. Time management:\n",
      "- Start by analyzing and prioritizing your tasks. Make a list of all the tasks that need to be accomplished and categorize them into urgent, important, and non-urgent.\n",
      "- Set realistic and achievable goals for each day and week. This will help you stay focused and motivated.\n",
      "- Use a planner or calendar to schedule your tasks and allocate specific time slots for each task.\n",
      "- Set deadlines for yourself and stick to them. This will help you stay organized and avoid last-minute rushes.\n",
      "- Eliminate distractions during your scheduled work time. This includes turning off your phone, finding a quiet place to work, and avoiding social media.\n",
      "- Take short breaks in between tasks to avoid burnout and stay energized.\n",
      "- Reflect on your progress at the end of each day and make necessary adjustments to your schedule for the next day.\n",
      "\n",
      "2. Written communication skills:\n",
      "- Read and practice writing regularly. This could include reading articles, books, and blogs on a variety of topics, and actively practicing writing in different styles.\n",
      "- Use online resources such as grammar and style guides to improve your writing skills.\n",
      "- Get feedback from others on your writing. This could be from friends, family, or even a writing tutor.\n",
      "-\n"
     ]
    }
   ],
   "source": [
    "print(results['final_plan'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9f4463",
   "metadata": {},
   "source": [
    "## LLMRouterChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "01d93631",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.router.llm_router import LLMRouterChain,RouterOutputParser\n",
    "from langchain.chains.router import MultiPromptChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "072a8a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "beginner_template = '''You are a physics teacher who is really\n",
    "focused on beginners and explaining complex topics in simple to understand terms. \n",
    "You assume no prior knowledge. Here is the question\\n{input}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "id": "bf5927f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_template = '''You are a world expert physics professor who explains physics topics\n",
    "to advanced audience members. You can assume anyone you answer has a \n",
    "PhD level understanding of Physics. Here is the question\\n{input}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "id": "89263fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_infos = [\n",
    "      {'name':'advanced physics','description': 'Answers advanced physics questions',\n",
    "     'prompt_template':expert_template},\n",
    "    {'name':'beginner physics','description': 'Answers basic beginner physics questions',\n",
    "     'prompt_template':beginner_template},\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "id": "5149ef31",
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_chains = {}\n",
    "for p_info in prompt_infos:\n",
    "    name = p_info[\"name\"]\n",
    "    prompt_template = p_info[\"prompt_template\"]\n",
    "    prompt = ChatPromptTemplate.from_template(template=prompt_template)\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    destination_chains[name] = chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "2c9696ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#destination_chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "id": "b817db5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.router.multi_prompt_prompt import MULTI_PROMPT_ROUTER_TEMPLATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "id": "7ec8ac6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given a raw text input to a language model select the model prompt best suited for the input. You will be given the names of the available prompts and a description of what the prompt is best suited for. You may also revise the original input if you think that revising it will ultimately lead to a better response from the language model.\n",
      "\n",
      "<< FORMATTING >>\n",
      "Return a markdown code snippet with a JSON object formatted to look like:\n",
      "```json\n",
      "{{{{\n",
      "    \"destination\": string \\ name of the prompt to use or \"DEFAULT\"\n",
      "    \"next_inputs\": string \\ a potentially modified version of the original input\n",
      "}}}}\n",
      "```\n",
      "\n",
      "REMEMBER: \"destination\" MUST be one of the candidate prompt names specified below OR it can be \"DEFAULT\" if the input is not well suited for any of the candidate prompts.\n",
      "REMEMBER: \"next_inputs\" can just be the original input if you don't think any modifications are needed.\n",
      "\n",
      "<< CANDIDATE PROMPTS >>\n",
      "{destinations}\n",
      "\n",
      "<< INPUT >>\n",
      "{{input}}\n",
      "\n",
      "<< OUTPUT (must include ```json at the start of the response) >>\n",
      "<< OUTPUT (must end with ```) >>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(MULTI_PROMPT_ROUTER_TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "id": "dcfde4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
    "destinations_str = \"\\n\".join(destinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "1eff60bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advanced physics: Answers advanced physics questions\n",
      "beginner physics: Answers basic beginner physics questions\n"
     ]
    }
   ],
   "source": [
    "print(destinations_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "id": "32de4aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(\n",
    "    destinations=destinations_str\n",
    ")\n",
    "router_prompt = PromptTemplate(\n",
    "    template=router_template,\n",
    "    input_variables=[\"input\"],\n",
    "    output_parser=RouterOutputParser(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "id": "c2555add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given a raw text input to a language model select the model prompt best suited for the input. You will be given the names of the available prompts and a description of what the prompt is best suited for. You may also revise the original input if you think that revising it will ultimately lead to a better response from the language model.\n",
      "\n",
      "<< FORMATTING >>\n",
      "Return a markdown code snippet with a JSON object formatted to look like:\n",
      "```json\n",
      "{{\n",
      "    \"destination\": string \\ name of the prompt to use or \"DEFAULT\"\n",
      "    \"next_inputs\": string \\ a potentially modified version of the original input\n",
      "}}\n",
      "```\n",
      "\n",
      "REMEMBER: \"destination\" MUST be one of the candidate prompt names specified below OR it can be \"DEFAULT\" if the input is not well suited for any of the candidate prompts.\n",
      "REMEMBER: \"next_inputs\" can just be the original input if you don't think any modifications are needed.\n",
      "\n",
      "<< CANDIDATE PROMPTS >>\n",
      "advanced physics: Answers advanced physics questions\n",
      "beginner physics: Answers basic beginner physics questions\n",
      "\n",
      "<< INPUT >>\n",
      "{input}\n",
      "\n",
      "<< OUTPUT (must include ```json at the start of the response) >>\n",
      "<< OUTPUT (must end with ```) >>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(router_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "id": "a9c09d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_chain = LLMRouterChain.from_llm(llm, router_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "id": "56137b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_prompt = ChatPromptTemplate.from_template(\"{input}\")\n",
    "default_chain = LLMChain(llm=llm,prompt=default_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "id": "88b85126",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jimmy\\AppData\\Local\\Temp\\ipykernel_18800\\3038952769.py:1: LangChainDeprecationWarning: Use RunnableLambda to select from multiple prompt templates. See example in API reference: https://api.python.langchain.com/en/latest/chains/langchain.chains.router.multi_prompt.MultiPromptChain.html\n",
      "  chain = MultiPromptChain(router_chain=router_chain,\n"
     ]
    }
   ],
   "source": [
    "chain = MultiPromptChain(router_chain=router_chain, \n",
    "                         destination_chains=destination_chains, \n",
    "                         default_chain=default_chain, verbose=True\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "id": "9134e6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "beginner physics: {'input': 'How do magnets work?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nMagnets work by creating a magnetic field around them. This magnetic field is invisible, but it interacts with other objects that also have a magnetic field. Objects with a magnetic field can either be attracted to or repelled by the magnet, depending on the direction of their magnetic field. This attraction or repulsion is what we typically observe as \"magnetism\".\\n\\nThe reason for this magnetic field is due to the microscopic arrangement of atoms within the magnet. These atoms have a special property called \"spin\", which creates tiny magnetic fields. In a magnet, these tiny magnetic fields align in the same direction, creating a strong overall magnetic field.\\n\\nWhen another object with a magnetic field, such as another magnet or a piece of metal, comes near the magnet, the magnetic fields interact with each other. If the two magnetic fields are aligned in the same direction, they will attract each other. However, if they are aligned in opposite directions, they will repel each other.\\n\\nIt\\'s important to note that magnets have two poles - a north pole and a south pole. These poles are always found in pairs, so if you were to cut a magnet in half, you would not get a single north or south pole, but two smaller magnets with their own north and south poles.\\n\\nThe'"
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"How do magnets work?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3664269f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.run(\"How do Feynman Diagrams work?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1438a2f8",
   "metadata": {},
   "source": [
    "## TransformChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e76069",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import TransformChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bb0c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_review = open('yelp_review.txt').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdba956a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(yelp_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e61eca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_review.split('REVIEW:')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8b7598",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_fun(inputs: dict) -> dict:\n",
    "    '''\n",
    "    Notice how this always takes an inputs dictionary.\n",
    "    Also outputs a dictionary. You can call the output and input keys whatever you want, \n",
    "    just make sure to reference it correct in the chain call.\n",
    "    '''   \n",
    "    text = inputs['text']\n",
    "    only_review_text = text.split('REVIEW:')[-1]\n",
    "    lower_case_text = only_review_text.lower()\n",
    "    return {'output':lower_case_text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e09761",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_chain = TransformChain(input_variables=['text'],\n",
    "                                 output_variables=['output'],\n",
    "                                 transform=transformer_fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751f2eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"Create a one sentence summary of this review:\\n{review_text}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0397ac2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI()\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "summary_chain = LLMChain(llm=llm,\n",
    "                     prompt=prompt,\n",
    "                     output_key=\"review_summary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cd8abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequential_chain = SimpleSequentialChain(chains=[transform_chain,summary_chain],\n",
    "                                        verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990d8812",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = sequential_chain(yelp_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd48059d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "bb0d1054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"TITLE: AN ABSOLUTE DELIGHT! A CULINARY HAVEN!\\n\\nREVIEW:\\nOH MY GOODNESS, WHERE DO I BEGIN? THIS RESTAURANT IS ABSOLUTELY PHENOMENAL! I WENT THERE LAST NIGHT WITH MY FRIENDS, AND WE WERE BLOWN AWAY BY THE EXPERIENCE!\\n\\nFIRST OF ALL, THE AMBIANCE IS OUT OF THIS WORLD! THE MOMENT YOU STEP INSIDE, YOU'RE GREETED WITH A WARM AND INVITING ATMOSPHERE. THE DECOR IS STUNNING, AND IT IMMEDIATELY SETS THE TONE FOR AN UNFORGETTABLE DINING EXPERIENCE.\\n\\nNOW, LET'S TALK ABOUT THE FOOD! WOW, JUST WOW! THE MENU IS A PARADISE FOR FOOD LOVERS. EVERY DISH WE ORDERED WAS A MASTERPIECE. THE FLAVORS WERE BOLD, VIBRANT, AND EXPLODED IN OUR MOUTHS. FROM STARTERS TO DESSERTS, EVERY BITE WAS PURE BLISS!\\n\\nTHEIR SEAFOOD PLATTER IS A MUST-TRY! THE FRESHNESS OF THE SEAFOOD IS UNMATCHED, AND THE PRESENTATION IS SIMPLY STUNNING. I HAVE NEVER TASTED SUCH DELICIOUS AND PERFECTLY COOKED SEAFOOD IN MY LIFE. IT'S A SEAFOOD LOVER'S DREAM COME TRUE!\\n\\nTHE SERVICE WAS EXEMPLARY. THE STAFF WAS ATTENTIVE, FRIENDLY, AND EXTREMELY KNOWLEDGEABLE ABOUT THE MENU. THEY WENT ABOVE AND BEYOND TO ENSURE THAT WE HAD THE BEST DINING EXPERIENCE POSSIBLE.\\n\\nAND LET'S NOT FORGET ABOUT THE DESSERTS! OH MY, OH MY! I HAD THEIR SIGNATURE CHOCOLATE LAVA CAKE, AND IT WAS PURE HEAVEN. THE CAKE WAS MOIST, AND WHEN I CUT INTO IT, THE WARM CHOCOLATE OOOZED OUT, CREATING AN EXPLOSION OF FLAVOR IN MY MOUTH. IT WAS LIKE A SYMPHONY OF CHOCOLATEY GOODNESS!\\n\\nIN CONCLUSION, THIS RESTAURANT IS A HIDDEN GEM! IF YOU WANT TO INDULGE IN A MEMORABLE DINING EXPERIENCE, DO YOURSELF A FAVOR AND VISIT THIS PLACE. YOU WON'T REGRET IT! I CAN'T WAIT TO GO BACK AND TRY MORE OF THEIR DELECTABLE DISHES. KUDOS TO THE ENTIRE TEAM FOR CREATING SUCH A CULINARY HAVEN!\\n\\nALL I CAN SAY IS... WOOHOO!\""
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['input']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3c1b3b",
   "metadata": {},
   "source": [
    "## LLMMathChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "1514724a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import LLMMathChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "746bbafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_math_model = LLMMathChain.from_llm(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "e3b085b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is 17 raised to the power of 11?',\n",
       " 'answer': 'Answer: 34271896307633'}"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_math_model(\"What is 17 raised to the power of 11?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85475fa4",
   "metadata": {},
   "source": [
    "#  OpenAI Functions API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "2e14e369",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.openai_functions import create_openai_fn_chain,create_structured_output_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "d5451293",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scientist():\n",
    "    \n",
    "    def __init__(self,first_name,last_name):\n",
    "        self.first_name = first_name\n",
    "        self.last_name = last_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "76818904",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_schema = {\"title\": \"Scientist\",\n",
    "               \"description\": \"Information about a famous scientist\",\n",
    "               \"type\": \"object\",\n",
    "               \"properties\":{\n",
    "                   \"first_name\":{'title':'First Name',\n",
    "                                 'description': \"First name of scientist\",\n",
    "                                 \"type\": \"string\"},\n",
    "                   \"last_name\":{'title':'Last Name',\n",
    "                                 'description': \"Last name of scientist\",\n",
    "                                 \"type\": \"string\"},\n",
    "               },\n",
    "                \"required\": ['first_name','last_name']\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "7c244b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = 'Name a famous {country} scientist'\n",
    "# human_prompt = HumanMessagePromptTemplate.from_template(template)\n",
    "chat_prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "29c5bcec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jimmy\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_core\\_api\\deprecation.py:151: LangChainDeprecationWarning: The function `create_structured_output_chain` was deprecated in LangChain 0.1.1 and will be removed in 1.0. Use ChatOpenAI.with_structured_output instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "chain = create_structured_output_chain(json_schema,llm,chat_prompt,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "1df27645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mHuman: Name a famous Indian scientist\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "result = chain.run(country='Indian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "4a8a7090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'first_name': 'APJ', 'last_name': 'Abdul Kalam'}"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d71f3fc",
   "metadata": {},
   "source": [
    "# Memory / History"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695426de",
   "metadata": {},
   "source": [
    "## ChatMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "e45d8aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = ChatMessageHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "10a4f211",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.add_user_message(\"Hello, nice to meet you.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "eb044380",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.add_ai_message(\"Nice to meet you too!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "b3523d6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InMemoryChatMessageHistory(messages=[HumanMessage(content='Hello, nice to meet you.'), AIMessage(content='Nice to meet you too!')])"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "64109c60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Hello, nice to meet you.'),\n",
       " AIMessage(content='Nice to meet you too!')]"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f64539",
   "metadata": {},
   "source": [
    "## ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "75cc696e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.0)\n",
    "memory = ConversationBufferMemory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "49190162",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jimmy\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_core\\_api\\deprecation.py:151: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use RunnableWithMessageHistory: https://api.python.langchain.com/en/latest/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "a047c52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hello, nice to meet you!\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hello! It's nice to meet you too. I'm an AI designed to assist with any questions or tasks you may have. How can I help you today?\""
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hello, nice to meet you!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "0e7b104d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hello, nice to meet you!\n",
      "AI: Hello! It's nice to meet you too. I'm an AI designed to assist with any questions or tasks you may have. How can I help you today?\n",
      "Human: Tell me about the Einstein-Szilard Letter \n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The Einstein-Szilard Letter was a letter written by physicist Albert Einstein to President Franklin D. Roosevelt in 1939. In the letter, Einstein and physicist Leo Szilard warned the President about the potential development of nuclear weapons by Nazi Germany and urged the United States to start its own nuclear research program. This letter ultimately led to the establishment of the Manhattan Project, which resulted in the development of the atomic bomb during World War II.'"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Tell me about the Einstein-Szilard Letter \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "2d57a081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Human: Hello, nice to meet you!\\nAI: Hello! It's nice to meet you too. I'm an AI designed to assist with any questions or tasks you may have. How can I help you today?\\nHuman: Tell me about the Einstein-Szilard Letter \\nAI: The Einstein-Szilard Letter was a letter written by physicist Albert Einstein to President Franklin D. Roosevelt in 1939. In the letter, Einstein and physicist Leo Szilard warned the President about the potential development of nuclear weapons by Nazi Germany and urged the United States to start its own nuclear research program. This letter ultimately led to the establishment of the Manhattan Project, which resulted in the development of the atomic bomb during World War II.\""
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "c2533874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: Hello, nice to meet you!\\nAI: Hello! It's nice to meet you too. I'm an AI designed to assist with any questions or tasks you may have. How can I help you today?\\nHuman: Tell me about the Einstein-Szilard Letter \\nAI: The Einstein-Szilard Letter was a letter written by physicist Albert Einstein to President Franklin D. Roosevelt in 1939. In the letter, Einstein and physicist Leo Szilard warned the President about the potential development of nuclear weapons by Nazi Germany and urged the United States to start its own nuclear research program. This letter ultimately led to the establishment of the Manhattan Project, which resulted in the development of the atomic bomb during World War II.\"}"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "fd974f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"Very Interesting.\"}, \n",
    "                    {\"output\": \"Yes, it was my pleasure as an AI to answer.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "157850a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: Hello, nice to meet you!\\nAI: Hello! It's nice to meet you too. I'm an AI designed to assist with any questions or tasks you may have. How can I help you today?\\nHuman: Tell me about the Einstein-Szilard Letter \\nAI: The Einstein-Szilard Letter was a letter written by physicist Albert Einstein to President Franklin D. Roosevelt in 1939. In the letter, Einstein and physicist Leo Szilard warned the President about the potential development of nuclear weapons by Nazi Germany and urged the United States to start its own nuclear research program. This letter ultimately led to the establishment of the Manhattan Project, which resulted in the development of the atomic bomb during World War II.\\nHuman: Very Interesting.\\nAI: Yes, it was my pleasure as an AI to answer.\"}"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "4bc2482b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to pickle\n",
    "with open('memory.pkl','wb') as f:\n",
    "    f.write(pickle.dumps(conversation.memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "b4147595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read back from pickle file\n",
    "llm = ChatOpenAI(temperature=0.0)\n",
    "reload_conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = pickle.loads(open('memory.pkl','rb').read()),\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "d1579e27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Human: Hello, nice to meet you!\\nAI: Hello! It's nice to meet you too. I'm an AI designed to assist with any questions or tasks you may have. How can I help you today?\\nHuman: Tell me about the Einstein-Szilard Letter \\nAI: The Einstein-Szilard Letter was a letter written by physicist Albert Einstein to President Franklin D. Roosevelt in 1939. In the letter, Einstein and physicist Leo Szilard warned the President about the potential development of nuclear weapons by Nazi Germany and urged the United States to start its own nuclear research program. This letter ultimately led to the establishment of the Manhattan Project, which resulted in the development of the atomic bomb during World War II.\\nHuman: Very Interesting.\\nAI: Yes, it was my pleasure as an AI to answer.\""
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload_conversation.memory.buffer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb5b3ad",
   "metadata": {},
   "source": [
    "# Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "a3a99811",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "16c42270",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = load_tools([\"llm-math\"], llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "7e9e4f59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CHAT_CONVERSATIONAL_REACT_DESCRIPTION',\n",
       " 'CHAT_ZERO_SHOT_REACT_DESCRIPTION',\n",
       " 'CONVERSATIONAL_REACT_DESCRIPTION',\n",
       " 'OPENAI_FUNCTIONS',\n",
       " 'OPENAI_MULTI_FUNCTIONS',\n",
       " 'REACT_DOCSTORE',\n",
       " 'SELF_ASK_WITH_SEARCH',\n",
       " 'STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION',\n",
       " 'ZERO_SHOT_REACT_DESCRIPTION',\n",
       " '__add__',\n",
       " '__class__',\n",
       " '__contains__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getnewargs__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__members__',\n",
       " '__mod__',\n",
       " '__module__',\n",
       " '__mul__',\n",
       " '__name__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__qualname__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__rmod__',\n",
       " '__rmul__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " 'capitalize',\n",
       " 'casefold',\n",
       " 'center',\n",
       " 'count',\n",
       " 'encode',\n",
       " 'endswith',\n",
       " 'expandtabs',\n",
       " 'find',\n",
       " 'format',\n",
       " 'format_map',\n",
       " 'index',\n",
       " 'isalnum',\n",
       " 'isalpha',\n",
       " 'isascii',\n",
       " 'isdecimal',\n",
       " 'isdigit',\n",
       " 'isidentifier',\n",
       " 'islower',\n",
       " 'isnumeric',\n",
       " 'isprintable',\n",
       " 'isspace',\n",
       " 'istitle',\n",
       " 'isupper',\n",
       " 'join',\n",
       " 'ljust',\n",
       " 'lower',\n",
       " 'lstrip',\n",
       " 'maketrans',\n",
       " 'partition',\n",
       " 'removeprefix',\n",
       " 'removesuffix',\n",
       " 'replace',\n",
       " 'rfind',\n",
       " 'rindex',\n",
       " 'rjust',\n",
       " 'rpartition',\n",
       " 'rsplit',\n",
       " 'rstrip',\n",
       " 'split',\n",
       " 'splitlines',\n",
       " 'startswith',\n",
       " 'strip',\n",
       " 'swapcase',\n",
       " 'title',\n",
       " 'translate',\n",
       " 'upper',\n",
       " 'zfill']"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(AgentType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "c7a57426",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jimmy\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_core\\_api\\deprecation.py:151: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 1.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "agent = initialize_agent(tools, \n",
    "                         llm, \n",
    "                         agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, \n",
    "                         verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "dfab6936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should use a calculator to solve this problem.\n",
      "Action: Calculator\n",
      "Action Input: 2 * 3\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAnswer: 6\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: 6\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'6'"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"What is 2 times 3?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "7f729771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should use a calculator to solve this problem.\n",
      "Action: Calculator\n",
      "Action Input: 2 * 3\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAnswer: 6\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m Now I need to multiply 6 by 5.\n",
      "Action: Calculator\n",
      "Action Input: 6 * 5\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAnswer: 30\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: 30\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'30'"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"What is 2 times 3? What is that number multiplied by 5?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c6bf2e",
   "metadata": {},
   "source": [
    "## Python Agent Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "8309fa9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Tool\n",
    "from langchain_experimental.utilities import PythonREPL\n",
    "from langchain_experimental.tools.python.tool import PythonREPLTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "619562bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.agents.agent_toolkits import create_python_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "da4b4f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_python_agent(tool=PythonREPLTool(),\n",
    "                         llm=llm, \n",
    "                         agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, \n",
    "                         verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "354fd84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "python_list = [7,3,1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "585ba536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python REPL can execute arbitrary code. Use with caution.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m I can use the built-in sort function to sort the list in ascending order and then reverse it to get the descending order.\n",
      "Action: Python_REPL\n",
      "Action Input: sorted([7, 3, 1, 2])\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I can use the reverse function to reverse the list.\n",
      "Action: Python_REPL\n",
      "Action Input: sorted([7, 3, 1, 2]).reverse()\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: [7, 3, 2, 1]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[7, 3, 2, 1]'"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(f'''Sort this Python list in descending order {python_list}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545a28a7",
   "metadata": {},
   "source": [
    "## Custom Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "a76d79cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "21d3799e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def first_verse(text: str) -> str:\n",
    "    '''Returns the first verse in the book named jmj_qwerty'''\n",
    "    return \"In the beginning was the Word, and the Word was with God, and the Word was God and He was in the beginning with God\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "050752e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = load_tools([\"llm-math\"], llm=llm) \n",
    "tools = tools +[first_verse]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "eab7ce2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent(tools, \n",
    "                         llm, \n",
    "                         agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, \n",
    "                         verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "be3ee73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should use the first_verse function to get the first verse.\n",
      "Action: first_verse\n",
      "Action Input: \"jmj_qwerty\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mIn the beginning was the Word, and the Word was with God, and the Word was God and He was in the beginning with God\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should use the Calculator function to get the verse number.\n",
      "Action: Calculator\n",
      "Action Input: \"1\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAnswer: 1\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: The first verse in the book named jmj_qwerty is \"In the beginning was the Word, and the Word was with God, and the Word was God and He was in the beginning with God\".\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The first verse in the book named jmj_qwerty is \"In the beginning was the Word, and the Word was with God, and the Word was God and He was in the beginning with God\".'"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"what is the first verse in the book named jmj_qwerty?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "34891279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should use the first_verse function to get the first verse in the book named jmj_qwerty\n",
      "Action: first_verse\n",
      "Action Input: \"Gospel of John\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mIn the beginning was the Word, and the Word was with God, and the Word was God and He was in the beginning with God\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: In the beginning was the Word, and the Word was with God, and the Word was God and He was in the beginning with God\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'In the beginning was the Word, and the Word was with God, and the Word was God and He was in the beginning with God'"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"what is the first verse in the Gospel of John?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6266e2c",
   "metadata": {},
   "source": [
    "## Conversation Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "6aaa0705",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "2e057f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_chain = initialize_agent(tools, \n",
    "                               llm,\n",
    "                               agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION, \n",
    "                               verbose=True, \n",
    "                               memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "592377f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Thought: Do I need to use a tool? Yes\n",
      "Action: None\n",
      "Action Input: None\u001b[0m\n",
      "Observation: None is not a valid tool, try one of [Calculator, first_verse].\n",
      "Thought:\u001b[32;1m\u001b[1;3m Do I need to use a tool? No\n",
      "AI: There are many delicious Thai food recipes available online. Some popular dishes include pad thai, green curry, and tom yum soup. You can also try making your own Thai iced tea or mango sticky rice for dessert.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'There are many delicious Thai food recipes available online. Some popular dishes include pad thai, green curry, and tom yum soup. You can also try making your own Thai iced tea or mango sticky rice for dessert.'"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_chain.run(input=\"What are some good thai food recipes?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "adccea7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
      "Action: None\n",
      "Action Input: None\u001b[0m\n",
      "Observation: None is not a valid tool, try one of [Calculator, first_verse].\n",
      "Thought:\u001b[32;1m\u001b[1;3m Do I need to use a tool? No\n",
      "AI: The spiciness level of Thai dishes can vary depending on the recipe and the chef's preferences. However, green curry and tom yum soup are generally considered to be on the spicier side. If you prefer a milder dish, you can always ask for less spice when ordering or adjust the amount of chili peppers used in the recipe.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The spiciness level of Thai dishes can vary depending on the recipe and the chef's preferences. However, green curry and tom yum soup are generally considered to be on the spicier side. If you prefer a milder dish, you can always ask for less spice when ordering or adjust the amount of chili peppers used in the recipe.\""
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_chain.run(\"Which one of those dishes is the spiciest?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd276c0",
   "metadata": {},
   "source": [
    "# Metadata query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "dff50620",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\n",
    "    Document(\n",
    "        page_content=\"A bunch of scientists bring back dinosaurs and mayhem breaks loose\",\n",
    "        metadata={\"year\": 1993, \"rating\": 7.7, \"genre\": \"science fiction\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Leo DiCaprio gets lost in a dream within a dream within a dream within a ...\",\n",
    "        metadata={\"year\": 2010, \"director\": \"Christopher Nolan\", \"rating\": 8.2},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"A psychologist / detective gets lost in a series of dreams within dreams within dreams and Inception reused the idea\",\n",
    "        metadata={\"year\": 2006, \"director\": \"Satoshi Kon\", \"rating\": 8.6},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"A bunch of normal-sized women are supremely wholesome and some men pine after them\",\n",
    "        metadata={\"year\": 2019, \"director\": \"Greta Gerwig\", \"rating\": 8.3},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Toys come alive and have a blast doing so\",\n",
    "        metadata={\"year\": 1995, \"genre\": \"animated\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Three men walk into the Zone, three men walk out of the Zone\",\n",
    "        metadata={\n",
    "            \"year\": 1979,\n",
    "            \"director\": \"Andrei Tarkovsky\",\n",
    "            \"genre\": \"thriller\",\n",
    "            \"rating\": 9.9,\n",
    "        },\n",
    "    ),\n",
    "]\n",
    "vectorstore = Chroma.from_documents(docs, OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "a652195e",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"genre\",\n",
    "        description=\"The genre of the movie. One of ['science fiction', 'comedy', 'drama', 'thriller', 'romance', 'action', 'animated']\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"year\",\n",
    "        description=\"The year the movie was released\",\n",
    "        type=\"integer\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"director\",\n",
    "        description=\"The name of the movie director\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"rating\", description=\"A 1-10 rating for the movie\", type=\"float\"\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "eaf6a661",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_content_description = \"Brief summary of a movie\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "d637860b",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm,\n",
    "    vectorstore,\n",
    "    document_content_description,\n",
    "    metadata_field_info,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "7a83d29b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'director': 'Andrei Tarkovsky', 'genre': 'thriller', 'rating': 9.9, 'year': 1979}, page_content='Three men walk into the Zone, three men walk out of the Zone'),\n",
       " Document(metadata={'director': 'Satoshi Kon', 'rating': 8.6, 'year': 2006}, page_content='A psychologist / detective gets lost in a series of dreams within dreams within dreams and Inception reused the idea')]"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"I want to watch a movie rated higher than 8.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "665f2c32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'director': 'Andrei Tarkovsky', 'genre': 'thriller', 'rating': 9.9, 'year': 1979}, page_content='Three men walk into the Zone, three men walk out of the Zone')]"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"How many movies has rating higher than 9?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39396821",
   "metadata": {},
   "source": [
    "# Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "5f2015b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "a9770fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jimmy\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "d1cce1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jimmy\\AppData\\Roaming\\Python\\Python311\\site-packages\\bitsandbytes\\cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jimmy\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2\", pad_token_id=tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "653342f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode context the generation is conditioned on\n",
    "model_inputs = tokenizer('Gospel of John begins with', return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "1fc1f486",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jimmy\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\generation\\utils.py:1270: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# generate 40 new tokens\n",
    "greedy_output = model.generate(**model_inputs, max_new_tokens=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "6ed05b32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   38, 13994,   286,  1757,  6140,   351,   262,  2456,    11,   366,\n",
       "          1870,   314,   481,  1577,   345,   262,  8251,   286,   262, 13239,\n",
       "           286,  9538,    11,   290,   262,  8251,   286,   262, 13239,   286,\n",
       "          5968,    11,   290,   262,  8251,   286,   262, 13239,   286,   262,\n",
       "          2877,  1793,    11,   290,   262,  8251]])"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "greedy_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "41ee2e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Gospel of John begins with the words, \"And I will give you the keys of the kingdom of heaven, and the keys of the kingdom of hell, and the keys of the kingdom of the living God, and the keys\n"
     ]
    }
   ],
   "source": [
    "print(\"Output:\\n\" + 100 * '-')\n",
    "print(tokenizer.decode(greedy_output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee40c86",
   "metadata": {},
   "source": [
    "## Hugging Fcae- Accessing Pre-trained Models Using Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "14c37205",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jimmy\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=\"gpt2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0bea85",
   "metadata": {},
   "source": [
    "pipe('Gospel of John begins with', max_length=30, num_return_sequences=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "23fdc161",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Gospel of Mark begins with the Gospel, the only work of God on earth by which the gospel is the one gospel which all humans are made to'},\n",
       " {'generated_text': 'Gospel of Mark begins with the resurrection and death of Jesus Christ, the first and final resurrection of the human race from the dead.\\n\\n\\nThis'},\n",
       " {'generated_text': \"Gospel of Mark begins with a reference to Jesus' own father who had been an enemy of the Jews to the end of the Roman Empire. We\"},\n",
       " {'generated_text': 'Gospel of Mark begins with the opening verse:\\n\\nGod hath appointed me a god to teach many of you for ever\\n\\nIn these words'},\n",
       " {'generated_text': 'Gospel of Mark begins with a verse: \"Behold, the Lord hath delivered the dead, the righteous, and the damned, from the evil'}]"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe('Gospel of Mark begins with', max_length=30, num_return_sequences=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "fac6095f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Config, GPT2Model\n",
    "\n",
    "# Building the config\n",
    "config = GPT2Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "4185c32e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2Config {\n",
       "  \"activation_function\": \"gelu_new\",\n",
       "  \"attn_pdrop\": 0.1,\n",
       "  \"bos_token_id\": 50256,\n",
       "  \"embd_pdrop\": 0.1,\n",
       "  \"eos_token_id\": 50256,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"layer_norm_epsilon\": 1e-05,\n",
       "  \"model_type\": \"gpt2\",\n",
       "  \"n_embd\": 768,\n",
       "  \"n_head\": 12,\n",
       "  \"n_inner\": null,\n",
       "  \"n_layer\": 12,\n",
       "  \"n_positions\": 1024,\n",
       "  \"reorder_and_upcast_attn\": false,\n",
       "  \"resid_pdrop\": 0.1,\n",
       "  \"scale_attn_by_inverse_layer_idx\": false,\n",
       "  \"scale_attn_weights\": true,\n",
       "  \"summary_activation\": null,\n",
       "  \"summary_first_dropout\": 0.1,\n",
       "  \"summary_proj_to_labels\": true,\n",
       "  \"summary_type\": \"cls_index\",\n",
       "  \"summary_use_proj\": true,\n",
       "  \"transformers_version\": \"4.31.0\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 50257\n",
       "}"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76019b2",
   "metadata": {},
   "source": [
    "## Hugging Face with Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "b8f99383",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import HuggingFaceEndpoint\n",
    "from langchain.llms import HuggingFaceHub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5898ca64",
   "metadata": {},
   "source": [
    "## Hugging Face with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "afe43824",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "c7c430d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.2'"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "b27ef278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to C:\\Users\\jimmy\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jimmy\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_core\\_api\\deprecation.py:151: LangChainDeprecationWarning: The class `HuggingFaceEndpoint` was deprecated in LangChain 0.0.37 and will be removed in 0.3. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEndpoint`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "llm = HuggingFaceEndpoint(repo_id=\"mistralai/Mistral-7B-Instruct-v0.2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "9d9cfe50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The LLM takes a prompt as an input and outputs a completion\n",
    "our_query = 'Gospel of John begins with'\n",
    "\n",
    "#Last week langchain has recommended to use invoke function for the below please :)\n",
    "completion = llm.invoke(our_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "3d1ab98a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " a famous verse:\n",
      "\n",
      "> In the beginning was the Word, and the Word was with God, and the Word was God. He was in the beginning with God. All things came into being through him, and without him not one thing came into being. What has come into being in him was life, and the life was the light of all people. The light shines in the darkness, and the darkness did not overcome it. John 1:1-5\n",
      "\n",
      "In the first verse, we see three distinct persons. God, the Word, and the Word was God. This is known as the doctrine of the Trinity, which is central to Christianity. The doctrine of the Trinity states that God is one essence, but exists in three distinct persons: the Father, the Son, and the Holy Spirit.\n",
      "\n",
      "The second and third verses explain that the Word created all things, and that the Word became flesh and dwelt among us as Jesus Christ.\n",
      "\n",
      "In the fourth verse, John explains that the Word, who became flesh, is the source of life and light for all people. The fifth verse explains that the light shines in the darkness, but the darkness did not overcome it.\n",
      "\n",
      "Overall, this passage emphasizes the deity of Jesus Christ and the importance of Jesus as the source of life and light for all people. It also highlights the idea that God's light shines in the darkness of the world, and that the darkness cannot overcome it.\n"
     ]
    }
   ],
   "source": [
    "print(completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8169caeb",
   "metadata": {},
   "source": [
    "## Tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "6fd77b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jimmy\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sshleifer/distilbart-cnn-12-6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "c18973f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[   0,  100,  657, 1844, 2239,  328,    2,    1],\n",
      "        [   0,  100, 4157,   42,   98,  203,  328,    2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "raw_inputs =     [\n",
    "        \"I love deep learning!\",\n",
    "        \"I hate this so much!\",\n",
    "    ]\n",
    "inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "bab45422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer output for \"I love deep learning!\"\n",
      "Input ids: tensor([   0,  100,  657, 1844, 2239,  328,    2,    1])\n",
      "Attention Mask: tensor([1, 1, 1, 1, 1, 1, 1, 0])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Tokenizer output for \"I hate this so much!\"\n",
      "Input ids: tensor([   0,  100, 4157,   42,   98,  203,  328,    2])\n",
      "Attention Mask: tensor([1, 1, 1, 1, 1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "print('Tokenizer output for \"I love deep learning!\"')\n",
    "print(f\"Input ids: {inputs['input_ids'][0]}\")\n",
    "print(f\"Attention Mask: {inputs['attention_mask'][0]}\")\n",
    "print(\"-\"*100)\n",
    "print('Tokenizer output for \"I hate this so much!\"')\n",
    "print(f\"Input ids: {inputs['input_ids'][1]}\")\n",
    "print(f\"Attention Mask: {inputs['attention_mask'][1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "88a851ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [0, 1121, 5, 1786, 21, 5, 15690, 6, 8, 5, 15690, 21, 19, 1840, 6, 463, 5, 15690, 21, 1840, 4, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('In the beginning was the Word, and the Word was with God,and the Word was God.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "3a7fcb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.tokenize('In the beginning was the Word, and the Word was with God,and the Word was God.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "55b90c3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In',\n",
       " 'Ġthe',\n",
       " 'Ġbeginning',\n",
       " 'Ġwas',\n",
       " 'Ġthe',\n",
       " 'ĠWord',\n",
       " ',',\n",
       " 'Ġand',\n",
       " 'Ġthe',\n",
       " 'ĠWord',\n",
       " 'Ġwas',\n",
       " 'Ġwith',\n",
       " 'ĠGod',\n",
       " ',',\n",
       " 'and',\n",
       " 'Ġthe',\n",
       " 'ĠWord',\n",
       " 'Ġwas',\n",
       " 'ĠGod',\n",
       " '.']"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "8180deb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1121,\n",
       " 5,\n",
       " 1786,\n",
       " 21,\n",
       " 5,\n",
       " 15690,\n",
       " 6,\n",
       " 8,\n",
       " 5,\n",
       " 15690,\n",
       " 21,\n",
       " 19,\n",
       " 1840,\n",
       " 6,\n",
       " 463,\n",
       " 5,\n",
       " 15690,\n",
       " 21,\n",
       " 1840,\n",
       " 4]"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "a6e883f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_tokens = tokenizer.decode(token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "68045b1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In the beginning was the Word, and the Word was with God,and the Word was God.'"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "3d282006",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BartTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [0, 1121, 5, 1786, 21, 5, 15690, 6, 8, 5, 15690, 21, 19, 1840, 6, 463, 5, 15690, 21, 1840, 4, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_prepped_ids = tokenizer.prepare_for_model(token_ids)\n",
    "model_prepped_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd87ca5",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "a2968aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9998645782470703},\n",
       " {'label': 'NEGATIVE', 'score': 0.9994558691978455},\n",
       " {'label': 'POSITIVE', 'score': 0.9798815250396729}]"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "classifier(\n",
    "    [\n",
    "        \"I love deep learning!\",\n",
    "        \"I hate this so much!\",\n",
    "        'In the beginning was the Word, and the Word was with God,and the Word was God.',\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "b3c32b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to gpt2 and revision 6c0e608 (https://huggingface.co/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "C:\\Users\\jimmy\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\generation\\utils.py:1369: UserWarning: Using `max_length`'s default (50) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[{'generated_text': 'In the beginning was the Word, and the Word was with God, for God made things for him, the Word being the Word.\\n\\nTherefore when we worship the Word, we must worship it in its proper form. This has happened before,'}],\n",
       " [{'generated_text': \"When two objects in space get close to each other (and when the objects are still too small to fit into their respective spaces), it's a relatively simple process.\\n\\nIn fact, these two processes are different from one another. They happen on\"}]]"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_generator = pipeline(\"text-generation\")\n",
    "\n",
    "text_generator([\n",
    "    'In the beginning was the Word, and the Word was with God',\n",
    "    'When two objects in space get close to each other'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "fb8ad666",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'summary_text': ' A Fibonacci heap is a collection of trees satisfying the min-heap property . It allows faster amortized time for many operations than binary or binomial heaps . Nodes have a \"mark\" indicating if they\\'ve lost a child since the last time they were made a child of another node .'}]"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer = pipeline(\"summarization\")\n",
    "\n",
    "summarizer([\n",
    "    \"\"\"A Fibonacci heap is a collection of trees satisfying the min-heap property. It allows faster amortized time for many operations than binary or binomial heaps.\n",
    "    Trees in a Fibonacci heap can have any shape, which facilitates efficient operations. Lazy strategies are employed: node removals and consolidations are delayed until\n",
    "    absolutely necessary (like during an extract-min operation). The main advantage lies in decreasing a key and merging two heaps, which are constant and amortized\n",
    "    constant time, respectively. Nodes have a \"mark\" indicating if they've lost a child since the last time they were made a child of another node, assisting in\n",
    "    restructuring during operations.\"\"\"\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e7861f",
   "metadata": {},
   "source": [
    "## Model Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "941b1a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "model = AutoModel.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "43791c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 22, 768])\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer('In the beginning was the Word, and the Word was with God,and the Word was God.', padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "outputs = model(**inputs)\n",
    "\n",
    "print(outputs.last_hidden_state.shape) # the token embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "fd02c435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to get the full context vector for the sequence\n",
    "context_vectors = outputs.last_hidden_state.mean(dim=1)\n",
    "context_vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01a125e",
   "metadata": {},
   "source": [
    "## Hugging Face Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "2deca252",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid pattern: '**' can only be an entire path component",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[326], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dataset\n\u001b[1;32m----> 3\u001b[0m dataset \u001b[38;5;241m=\u001b[39m load_dataset(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfka/awesome-chatgpt-prompts\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m dataset\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\datasets\\load.py:1773\u001b[0m, in \u001b[0;36mload_dataset\u001b[1;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, use_auth_token, task, streaming, num_proc, storage_options, **config_kwargs)\u001b[0m\n\u001b[0;32m   1768\u001b[0m verification_mode \u001b[38;5;241m=\u001b[39m VerificationMode(\n\u001b[0;32m   1769\u001b[0m     (verification_mode \u001b[38;5;129;01mor\u001b[39;00m VerificationMode\u001b[38;5;241m.\u001b[39mBASIC_CHECKS) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m save_infos \u001b[38;5;28;01melse\u001b[39;00m VerificationMode\u001b[38;5;241m.\u001b[39mALL_CHECKS\n\u001b[0;32m   1770\u001b[0m )\n\u001b[0;32m   1772\u001b[0m \u001b[38;5;66;03m# Create a dataset builder\u001b[39;00m\n\u001b[1;32m-> 1773\u001b[0m builder_instance \u001b[38;5;241m=\u001b[39m load_dataset_builder(\n\u001b[0;32m   1774\u001b[0m     path\u001b[38;5;241m=\u001b[39mpath,\n\u001b[0;32m   1775\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n\u001b[0;32m   1776\u001b[0m     data_dir\u001b[38;5;241m=\u001b[39mdata_dir,\n\u001b[0;32m   1777\u001b[0m     data_files\u001b[38;5;241m=\u001b[39mdata_files,\n\u001b[0;32m   1778\u001b[0m     cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[0;32m   1779\u001b[0m     features\u001b[38;5;241m=\u001b[39mfeatures,\n\u001b[0;32m   1780\u001b[0m     download_config\u001b[38;5;241m=\u001b[39mdownload_config,\n\u001b[0;32m   1781\u001b[0m     download_mode\u001b[38;5;241m=\u001b[39mdownload_mode,\n\u001b[0;32m   1782\u001b[0m     revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[0;32m   1783\u001b[0m     use_auth_token\u001b[38;5;241m=\u001b[39muse_auth_token,\n\u001b[0;32m   1784\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m   1785\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig_kwargs,\n\u001b[0;32m   1786\u001b[0m )\n\u001b[0;32m   1788\u001b[0m \u001b[38;5;66;03m# Return iterable dataset in case of streaming\u001b[39;00m\n\u001b[0;32m   1789\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m streaming:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\datasets\\load.py:1502\u001b[0m, in \u001b[0;36mload_dataset_builder\u001b[1;34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, use_auth_token, storage_options, **config_kwargs)\u001b[0m\n\u001b[0;32m   1500\u001b[0m     download_config \u001b[38;5;241m=\u001b[39m download_config\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m download_config \u001b[38;5;28;01melse\u001b[39;00m DownloadConfig()\n\u001b[0;32m   1501\u001b[0m     download_config\u001b[38;5;241m.\u001b[39muse_auth_token \u001b[38;5;241m=\u001b[39m use_auth_token\n\u001b[1;32m-> 1502\u001b[0m dataset_module \u001b[38;5;241m=\u001b[39m dataset_module_factory(\n\u001b[0;32m   1503\u001b[0m     path,\n\u001b[0;32m   1504\u001b[0m     revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[0;32m   1505\u001b[0m     download_config\u001b[38;5;241m=\u001b[39mdownload_config,\n\u001b[0;32m   1506\u001b[0m     download_mode\u001b[38;5;241m=\u001b[39mdownload_mode,\n\u001b[0;32m   1507\u001b[0m     data_dir\u001b[38;5;241m=\u001b[39mdata_dir,\n\u001b[0;32m   1508\u001b[0m     data_files\u001b[38;5;241m=\u001b[39mdata_files,\n\u001b[0;32m   1509\u001b[0m )\n\u001b[0;32m   1511\u001b[0m \u001b[38;5;66;03m# Get dataset builder class from the processing script\u001b[39;00m\n\u001b[0;32m   1512\u001b[0m builder_cls \u001b[38;5;241m=\u001b[39m import_main_class(dataset_module\u001b[38;5;241m.\u001b[39mmodule_path)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\datasets\\load.py:1219\u001b[0m, in \u001b[0;36mdataset_module_factory\u001b[1;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, **download_kwargs)\u001b[0m\n\u001b[0;32m   1214\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e1, \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m):\n\u001b[0;32m   1215\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[0;32m   1216\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find a dataset script at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrelative_to_absolute_path(combined_path)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or any data file in the same directory. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1217\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m on the Hugging Face Hub either: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(e1)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1218\u001b[0m                 ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1219\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m e1 \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1220\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1221\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[0;32m   1222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find a dataset script at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrelative_to_absolute_path(combined_path)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or any data file in the same directory.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1223\u001b[0m     )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\datasets\\load.py:1203\u001b[0m, in \u001b[0;36mdataset_module_factory\u001b[1;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, **download_kwargs)\u001b[0m\n\u001b[0;32m   1188\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m HubDatasetModuleFactoryWithScript(\n\u001b[0;32m   1189\u001b[0m             path,\n\u001b[0;32m   1190\u001b[0m             revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1193\u001b[0m             dynamic_modules_path\u001b[38;5;241m=\u001b[39mdynamic_modules_path,\n\u001b[0;32m   1194\u001b[0m         )\u001b[38;5;241m.\u001b[39mget_module()\n\u001b[0;32m   1195\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1196\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m HubDatasetModuleFactoryWithoutScript(\n\u001b[0;32m   1197\u001b[0m             path,\n\u001b[0;32m   1198\u001b[0m             revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[0;32m   1199\u001b[0m             data_dir\u001b[38;5;241m=\u001b[39mdata_dir,\n\u001b[0;32m   1200\u001b[0m             data_files\u001b[38;5;241m=\u001b[39mdata_files,\n\u001b[0;32m   1201\u001b[0m             download_config\u001b[38;5;241m=\u001b[39mdownload_config,\n\u001b[0;32m   1202\u001b[0m             download_mode\u001b[38;5;241m=\u001b[39mdownload_mode,\n\u001b[1;32m-> 1203\u001b[0m         )\u001b[38;5;241m.\u001b[39mget_module()\n\u001b[0;32m   1204\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\n\u001b[0;32m   1205\u001b[0m     \u001b[38;5;167;01mException\u001b[39;00m\n\u001b[0;32m   1206\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m e1:  \u001b[38;5;66;03m# noqa: all the attempts failed, before raising the error we should check if the module is already cached.\u001b[39;00m\n\u001b[0;32m   1207\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\datasets\\load.py:769\u001b[0m, in \u001b[0;36mHubDatasetModuleFactoryWithoutScript.get_module\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    759\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_module\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DatasetModule:\n\u001b[0;32m    760\u001b[0m     hfh_dataset_info \u001b[38;5;241m=\u001b[39m HfApi(config\u001b[38;5;241m.\u001b[39mHF_ENDPOINT)\u001b[38;5;241m.\u001b[39mdataset_info(\n\u001b[0;32m    761\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    762\u001b[0m         revision\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrevision,\n\u001b[0;32m    763\u001b[0m         token\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownload_config\u001b[38;5;241m.\u001b[39muse_auth_token,\n\u001b[0;32m    764\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100.0\u001b[39m,\n\u001b[0;32m    765\u001b[0m     )\n\u001b[0;32m    766\u001b[0m     patterns \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    767\u001b[0m         sanitize_patterns(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_files)\n\u001b[0;32m    768\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_files \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 769\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m get_data_patterns_in_dataset_repository(hfh_dataset_info, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_dir)\n\u001b[0;32m    770\u001b[0m     )\n\u001b[0;32m    771\u001b[0m     data_files \u001b[38;5;241m=\u001b[39m DataFilesDict\u001b[38;5;241m.\u001b[39mfrom_hf_repo(\n\u001b[0;32m    772\u001b[0m         patterns,\n\u001b[0;32m    773\u001b[0m         dataset_info\u001b[38;5;241m=\u001b[39mhfh_dataset_info,\n\u001b[0;32m    774\u001b[0m         base_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_dir,\n\u001b[0;32m    775\u001b[0m         allowed_extensions\u001b[38;5;241m=\u001b[39mALL_ALLOWED_EXTENSIONS,\n\u001b[0;32m    776\u001b[0m     )\n\u001b[0;32m    777\u001b[0m     split_modules \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    778\u001b[0m         split: infer_module_for_data_files(data_files_list, use_auth_token\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownload_config\u001b[38;5;241m.\u001b[39muse_auth_token)\n\u001b[0;32m    779\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m split, data_files_list \u001b[38;5;129;01min\u001b[39;00m data_files\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    780\u001b[0m     }\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\datasets\\data_files.py:662\u001b[0m, in \u001b[0;36mget_data_patterns_in_dataset_repository\u001b[1;34m(dataset_info, base_path)\u001b[0m\n\u001b[0;32m    660\u001b[0m resolver \u001b[38;5;241m=\u001b[39m partial(_resolve_single_pattern_in_dataset_repository, dataset_info, base_path\u001b[38;5;241m=\u001b[39mbase_path)\n\u001b[0;32m    661\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 662\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _get_data_files_patterns(resolver)\n\u001b[0;32m    663\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n\u001b[0;32m    664\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m EmptyDatasetError(\n\u001b[0;32m    665\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe dataset repository at \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_info\u001b[38;5;241m.\u001b[39mid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt contain any data files\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    666\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\datasets\\data_files.py:223\u001b[0m, in \u001b[0;36m_get_data_files_patterns\u001b[1;34m(pattern_resolver)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m pattern \u001b[38;5;129;01min\u001b[39;00m patterns:\n\u001b[1;32m--> 223\u001b[0m         data_files \u001b[38;5;241m=\u001b[39m pattern_resolver(pattern)\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data_files) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    225\u001b[0m             non_empty_splits\u001b[38;5;241m.\u001b[39mappend(split)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\datasets\\data_files.py:473\u001b[0m, in \u001b[0;36m_resolve_single_pattern_in_dataset_repository\u001b[1;34m(dataset_info, pattern, base_path, allowed_extensions)\u001b[0m\n\u001b[0;32m    471\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    472\u001b[0m     base_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 473\u001b[0m glob_iter \u001b[38;5;241m=\u001b[39m [PurePath(filepath) \u001b[38;5;28;01mfor\u001b[39;00m filepath \u001b[38;5;129;01min\u001b[39;00m fs\u001b[38;5;241m.\u001b[39mglob(PurePath(pattern)\u001b[38;5;241m.\u001b[39mas_posix()) \u001b[38;5;28;01mif\u001b[39;00m fs\u001b[38;5;241m.\u001b[39misfile(filepath)]\n\u001b[0;32m    474\u001b[0m matched_paths \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    475\u001b[0m     filepath\n\u001b[0;32m    476\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m filepath \u001b[38;5;129;01min\u001b[39;00m glob_iter\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    483\u001b[0m     )\n\u001b[0;32m    484\u001b[0m ]  \u001b[38;5;66;03m# ignore .ipynb and __pycache__, but keep /../\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m allowed_extensions \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\fsspec\\spec.py:613\u001b[0m, in \u001b[0;36mAbstractFileSystem.glob\u001b[1;34m(self, path, maxdepth, **kwargs)\u001b[0m\n\u001b[0;32m    609\u001b[0m         depth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    611\u001b[0m allpaths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfind(root, maxdepth\u001b[38;5;241m=\u001b[39mdepth, withdirs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, detail\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 613\u001b[0m pattern \u001b[38;5;241m=\u001b[39m glob_translate(path \u001b[38;5;241m+\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ends_with_sep \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m    614\u001b[0m pattern \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mcompile(pattern)\n\u001b[0;32m    616\u001b[0m out \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    617\u001b[0m     p: info\n\u001b[0;32m    618\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m p, info \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(allpaths\u001b[38;5;241m.\u001b[39mitems())\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    625\u001b[0m     )\n\u001b[0;32m    626\u001b[0m }\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\fsspec\\utils.py:729\u001b[0m, in \u001b[0;36mglob_translate\u001b[1;34m(pat)\u001b[0m\n\u001b[0;32m    727\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m**\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m part:\n\u001b[1;32m--> 729\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    730\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid pattern: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m**\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m can only be an entire path component\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    731\u001b[0m     )\n\u001b[0;32m    732\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m part:\n\u001b[0;32m    733\u001b[0m     results\u001b[38;5;241m.\u001b[39mextend(_translate(part, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_sep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m, not_sep))\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid pattern: '**' can only be an entire path component"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"fka/awesome-chatgpt-prompts\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "3f9acdb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset samsum (file://C:/Users/jimmy/.cache/huggingface/datasets/samsum/samsum/0.0.0/f1d7c6b7353e6de335d444e424dc002ef70d1277109031327bc9cc6af5d3d46e)\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Loading a dataset cached in a LocalFileSystem is not supported.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[327], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dataset \u001b[38;5;241m=\u001b[39m load_dataset(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msamsum\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m dataset\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\datasets\\load.py:1810\u001b[0m, in \u001b[0;36mload_dataset\u001b[1;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, use_auth_token, task, streaming, num_proc, storage_options, **config_kwargs)\u001b[0m\n\u001b[0;32m   1806\u001b[0m \u001b[38;5;66;03m# Build dataset for splits\u001b[39;00m\n\u001b[0;32m   1807\u001b[0m keep_in_memory \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1808\u001b[0m     keep_in_memory \u001b[38;5;28;01mif\u001b[39;00m keep_in_memory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m is_small_dataset(builder_instance\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mdataset_size)\n\u001b[0;32m   1809\u001b[0m )\n\u001b[1;32m-> 1810\u001b[0m ds \u001b[38;5;241m=\u001b[39m builder_instance\u001b[38;5;241m.\u001b[39mas_dataset(split\u001b[38;5;241m=\u001b[39msplit, verification_mode\u001b[38;5;241m=\u001b[39mverification_mode, in_memory\u001b[38;5;241m=\u001b[39mkeep_in_memory)\n\u001b[0;32m   1811\u001b[0m \u001b[38;5;66;03m# Rename and cast features to match task schema\u001b[39;00m\n\u001b[0;32m   1812\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\datasets\\builder.py:1107\u001b[0m, in \u001b[0;36mDatasetBuilder.as_dataset\u001b[1;34m(self, split, run_post_process, verification_mode, ignore_verifications, in_memory)\u001b[0m\n\u001b[0;32m   1105\u001b[0m is_local \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m is_remote_filesystem(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fs)\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_local:\n\u001b[1;32m-> 1107\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading a dataset cached in a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fs)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_dir):\n\u001b[0;32m   1109\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[0;32m   1110\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: could not find data in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Please make sure to call \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1111\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbuilder.download_and_prepare(), or use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1112\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatasets.load_dataset() before trying to access the Dataset object.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1113\u001b[0m     )\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: Loading a dataset cached in a LocalFileSystem is not supported."
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"samsum\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1b1909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload GPT Prompt dataset (Cache keeps from loading it twice)\n",
    "dataset = load_dataset(\"fka/awesome-chatgpt-prompts\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a0ee14",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f85adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle & sample\n",
    "\n",
    "dataset = dataset['train'].shuffle(seed=37).select(range(100))\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3007d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Test Dataset\n",
    "\n",
    "dataset = dataset.train_test_split(train_size=0.8, seed=42)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fb87c6",
   "metadata": {},
   "source": [
    "## Creating and uploading custom dataset into Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4eefa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the sgm files are what contains the articles\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Open the file and parse its content with BeautifulSoup\n",
    "reuters_articles = []\n",
    "for i in range(22):\n",
    "  if i < 10:\n",
    "    i = f\"0{i}\"\n",
    "\n",
    "  # load file data\n",
    "  with open(f\"reuters21578/reut2-0{i}.sgm\", 'r', encoding='latin-1') as file:\n",
    "      soup = BeautifulSoup(file, \"html.parser\")\n",
    "\n",
    "  # Extract articles' titles and bodies\n",
    "  articles = []\n",
    "  for reuters in soup.find_all('reuters'):\n",
    "      title = reuters.title.string if reuters.title else \"\"\n",
    "      body = reuters.body.string if reuters.body else \"\"\n",
    "      articles.append({\n",
    "            'title': title,\n",
    "            'body': body\n",
    "        })\n",
    "\n",
    "  reuters_articles.extend(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d99688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the first few articles for inspection\n",
    "for i, article in enumerate(reuters_articles[:5]):\n",
    "  print(article)\n",
    "  print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "ae2db63c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reuters_articles' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[328], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mlen\u001b[39m(reuters_articles)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'reuters_articles' is not defined"
     ]
    }
   ],
   "source": [
    "len(reuters_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "e8f20185",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reuters_articles' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[329], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m TRAIN_PCT, VALID_PCT \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.8\u001b[39m, \u001b[38;5;241m0.1\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Split the data\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m train_articles \u001b[38;5;241m=\u001b[39m reuters_articles[:\u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(reuters_articles)\u001b[38;5;241m*\u001b[39mTRAIN_PCT)]\n\u001b[0;32m      7\u001b[0m valid_articles \u001b[38;5;241m=\u001b[39m reuters_articles[\u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(reuters_articles)\u001b[38;5;241m*\u001b[39mTRAIN_PCT): \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(reuters_articles)\u001b[38;5;241m*\u001b[39m(TRAIN_PCT \u001b[38;5;241m+\u001b[39m VALID_PCT))]\n\u001b[0;32m      8\u001b[0m test_articles \u001b[38;5;241m=\u001b[39m reuters_articles[\u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(reuters_articles)\u001b[38;5;241m*\u001b[39m(TRAIN_PCT \u001b[38;5;241m+\u001b[39m VALID_PCT)):]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'reuters_articles' is not defined"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "TRAIN_PCT, VALID_PCT = 0.8, 0.1\n",
    "\n",
    "# Split the data\n",
    "train_articles = reuters_articles[:int(len(reuters_articles)*TRAIN_PCT)]\n",
    "valid_articles = reuters_articles[int(len(reuters_articles)*TRAIN_PCT): int(len(reuters_articles)*(TRAIN_PCT + VALID_PCT))]\n",
    "test_articles = reuters_articles[int(len(reuters_articles)*(TRAIN_PCT + VALID_PCT)):]\n",
    "\n",
    "# Function to save articles as JSONL\n",
    "def save_as_jsonl(data, filename):\n",
    "    with open(filename, \"w\") as f:\n",
    "        for article in data:\n",
    "            f.write(json.dumps(article) + \"\\n\")\n",
    "\n",
    "# Save them into temporary JSONL files\n",
    "save_as_jsonl(train_articles, \"train.jsonl\")\n",
    "save_as_jsonl(valid_articles, \"valid.jsonl\")\n",
    "save_as_jsonl(test_articles, \"test.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "0d1dde8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (file://C:/Users/jimmy/.cache/huggingface/datasets/json/default-647d8507dbef3ff8/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Loading a dataset cached in a LocalFileSystem is not supported.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[330], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load them as datasets\u001b[39;00m\n\u001b[0;32m      2\u001b[0m data_files \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain.jsonl\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalid.jsonl\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest.jsonl\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m----> 3\u001b[0m dataset \u001b[38;5;241m=\u001b[39m load_dataset(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjson\u001b[39m\u001b[38;5;124m\"\u001b[39m, data_files\u001b[38;5;241m=\u001b[39mdata_files)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\datasets\\load.py:1810\u001b[0m, in \u001b[0;36mload_dataset\u001b[1;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, use_auth_token, task, streaming, num_proc, storage_options, **config_kwargs)\u001b[0m\n\u001b[0;32m   1806\u001b[0m \u001b[38;5;66;03m# Build dataset for splits\u001b[39;00m\n\u001b[0;32m   1807\u001b[0m keep_in_memory \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1808\u001b[0m     keep_in_memory \u001b[38;5;28;01mif\u001b[39;00m keep_in_memory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m is_small_dataset(builder_instance\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mdataset_size)\n\u001b[0;32m   1809\u001b[0m )\n\u001b[1;32m-> 1810\u001b[0m ds \u001b[38;5;241m=\u001b[39m builder_instance\u001b[38;5;241m.\u001b[39mas_dataset(split\u001b[38;5;241m=\u001b[39msplit, verification_mode\u001b[38;5;241m=\u001b[39mverification_mode, in_memory\u001b[38;5;241m=\u001b[39mkeep_in_memory)\n\u001b[0;32m   1811\u001b[0m \u001b[38;5;66;03m# Rename and cast features to match task schema\u001b[39;00m\n\u001b[0;32m   1812\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\datasets\\builder.py:1107\u001b[0m, in \u001b[0;36mDatasetBuilder.as_dataset\u001b[1;34m(self, split, run_post_process, verification_mode, ignore_verifications, in_memory)\u001b[0m\n\u001b[0;32m   1105\u001b[0m is_local \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m is_remote_filesystem(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fs)\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_local:\n\u001b[1;32m-> 1107\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading a dataset cached in a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fs)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_dir):\n\u001b[0;32m   1109\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[0;32m   1110\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: could not find data in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Please make sure to call \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1111\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbuilder.download_and_prepare(), or use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1112\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatasets.load_dataset() before trying to access the Dataset object.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1113\u001b[0m     )\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: Loading a dataset cached in a LocalFileSystem is not supported."
     ]
    }
   ],
   "source": [
    "# Load them as datasets\n",
    "data_files = {\"train\": \"train.jsonl\", \"validation\": \"valid.jsonl\", \"test\": \"test.jsonl\"}\n",
    "dataset = load_dataset(\"json\", data_files=data_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ac7c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "65c5ef09",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[331], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "c0e13184",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "b25e98b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45dc6b9a50e34ac7ba5e42a6667b1a0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "09b0b224",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[334], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dataset\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "e8cf9092",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[335], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dataset\u001b[38;5;241m.\u001b[39mpush_to_hub(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_dataset1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "dataset.push_to_hub(\"test_dataset1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a2a8a4",
   "metadata": {},
   "source": [
    "## Downloading custom dataset from Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "c8f5a9f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (file://C:/Users/jimmy/.cache/huggingface/datasets/jimmypjoy___parquet/jimmypjoy--test_dataset1-4cb77d05776b4811/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Loading a dataset cached in a LocalFileSystem is not supported.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[336], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dataset \u001b[38;5;241m=\u001b[39m load_dataset(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjimmypjoy/test_dataset1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\datasets\\load.py:1810\u001b[0m, in \u001b[0;36mload_dataset\u001b[1;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, use_auth_token, task, streaming, num_proc, storage_options, **config_kwargs)\u001b[0m\n\u001b[0;32m   1806\u001b[0m \u001b[38;5;66;03m# Build dataset for splits\u001b[39;00m\n\u001b[0;32m   1807\u001b[0m keep_in_memory \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1808\u001b[0m     keep_in_memory \u001b[38;5;28;01mif\u001b[39;00m keep_in_memory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m is_small_dataset(builder_instance\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mdataset_size)\n\u001b[0;32m   1809\u001b[0m )\n\u001b[1;32m-> 1810\u001b[0m ds \u001b[38;5;241m=\u001b[39m builder_instance\u001b[38;5;241m.\u001b[39mas_dataset(split\u001b[38;5;241m=\u001b[39msplit, verification_mode\u001b[38;5;241m=\u001b[39mverification_mode, in_memory\u001b[38;5;241m=\u001b[39mkeep_in_memory)\n\u001b[0;32m   1811\u001b[0m \u001b[38;5;66;03m# Rename and cast features to match task schema\u001b[39;00m\n\u001b[0;32m   1812\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\datasets\\builder.py:1107\u001b[0m, in \u001b[0;36mDatasetBuilder.as_dataset\u001b[1;34m(self, split, run_post_process, verification_mode, ignore_verifications, in_memory)\u001b[0m\n\u001b[0;32m   1105\u001b[0m is_local \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m is_remote_filesystem(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fs)\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_local:\n\u001b[1;32m-> 1107\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading a dataset cached in a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fs)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_dir):\n\u001b[0;32m   1109\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[0;32m   1110\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: could not find data in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Please make sure to call \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1111\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbuilder.download_and_prepare(), or use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1112\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatasets.load_dataset() before trying to access the Dataset object.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1113\u001b[0m     )\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: Loading a dataset cached in a LocalFileSystem is not supported."
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"jimmypjoy/test_dataset1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c18b5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d633ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column to this dataset\n",
    "def create_full_article_col(example):\n",
    "\n",
    "  return {'full_article': f\"TITLE:{example['title']}\\n\\nBODY:{example['body']}\"}\n",
    "\n",
    "dataset = dataset.map(create_full_article_col)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf21c65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['train'][0]['full_article']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61a658c",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60a7359",
   "metadata": {},
   "source": [
    "## Creating custom Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "df856040",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[337], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Create a batched dataset for training, creates an iterator object for later usage when training tokenizer\u001b[39;00m\n\u001b[0;32m      3\u001b[0m training_corpus \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m      4\u001b[0m     dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m][i : i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1000\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfull_article\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m----> 5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m]), \u001b[38;5;241m1000\u001b[39m)\n\u001b[0;32m      6\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "# Create a batched dataset for training, creates an iterator object for later usage when training tokenizer\n",
    "\n",
    "training_corpus = (\n",
    "    dataset[\"train\"][i : i + 1000][\"full_article\"]\n",
    "    for i in range(0, len(dataset[\"train\"]), 1000)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "8aab91e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_tokenizer = AutoTokenizer.from_pretrained(\"gpt2\") # train gpt2 tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "9fd7ab90",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_corpus' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[339], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m old_tokenizer\u001b[38;5;241m.\u001b[39mtrain_new_from_iterator(training_corpus, \u001b[38;5;241m52000\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'training_corpus' is not defined"
     ]
    }
   ],
   "source": [
    "tokenizer = old_tokenizer.train_new_from_iterator(training_corpus, 52000) # vocab size of 52000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "48968af4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[340], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m example \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m2\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfull_article\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      2\u001b[0m example\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "example = dataset['test'][2]['full_article']\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "c6047dc2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'example' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[341], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m old_tokenizer\u001b[38;5;241m.\u001b[39mtokenize(example)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'example' is not defined"
     ]
    }
   ],
   "source": [
    "old_tokenizer.tokenize(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "57f08161",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'example' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[342], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39mtokenize(example)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'example' is not defined"
     ]
    }
   ],
   "source": [
    "tokenizer.tokenize(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "bc6bd0ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "951149df570f4966b35a7317dd06da4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "e1195401",
   "metadata": {},
   "outputs": [
    {
     "ename": "HfHubHTTPError",
     "evalue": " (Request ID: Root=1-670d445d-7455dce17fdf51ec43b4cbbc;85b6c4c2-107a-45a3-8f63-7603118308da)\n\n403 Forbidden: You don't have the rights to create a model under the namespace \"jimmypjoy\".\nCannot access content at: https://huggingface.co/api/repos/create.\nIf you are trying to create or update content, make sure you have a token with the `write` role.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\utils\\_errors.py:304\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[1;34m(response, endpoint_name)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 304\u001b[0m     response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\requests\\models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1020\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[1;32m-> 1021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[1;31mHTTPError\u001b[0m: 403 Client Error: Forbidden for url: https://huggingface.co/api/repos/create",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mHfHubHTTPError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[344], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39mpush_to_hub(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt2-reuters-tokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\utils\\hub.py:803\u001b[0m, in \u001b[0;36mPushToHubMixin.push_to_hub\u001b[1;34m(self, repo_id, use_temp_dir, commit_message, private, use_auth_token, max_shard_size, create_pr, safe_serialization, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    800\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    801\u001b[0m     working_dir \u001b[38;5;241m=\u001b[39m repo_id\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m--> 803\u001b[0m repo_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_repo(\n\u001b[0;32m    804\u001b[0m     repo_id, private\u001b[38;5;241m=\u001b[39mprivate, use_auth_token\u001b[38;5;241m=\u001b[39muse_auth_token, repo_url\u001b[38;5;241m=\u001b[39mrepo_url, organization\u001b[38;5;241m=\u001b[39morganization\n\u001b[0;32m    805\u001b[0m )\n\u001b[0;32m    807\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_temp_dir \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    808\u001b[0m     use_temp_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(working_dir)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\utils\\hub.py:661\u001b[0m, in \u001b[0;36mPushToHubMixin._create_repo\u001b[1;34m(self, repo_id, private, use_auth_token, repo_url, organization)\u001b[0m\n\u001b[0;32m    658\u001b[0m             repo_id \u001b[38;5;241m=\u001b[39m repo_id\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    659\u001b[0m         repo_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00morganization\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 661\u001b[0m url \u001b[38;5;241m=\u001b[39m create_repo(repo_id\u001b[38;5;241m=\u001b[39mrepo_id, token\u001b[38;5;241m=\u001b[39muse_auth_token, private\u001b[38;5;241m=\u001b[39mprivate, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    663\u001b[0m \u001b[38;5;66;03m# If the namespace is not there, add it or `upload_file` will complain\u001b[39;00m\n\u001b[0;32m    664\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m repo_id \u001b[38;5;129;01mand\u001b[39;00m url \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mHUGGINGFACE_CO_RESOLVE_ENDPOINT\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[0;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\hf_api.py:3376\u001b[0m, in \u001b[0;36mHfApi.create_repo\u001b[1;34m(self, repo_id, token, private, repo_type, exist_ok, resource_group_id, space_sdk, space_hardware, space_storage, space_sleep_time, space_secrets, space_variables)\u001b[0m\n\u001b[0;32m   3374\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m RepoUrl(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendpoint\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   3375\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m HfHubHTTPError:\n\u001b[1;32m-> 3376\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m   3377\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3378\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\hf_api.py:3363\u001b[0m, in \u001b[0;36mHfApi.create_repo\u001b[1;34m(self, repo_id, token, private, repo_type, exist_ok, resource_group_id, space_sdk, space_hardware, space_storage, space_sleep_time, space_secrets, space_variables)\u001b[0m\n\u001b[0;32m   3360\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   3362\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3363\u001b[0m     hf_raise_for_status(r)\n\u001b[0;32m   3364\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m   3365\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exist_ok \u001b[38;5;129;01mand\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m409\u001b[39m:\n\u001b[0;32m   3366\u001b[0m         \u001b[38;5;66;03m# Repo already exists and `exist_ok=True`\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\utils\\_errors.py:367\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[1;34m(response, endpoint_name)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m403\u001b[39m:\n\u001b[0;32m    361\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    362\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Forbidden: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_message\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    363\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCannot access content at: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    364\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mIf you are trying to create or update content, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    365\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmake sure you have a token with the `write` role.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    366\u001b[0m     )\n\u001b[1;32m--> 367\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HfHubHTTPError(message, response\u001b[38;5;241m=\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;66;03m# Convert `HTTPError` into a `HfHubHTTPError` to display request information\u001b[39;00m\n\u001b[0;32m    370\u001b[0m \u001b[38;5;66;03m# as well (request id and/or server error message)\u001b[39;00m\n\u001b[0;32m    371\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m HfHubHTTPError(\u001b[38;5;28mstr\u001b[39m(e), response\u001b[38;5;241m=\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mHfHubHTTPError\u001b[0m:  (Request ID: Root=1-670d445d-7455dce17fdf51ec43b4cbbc;85b6c4c2-107a-45a3-8f63-7603118308da)\n\n403 Forbidden: You don't have the rights to create a model under the namespace \"jimmypjoy\".\nCannot access content at: https://huggingface.co/api/repos/create.\nIf you are trying to create or update content, make sure you have a token with the `write` role."
     ]
    }
   ],
   "source": [
    "tokenizer.push_to_hub(\"gpt2-reuters-tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66125962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use newly created tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"jimmypjoy/gpt2-reuters-tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "880382b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[345], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m example \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m      2\u001b[0m example\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "example = dataset['test'][2]\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "af590292",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'example' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[346], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39mtokenize(example[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfull_article\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'example' is not defined"
     ]
    }
   ],
   "source": [
    "tokenizer.tokenize(example['full_article'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a37be4c",
   "metadata": {},
   "source": [
    "## Training gpt2 from scratch in Hugging Face "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "648a4fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (file://C:/Users/jimmy/.cache/huggingface/datasets/jimmypjoy___parquet/jimmypjoy--test_dataset1-4cb77d05776b4811/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Loading a dataset cached in a LocalFileSystem is not supported.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[347], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dataset \u001b[38;5;241m=\u001b[39m load_dataset(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjimmypjoy/test_dataset1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m dataset\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\datasets\\load.py:1810\u001b[0m, in \u001b[0;36mload_dataset\u001b[1;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, use_auth_token, task, streaming, num_proc, storage_options, **config_kwargs)\u001b[0m\n\u001b[0;32m   1806\u001b[0m \u001b[38;5;66;03m# Build dataset for splits\u001b[39;00m\n\u001b[0;32m   1807\u001b[0m keep_in_memory \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1808\u001b[0m     keep_in_memory \u001b[38;5;28;01mif\u001b[39;00m keep_in_memory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m is_small_dataset(builder_instance\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mdataset_size)\n\u001b[0;32m   1809\u001b[0m )\n\u001b[1;32m-> 1810\u001b[0m ds \u001b[38;5;241m=\u001b[39m builder_instance\u001b[38;5;241m.\u001b[39mas_dataset(split\u001b[38;5;241m=\u001b[39msplit, verification_mode\u001b[38;5;241m=\u001b[39mverification_mode, in_memory\u001b[38;5;241m=\u001b[39mkeep_in_memory)\n\u001b[0;32m   1811\u001b[0m \u001b[38;5;66;03m# Rename and cast features to match task schema\u001b[39;00m\n\u001b[0;32m   1812\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\datasets\\builder.py:1107\u001b[0m, in \u001b[0;36mDatasetBuilder.as_dataset\u001b[1;34m(self, split, run_post_process, verification_mode, ignore_verifications, in_memory)\u001b[0m\n\u001b[0;32m   1105\u001b[0m is_local \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m is_remote_filesystem(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fs)\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_local:\n\u001b[1;32m-> 1107\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading a dataset cached in a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fs)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_dir):\n\u001b[0;32m   1109\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[0;32m   1110\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: could not find data in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Please make sure to call \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1111\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbuilder.download_and_prepare(), or use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1112\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatasets.load_dataset() before trying to access the Dataset object.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1113\u001b[0m     )\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: Loading a dataset cached in a LocalFileSystem is not supported."
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"jimmypjoy/test_dataset1\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac7a1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_full_article_col(example):\n",
    "\n",
    "  return {'full_article': f\"TITLE:{example['title']}\\n\\nBODY:{example['body']}\"}\n",
    "\n",
    "dataset = dataset.map(create_full_article_col)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff69a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['train'][0]['full_article']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a02261d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"jimmypjoy/gpt2-reuters-tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64bee0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTEXT_LENGTH = 512\n",
    "\n",
    "def tokenize(element):\n",
    "    outputs = tokenizer(\n",
    "        element[\"full_article\"],\n",
    "        truncation=True,\n",
    "        max_length=CONTEXT_LENGTH,\n",
    "        return_overflowing_tokens=False\n",
    "    )\n",
    "\n",
    "    return outputs\n",
    "\n",
    "\n",
    "tokenized_datasets = dataset.map(\n",
    "    tokenize, batched=True, remove_columns=dataset[\"train\"].column_names\n",
    ")\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "2b754ad0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CONTEXT_LENGTH' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[348], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer, GPT2LMHeadModel, AutoConfig\n\u001b[0;32m      3\u001b[0m config \u001b[38;5;241m=\u001b[39m AutoConfig\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt2\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      5\u001b[0m     vocab_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(tokenizer),\n\u001b[1;32m----> 6\u001b[0m     n_ctx\u001b[38;5;241m=\u001b[39mCONTEXT_LENGTH,\n\u001b[0;32m      7\u001b[0m     bos_token_id\u001b[38;5;241m=\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mbos_token_id,\n\u001b[0;32m      8\u001b[0m     eos_token_id\u001b[38;5;241m=\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39meos_token_id,\n\u001b[0;32m      9\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'CONTEXT_LENGTH' is not defined"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, GPT2LMHeadModel, AutoConfig\n",
    "\n",
    "config = AutoConfig.from_pretrained(\n",
    "    \"gpt2\",\n",
    "    vocab_size=len(tokenizer),\n",
    "    n_ctx=CONTEXT_LENGTH,\n",
    "    bos_token_id=tokenizer.bos_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "4e4c875e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2Config {\n",
       "  \"activation_function\": \"gelu_new\",\n",
       "  \"attn_pdrop\": 0.1,\n",
       "  \"bos_token_id\": 50256,\n",
       "  \"embd_pdrop\": 0.1,\n",
       "  \"eos_token_id\": 50256,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"layer_norm_epsilon\": 1e-05,\n",
       "  \"model_type\": \"gpt2\",\n",
       "  \"n_embd\": 768,\n",
       "  \"n_head\": 12,\n",
       "  \"n_inner\": null,\n",
       "  \"n_layer\": 12,\n",
       "  \"n_positions\": 1024,\n",
       "  \"reorder_and_upcast_attn\": false,\n",
       "  \"resid_pdrop\": 0.1,\n",
       "  \"scale_attn_by_inverse_layer_idx\": false,\n",
       "  \"scale_attn_weights\": true,\n",
       "  \"summary_activation\": null,\n",
       "  \"summary_first_dropout\": 0.1,\n",
       "  \"summary_proj_to_labels\": true,\n",
       "  \"summary_type\": \"cls_index\",\n",
       "  \"summary_use_proj\": true,\n",
       "  \"transformers_version\": \"4.31.0\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 50257\n",
       "}"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "c642b77a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-2 size: 124.4M parameters\n"
     ]
    }
   ],
   "source": [
    "model = GPT2LMHeadModel(config)\n",
    "model_size = sum(t.numel() for t in model.parameters())\n",
    "print(f\"GPT-2 size: {model_size/1000**2:.1f}M parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "25e3a17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "accdca75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e24ff12d56fc41aaaa4b54d7713a515c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "e70c0b84",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "FP16 Mixed precision training with AMP or APEX (`--fp16`) and FP16 half precision evaluation (`--fp16_full_eval`) can only be used on CUDA devices.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[353], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Trainer, TrainingArguments\n\u001b[1;32m----> 3\u001b[0m training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[0;32m      4\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./reuters-gpt2-text-gen\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# local directory\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     hub_model_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mingeniumacademy/reuters-gpt2-text-gen\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# identifier on the Hub\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     evaluation_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      7\u001b[0m     auto_find_batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m      8\u001b[0m     num_train_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m      9\u001b[0m     gradient_accumulation_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m,\n\u001b[0;32m     10\u001b[0m     weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m,\n\u001b[0;32m     11\u001b[0m     lr_scheduler_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcosine\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     12\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5e-4\u001b[39m,\n\u001b[0;32m     13\u001b[0m     fp16\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     14\u001b[0m     push_to_hub\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     15\u001b[0m     logging_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m\n\u001b[0;32m     16\u001b[0m )\n\u001b[0;32m     18\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m     19\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m     20\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mtokenizer,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     24\u001b[0m     eval_dataset\u001b[38;5;241m=\u001b[39mtokenized_datasets[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     25\u001b[0m )\n",
      "File \u001b[1;32m<string>:112\u001b[0m, in \u001b[0;36m__init__\u001b[1;34m(self, output_dir, overwrite_output_dir, do_train, do_eval, do_predict, evaluation_strategy, prediction_loss_only, per_device_train_batch_size, per_device_eval_batch_size, per_gpu_train_batch_size, per_gpu_eval_batch_size, gradient_accumulation_steps, eval_accumulation_steps, eval_delay, learning_rate, weight_decay, adam_beta1, adam_beta2, adam_epsilon, max_grad_norm, num_train_epochs, max_steps, lr_scheduler_type, warmup_ratio, warmup_steps, log_level, log_level_replica, log_on_each_node, logging_dir, logging_strategy, logging_first_step, logging_steps, logging_nan_inf_filter, save_strategy, save_steps, save_total_limit, save_safetensors, save_on_each_node, no_cuda, use_mps_device, seed, data_seed, jit_mode_eval, use_ipex, bf16, fp16, fp16_opt_level, half_precision_backend, bf16_full_eval, fp16_full_eval, tf32, local_rank, ddp_backend, tpu_num_cores, tpu_metrics_debug, debug, dataloader_drop_last, eval_steps, dataloader_num_workers, past_index, run_name, disable_tqdm, remove_unused_columns, label_names, load_best_model_at_end, metric_for_best_model, greater_is_better, ignore_data_skip, sharded_ddp, fsdp, fsdp_min_num_params, fsdp_config, fsdp_transformer_layer_cls_to_wrap, deepspeed, label_smoothing_factor, optim, optim_args, adafactor, group_by_length, length_column_name, report_to, ddp_find_unused_parameters, ddp_bucket_cap_mb, ddp_broadcast_buffers, dataloader_pin_memory, skip_memory_metrics, use_legacy_prediction_loop, push_to_hub, resume_from_checkpoint, hub_model_id, hub_strategy, hub_token, hub_private_repo, gradient_checkpointing, include_inputs_for_metrics, fp16_backend, push_to_hub_model_id, push_to_hub_organization, push_to_hub_token, mp_parameters, auto_find_batch_size, full_determinism, torchdynamo, ray_scope, ddp_timeout, torch_compile, torch_compile_backend, torch_compile_mode, xpu_backend)\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\training_args.py:1376\u001b[0m, in \u001b[0;36mTrainingArguments.__post_init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1367\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--optim adamw_torch_fused with --fp16 requires PyTorch>2.0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   1370\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1371\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m is_torch_available()\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1374\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp16 \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp16_full_eval)\n\u001b[0;32m   1375\u001b[0m ):\n\u001b[1;32m-> 1376\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1377\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFP16 Mixed precision training with AMP or APEX (`--fp16`) and FP16 half precision evaluation\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1378\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (`--fp16_full_eval`) can only be used on CUDA devices.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1379\u001b[0m     )\n\u001b[0;32m   1381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   1382\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1383\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m is_torch_available()\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1388\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbf16 \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbf16_full_eval)\n\u001b[0;32m   1389\u001b[0m ):\n\u001b[0;32m   1390\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1391\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBF16 Mixed precision training with AMP (`--bf16`) and BF16 half precision evaluation\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1392\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (`--bf16_full_eval`) can only be used on CUDA or CPU/TPU/NeuronCore devices.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1393\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: FP16 Mixed precision training with AMP or APEX (`--fp16`) and FP16 half precision evaluation (`--fp16_full_eval`) can only be used on CUDA devices."
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./reuters-gpt2-text-gen\",  # local directory\n",
    "    hub_model_id=\"ingeniumacademy/reuters-gpt2-text-gen\",  # identifier on the Hub\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    auto_find_batch_size=True,\n",
    "    num_train_epochs=2,\n",
    "    gradient_accumulation_steps=8,\n",
    "    weight_decay=0.1,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    learning_rate=5e-4,\n",
    "    fp16=True,\n",
    "    push_to_hub=True,\n",
    "    logging_steps=10\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884462a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f98a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "3c9886cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Our Model In Pipeline\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "#pipe = pipeline(\n",
    "#    \"text-generation\", model=\"jimmypjoy/reuters-gpt2-text-gen\"\n",
    "#)\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\", model=\"ingeniumacademy/reuters-gpt2-text-gen\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "1d087dba",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[355], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m sample \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m      2\u001b[0m sample\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "sample = dataset['test'][2]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f3944d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"TITLE:{sample['title']}\\n\\nBODY:\"\n",
    "pipe(prompt, max_new_tokens=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6b0801",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"TITLE:{sample['title']}\"\n",
    "pipe(prompt, max_new_tokens=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5255d3e9",
   "metadata": {},
   "source": [
    "# Langsmith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a2db360",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = \"https://api.smith.langchain.com\"\n",
    "#os.environ['LANGCHAIN_PROJECT'] = \"pr-drab-gift-52\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6c793ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 11, 'total_tokens': 20, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-3997f614-2b6a-4812-86a3-2f090fb35de8-0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatOpenAI()\n",
    "llm.invoke(\"Hello, world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c3caf59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Thank you for asking! I'm just a computer program so I don't have feelings like humans do, but I'm here and ready to assist you with anything you need. How can I help you today?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 42, 'prompt_tokens': 12, 'total_tokens': 54, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-b17f29f2-b440-450f-a46a-60851a644f7a-0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"How is your day?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1131140c",
   "metadata": {},
   "source": [
    "# LangChain Expression Language- LCEL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3774854f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Define classification and answer templates\n",
    "classification_prompt = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"Classify this question as 'simple' or 'complex': {question}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e939ac78",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_answer_prompt = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"Answer this simple question: {question}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87f70fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "clarification_prompt = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"Ask a clarifying question for this complex question: {question}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb296c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jimmy\\AppData\\Local\\Temp\\ipykernel_199184\\402048707.py:2: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  classify_chain = LLMChain(llm=llm, prompt=classification_prompt)\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Define chains\n",
    "classify_chain = LLMChain(llm=llm, prompt=classification_prompt)\n",
    "simple_answer_chain = LLMChain(llm=llm, prompt=simple_answer_prompt)\n",
    "clarification_chain = LLMChain(llm=llm, prompt=clarification_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "20c601f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Workflow to decide based on classification\n",
    "def question_answering_pipeline(question):\n",
    "    classification_result = classify_chain.run({\"question\": question}).strip().lower()\n",
    "    \n",
    "    print(\"Question: \"+ question +\"     Classified as: \"+ classification_result )\n",
    "\n",
    "    if classification_result == \"simple\":\n",
    "        answer = simple_answer_chain.run({\"question\": question})\n",
    "        print(f\"Answer: {answer}\")\n",
    "    else:\n",
    "        clarification = clarification_chain.run({\"question\": question})\n",
    "        print(f\"Clarification: {clarification}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "766c3ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the capital of France?     Classified as: simple\n",
      "Answer: Paris\n"
     ]
    }
   ],
   "source": [
    "question_answering_pipeline(\"What is the capital of France?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e714bac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Explain the implications of quantum computing.     Classified as: complex\n",
      "Clarification: What specific areas or industries do you want to focus on when discussing the implications of quantum computing?\n"
     ]
    }
   ],
   "source": [
    "question_answering_pipeline(\"Explain the implications of quantum computing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeddcf90",
   "metadata": {},
   "source": [
    "# Delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae7ef7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
