{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To enable plotting graphs in Jupyter notebook\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical libraries\n",
    "import numpy as np   \n",
    "\n",
    "# Import Linear Regression machine learning library\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# to handle data in form of rows and columns \n",
    "import pandas as pd    \n",
    "\n",
    "# importing ploting libraries\n",
    "import matplotlib.pyplot as plt   \n",
    "import matplotlib.style\n",
    "plt.style.use('classic')\n",
    "\n",
    "#importing seaborn for statistical plots\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the CSV file into pandas dataframe\n",
    "mpg_df = pd.read_csv(\"car-mpg.csv\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check top few records to get a feel of the data structure\n",
    "mpg_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the car name column as it is useless for the model\n",
    "mpg_df = mpg_df.drop('car_name', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the numbers in categorical variables with the actual country names in the origin col\n",
    "mpg_df['origin'] = mpg_df['origin'].replace({1: 'america', 2: 'europe', 3: 'asia'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical variable into dummy/indicator variables. As many columns will be created as distinct values\n",
    "# This is also kown as one hot coding. The column names will be America, Europe and Asia... with one hot coding\n",
    "mpg_df = pd.get_dummies(mpg_df, columns=['origin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets analysze the distribution of the dependent (mpg) column\n",
    "mpg_df.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note:  HP column is missing the describe output. That indicates something is not right with that column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if the hp column contains anything other than digits \n",
    "# run the \"isdigit() check on 'hp' column of the mpg_df dataframe. Result will be True or False for every row\n",
    "# capture the result in temp dataframe and dow a frequency count using value_counts()\n",
    "# There are six records with non digit values in 'hp' column\n",
    "\n",
    "temp = pd.DataFrame(mpg_df.hp.str.isdigit())  # if the string is made of digits store True else False  in the hp column \n",
    "# in temp dataframe\n",
    "\n",
    "temp[temp['hp'] == False]   # from temp take only those rows where hp has false\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On inspecting records number 32, 126 etc, we find \"?\" in the columns. Replace them with \"nan\"\n",
    "#Replace them with nan and remove the records from the data frame that have \"nan\"\n",
    "mpg_df = mpg_df.replace('?', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us see if we can get those records with nan\n",
    "\n",
    "mpg_df[mpg_df.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are various ways to handle missing values. Drop the rows, replace missing values with median values etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#of the 398 rows 6 have NAN in the hp column. We will drop those 6 rows. Not a good idea under all situations\n",
    "#note: HP is missing becauses of the non-numeric values in the column. \n",
    "#mpg_df = mpg_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instead of dropping the rows, lets replace the missing values with median value. \n",
    "mpg_df.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the missing values in 'hp' with median value of 'hp' :Note, we do not need to specify the column names\n",
    "# every column's missing value is replaced with that column's median respectively  (axis =0 means columnwise)\n",
    "#mpg_df = mpg_df.fillna(mpg_df.median())\n",
    "\n",
    "mpg_df = mpg_df.apply(lambda x: x.fillna(x.median()),axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg_df['hp'] = mpg_df['hp'].astype('float64')  # converting the hp column from object / string type to float\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us do a correlation analysis among the different dimensions and also each dimension with the dependent dimension\n",
    "# This is done using scatter matrix function which creates a dashboard reflecting useful information about the dimensions\n",
    "# The result can be stored as a .png file and opened in say, paint to get a larger view \n",
    "\n",
    "mpg_df_attr = mpg_df.iloc[:, 0:10]\n",
    "\n",
    "#axes = pd.plotting.scatter_matrix(mpg_df_attr)\n",
    "#plt.tight_layout()\n",
    "#plt.savefig('d:\\greatlakes\\mpg_pairpanel.png')\n",
    "\n",
    "sns.pairplot(mpg_df_attr, diag_kind='kde')   # to plot density curve instead of histogram\n",
    "\n",
    "#sns.pairplot(mpg_df_attr)  # to plot histogram, the default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The data distribution across various dimensions except 'Acc' do not look normal\n",
    "#Close observation between 'mpg' and other attributes indicate the relationship is not really linear\n",
    "#relation between 'mpg' and 'hp' show hetroscedacity... which will impact model accuracy\n",
    "#How about 'mpg' vs 'yr' surprising to see a positive relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy all the predictor variables into X dataframe. Since 'mpg' is dependent variable drop it\n",
    "X = mpg_df.drop('mpg', axis=1)\n",
    "X = X.drop({'origin_america', 'origin_asia' ,'origin_europe'}, axis=1)\n",
    "\n",
    "# Copy the 'mpg' column alone into the y dataframe. This is the dependent variable\n",
    "y = mpg_df[['mpg']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us break the X and y dataframes into training set and test set. For this we will use\n",
    "#Sklearn package's data splitting function which is based on random function\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split X and y into training and test set in 75:25 ratio\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30 , random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invoke the LinearRegression function and find the bestfit model on training data\n",
    "\n",
    "regression_model = LinearRegression()\n",
    "regression_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us explore the coefficients for each of the independent attributes\n",
    "\n",
    "for idx, col_name in enumerate(X_train.columns):\n",
    "    print(\"The coefficient for {} is {}\".format(col_name, regression_model.coef_[0][idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us check the intercept for the model\n",
    "\n",
    "intercept = regression_model.intercept_[0]\n",
    "\n",
    "print(\"The intercept for our model is {}\".format(intercept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "regression_model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model score - R2 or coeff of determinant\n",
    "# R^2=1–RSS / TSS =  RegErr / TSS\n",
    "\n",
    "regression_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is OLS a good model ? Should we building a simple linear model ? Check the residuals for each predictor.\n",
    "\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "sns.residplot(x= X_test['hp'], y= y_test['mpg'], color='green', lowess=True )\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "sns.residplot(x= X_test['acc'], y= y_test['mpg'], color='green', lowess=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So the model explains 85% of the variability in Y using X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------- Using Statsmodel library to get R type outputs -----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R^2 is not a reliable metric as it always increases with addition of more attributes even if the attributes have no \n",
    "# influence on the predicted variable. Instead we use adjusted R^2 which removes the statistical chance that improves R^2\n",
    "# Scikit does not provide a facility for adjusted R^2... so we use \n",
    "# statsmodel, a library that gives results similar to\n",
    "# what you obtain in R language\n",
    "# This library expects the X and Y to be given in one single dataframe\n",
    "\n",
    "data_train = pd.concat([X_train, y_train], axis=1)\n",
    "data_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "lm1 = smf.ols(formula= 'mpg ~ cyl+disp+hp+wt+acc+yr+car_type', data = data_train).fit()\n",
    "lm1.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(lm1.summary())  #Inferential statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us check the sum of squared errors by predicting value of y for test cases and \n",
    "# subtracting from the actual y for the test cases\n",
    "\n",
    "mse = np.mean((regression_model.predict(X_test)-y_test)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# underroot of mean_sq_error is standard deviation i.e. avg variance between predicted and actual\n",
    "\n",
    "import math\n",
    "\n",
    "math.sqrt(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so there is avg of 3.0 (roundoff) mpg difference from real mpg on an avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict mileage (mpg) for a set of attributes not in the training or test set\n",
    "y_pred = regression_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since this is regression, plot the predicted y value vs actual y values for the test data\n",
    "# A good model's prediction will be close to actual leading to high R and R2 values\n",
    "#plt.rcParams['figure.dpi'] = 500\n",
    "\n",
    "\n",
    "\n",
    "plt.scatter(y_test['mpg'], y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------- ITERATION 2  ---------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How do we improve the model? the R^2 is .844, how do we improve it\n",
    "# The indpendent attributes have different units and scales of measurement \n",
    "# It is always a good practice to scale all the dimensions using z scores or someother methode to address the problem of different scales \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "\n",
    "mpg_df_scaled  = mpg_df.apply(zscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the numpy array back into a dataframe \n",
    "\n",
    "mpg_df_scaled = pd.DataFrame(mpg_df_scaled, columns=mpg_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#browse the contents of the dataframe. Check that all the values are now z scores\n",
    "\n",
    "mpg_df_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy all the predictor variables into X dataframe. Since 'mpg' is dependent variable drop it\n",
    "X = mpg_df_scaled.drop('mpg', axis=1)\n",
    "X = X.drop({'origin_america', 'origin_asia' ,'origin_europe'}, axis=1)\n",
    "\n",
    "# Copy the 'mpg' column alone into the y dataframe. This is the dependent variable\n",
    "y = mpg_df_scaled[['mpg']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split X and y into training and test set in 75:25 ratio\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invoke the LinearRegression function and find the bestfit model on training data\n",
    "\n",
    "regression_model = LinearRegression()\n",
    "regression_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us explore the coefficients for each of the independent attributes\n",
    "\n",
    "for idx, col_name in enumerate(X_train.columns):\n",
    "    print(\"The coefficient for {} is {}\".format(col_name, regression_model.coef_[0][idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intercept = regression_model.intercept_[0]\n",
    "\n",
    "print(\"The intercept for our model is {}\".format(intercept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model score - R2 or coeff of determinant\n",
    "# R^2=1–RSS / TSS\n",
    "\n",
    "regression_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us check the sum of squared errors by predicting value of y for training cases and \n",
    "# subtracting from the actual y for the training cases\n",
    "\n",
    "mse = np.mean((regression_model.predict(X_test)-y_test)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# underroot of mean_sq_error is standard deviation i.e. avg variance between predicted and actual\n",
    "\n",
    "import math\n",
    "\n",
    "math.sqrt(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict mileage (mpg) for a set of attributes not in the training or test set\n",
    "y_pred = regression_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since this is regression, plot the predicted y value vs actual y values for the test data\n",
    "# A good model's prediction will be close to actual leading to high R and R2 values\n",
    "plt.scatter(y_test['mpg'], y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
