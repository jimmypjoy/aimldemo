{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will start from the decision trees(discussed last week) and go ahead to implement the Ensemble Techniques(this week's learnings) in the later part of the notebook.\n",
    "\n",
    "Or, click here to jump directly to <a href = #ensemblelearning> Ensemble Learning. </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to build a model that predicts if someone who seeks a loan might be a defaulter or a non-defaulter. We have several independent variables like, checking account balance, credit history, purpose, loan amount etc. For more details on the dataset, please see source at https://archive.ics.uci.edu/ml/datasets/statlog+(german+credit+data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#from sklearn.feature_extraction.text import CountVectorizer  #DT does not take strings as input for the model fit step....\n",
    "from IPython.display import Image  \n",
    "#import pydotplus as pydot\n",
    "from sklearn import tree\n",
    "from os import system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "creditData = pd.read_csv(\"credit.csv\")\n",
    "creditData.head(10) #several missing values!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "creditData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "creditData.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "creditData.info()  # many columns are of type object i.e. strings. These need to be converted to ordinal type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets convert the columns with an 'object' datatype into categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in creditData.columns: # Loop through all columns in the dataframe\n",
    "    if creditData[feature].dtype == 'object': # Only apply for columns with categorical strings\n",
    "        creditData[feature] = pd.Categorical(creditData[feature])# Replace strings with an integer\n",
    "creditData.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(creditData.checking_balance.value_counts())\n",
    "print(creditData.credit_history.value_counts())\n",
    "print(creditData.purpose.value_counts())\n",
    "print(creditData.savings_balance.value_counts())\n",
    "print(creditData.employment_duration.value_counts())\n",
    "print(creditData.other_credit.value_counts())\n",
    "print(creditData.housing.value_counts())\n",
    "print(creditData.job.value_counts())\n",
    "print(creditData.phone.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "replaceStruct = {\n",
    "                \"checking_balance\":     {\"< 0 DM\": 1, \"1 - 200 DM\": 2 ,\"> 200 DM\": 3 ,\"unknown\":-1},\n",
    "                \"credit_history\": {\"critical\": 1, \"poor\":2 , \"good\": 3, \"very good\": 4,\"perfect\": 5},\n",
    "                 \"savings_balance\": {\"< 100 DM\": 1, \"100 - 500 DM\":2 , \"500 - 1000 DM\": 3, \"> 1000 DM\": 4,\"unknown\": -1},\n",
    "                 \"employment_duration\":     {\"unemployed\": 1, \"< 1 year\": 2 ,\"1 - 4 years\": 3 ,\"4 - 7 years\": 4 ,\"> 7 years\": 5},\n",
    "                \"phone\":     {\"no\": 1, \"yes\": 2 },\n",
    "                #\"job\":     {\"unemployed\": 1, \"unskilled\": 2, \"skilled\": 3, \"management\": 4 },\n",
    "                \"default\":     {\"no\": 0, \"yes\": 1 } \n",
    "                    }\n",
    "oneHotCols=[\"purpose\",\"housing\",\"other_credit\",\"job\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "creditData=creditData.replace(replaceStruct)\n",
    "creditData=pd.get_dummies(creditData, columns=oneHotCols)\n",
    "creditData.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "creditData.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = creditData.drop(\"default\" , axis=1)\n",
    "y = creditData.pop(\"default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.30, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Decision Tree Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will build our model using the DecisionTreeClassifier function. Using default 'gini' criteria to split. Other option include 'entropy'.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dTree = DecisionTreeClassifier(criterion = 'gini', random_state=1)\n",
    "dTree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring our Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dTree.score(X_train, y_train))\n",
    "print(dTree.score(X_test, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_char_label = ['No', 'Yes']\n",
    "Credit_Tree_File = open('credit_tree.dot','w')\n",
    "dot_data = tree.export_graphviz(dTree, out_file=Credit_Tree_File, feature_names = list(X_train), class_names = list(train_char_label))\n",
    "Credit_Tree_File.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tree.export_graphviz outputs a .dot file. This is a text file that describes a graph structure using a specific structure. You can plot this by\n",
    "\n",
    "1. pasting the contents of that file at  http://webgraphviz.com/ (or)\n",
    "2. generate a image file using the 'dot' command (this will only work if you have graphviz installed on your machine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Works only if \"dot\" command works on you machine\n",
    "\n",
    "retCode = system(\"dot -Tpng credit_tree.dot -o credit_tree.png\")\n",
    "if(retCode>0):\n",
    "    print(\"system command returning error: \"+str(retCode))\n",
    "else:\n",
    "    display(Image(\"credit_tree.png\"))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reducing over fitting (Regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dTreeR = DecisionTreeClassifier(criterion = 'gini', max_depth = 3, random_state=1)\n",
    "dTreeR.fit(X_train, y_train)\n",
    "print(dTreeR.score(X_train, y_train))\n",
    "print(dTreeR.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_char_label = ['No', 'Yes']\n",
    "Credit_Tree_FileR = open('credit_treeR.dot','w')\n",
    "dot_data = tree.export_graphviz(dTreeR, out_file=Credit_Tree_FileR, feature_names = list(X_train), class_names = list(train_char_label))\n",
    "Credit_Tree_FileR.close()\n",
    "\n",
    "#Works only if \"dot\" command works on you machine\n",
    "\n",
    "retCode = system(\"dot -Tpng credit_treeR.dot -o credit_treeR.png\")\n",
    "if(retCode>0):\n",
    "    print(\"system command returning error: \"+str(retCode))\n",
    "else:\n",
    "    display(Image(\"credit_treeR.png\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importance of features in the tree building ( The importance of a feature is computed as the \n",
    "#(normalized) total reduction of the criterion brought by that feature. It is also known as the Gini importance )\n",
    "\n",
    "print (pd.DataFrame(dTreeR.feature_importances_, columns = [\"Imp\"], index = X_train.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(dTreeR.score(X_test , y_test))\n",
    "y_predict = dTreeR.predict(X_test)\n",
    "\n",
    "cm=metrics.confusion_matrix(y_test, y_predict, labels=[0, 1])\n",
    "\n",
    "df_cm = pd.DataFrame(cm, index = [i for i in [\"No\",\"Yes\"]],\n",
    "                  columns = [i for i in [\"No\",\"Yes\"]])\n",
    "plt.figure(figsize = (7,5))\n",
    "sns.heatmap(df_cm, annot=True ,fmt='g')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Last week we learned about the decision trees. Lets go ahead and implement this week's learnings now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id  = ensemblelearning></a>\n",
    "#                             Ensemble Learning - Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "bgcl = BaggingClassifier(base_estimator=dTree, n_estimators=50,random_state=1)\n",
    "#bgcl = BaggingClassifier(n_estimators=50,random_state=1)\n",
    "\n",
    "bgcl = bgcl.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = bgcl.predict(X_test)\n",
    "\n",
    "print(bgcl.score(X_test , y_test))\n",
    "\n",
    "cm=metrics.confusion_matrix(y_test, y_predict,labels=[0, 1])\n",
    "\n",
    "df_cm = pd.DataFrame(cm, index = [i for i in [\"No\",\"Yes\"]],\n",
    "                  columns = [i for i in [\"No\",\"Yes\"]])\n",
    "plt.figure(figsize = (7,5))\n",
    "sns.heatmap(df_cm, annot=True ,fmt='g')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Ensemble Learning - AdaBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "abcl = AdaBoostClassifier(n_estimators=10, random_state=1)\n",
    "#abcl = AdaBoostClassifier( n_estimators=50,random_state=1)\n",
    "abcl = abcl.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = abcl.predict(X_test)\n",
    "print(abcl.score(X_test , y_test))\n",
    "\n",
    "cm=metrics.confusion_matrix(y_test, y_predict,labels=[0, 1])\n",
    "\n",
    "df_cm = pd.DataFrame(cm, index = [i for i in [\"No\",\"Yes\"]],\n",
    "                  columns = [i for i in [\"No\",\"Yes\"]])\n",
    "plt.figure(figsize = (7,5))\n",
    "sns.heatmap(df_cm, annot=True ,fmt='g')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                     Ensemble Learning - GradientBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbcl = GradientBoostingClassifier(n_estimators = 50,random_state=1)\n",
    "gbcl = gbcl.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = gbcl.predict(X_test)\n",
    "print(gbcl.score(X_test, y_test))\n",
    "cm=metrics.confusion_matrix(y_test, y_predict,labels=[0, 1])\n",
    "\n",
    "df_cm = pd.DataFrame(cm, index = [i for i in [\"No\",\"Yes\"]],\n",
    "                  columns = [i for i in [\"No\",\"Yes\"]])\n",
    "plt.figure(figsize = (7,5))\n",
    "sns.heatmap(df_cm, annot=True ,fmt='g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble RandomForest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfcl = RandomForestClassifier(n_estimators = 50, random_state=1,max_features=12)\n",
    "rfcl = rfcl.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = rfcl.predict(X_test)\n",
    "print(rfcl.score(X_test, y_test))\n",
    "cm=metrics.confusion_matrix(y_test, y_predict,labels=[0, 1])\n",
    "\n",
    "df_cm = pd.DataFrame(cm, index = [i for i in [\"No\",\"Yes\"]],\n",
    "                  columns = [i for i in [\"No\",\"Yes\"]])\n",
    "plt.figure(figsize = (7,5))\n",
    "sns.heatmap(df_cm, annot=True ,fmt='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
