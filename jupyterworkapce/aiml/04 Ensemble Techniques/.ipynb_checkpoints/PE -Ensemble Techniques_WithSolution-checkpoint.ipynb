{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "The purpose is to predict whether the Pima Indian women shows signs of diabetes or not. We are using a dataset collected by \n",
    "\"National Institute of Diabetes and Digestive and Kidney Diseases\" which consists of a number of attributes which would help us \n",
    "to perform this prediction.\n",
    "\n",
    "Constraints on data collection\n",
    "All patients whose data has been collected are females at least 21 years old of Pima Indian heritage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset:\n",
    "https://www.kaggle.com/kumargh/pimaindiansdiabetescsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import Libraries and load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all the necessary modules\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "num_bins = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "pima_df = pd.read_csv('pima-indians-diabetes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is always a good practice to eye-ball raw data to get a feel of the data in terms of number of structure of the file, number \n",
    "of attributes, types of attributes and a general idea of likely challenges in the dataset. You would notice that it is a comma \n",
    "separated file. There are no column names!. Check the associated folders and find out about each attribute the name. What \n",
    "information is available about the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Print 10 samples from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pima_df.head(10)\n",
    "#0s signify a lot of missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Print the datatypes of each column and the shape of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pima_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pima_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are '0's in the data. Are they really valid '0's or they are missing values? Plasma, BP, skin thickness etc. these values \n",
    "cannot be 0. look at column by column logically to understand this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Replace all the 0s in the column with the median of the same column value accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pima_df.loc[pima_df.Plas == 0, 'Plas'] = pima_df.Plas.median()\n",
    "pima_df.loc[pima_df.Pres == 0, 'Pres'] = pima_df.Pres.median()\n",
    "pima_df.loc[pima_df.skin == 0, 'skin'] = pima_df.skin.median()\n",
    "pima_df.loc[pima_df.test == 0, 'test'] = pima_df.test.median()\n",
    "pima_df.loc[pima_df.mass == 0, 'mass'] = pima_df.mass.median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Print the descriptive statistics of each & every column using describe() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pima_df.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. See the distribution of 'Class' variable and plot it using appropriate graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pima_df.groupby(\"class\").agg({'class': 'count'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Use pairplots and correlation method to observe the relationship between different variables and state your insights.\n",
    "Hint: Use seaborn plot and check the relationship between different variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.pairplot(pima_df, hue=\"class\", palette=\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pima_df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for correlation between variables whose values are >0.8\n",
    "\n",
    "Observations:\n",
    "\n",
    "Diagonal plots have already been discussed in the Observations I of Univariate Analysis.\n",
    "There are no linear relationships between any two variables.\n",
    "There is no strong correlation between any two variables.\n",
    "There is no strong correlation between any independent variable and class variable.\n",
    "\n",
    "Using the plot - infer the relationship between different variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Split the pima_df into training and test set in the ratio of 70:30 (Training:Test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting data into training and test set for independent attributes\n",
    "n=pima_df['class'].count()\n",
    "train_set = pima_df.head(int(round(n*0.7))) # Up to the last initial training set row\n",
    "test_set = pima_df.tail(int(round(n*0.3))) # Past the last initial training set row\n",
    "\n",
    "# capture the target column (\"class\") into separate vectors for training set and test set\n",
    "train_labels = train_set.pop(\"class\")\n",
    "test_labels = test_set.pop(\"class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Create the decision tree model using “entropy” method of reducing the entropy and fit it to training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt_model = DecisionTreeClassifier(criterion = 'entropy' )\n",
    "dt_model.fit(train_set, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Print the accuracy of the model & print the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model.score(test_set , test_labels)\n",
    "test_pred = dt_model.predict(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (pd.DataFrame(dt_model.feature_importances_, columns = [\"Imp\"], index = train_set.columns))#Print the feature importance of the decision model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Apply the Random forest model and print the accuracy of Random forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfcl = RandomForestClassifier(criterion = 'entropy', class_weight={0:.5,1:.5}, max_depth = 5, min_samples_leaf=5)\n",
    "rfcl = rfcl.fit(train_set, train_labels)\n",
    "test_pred = rfcl.predict(test_set)\n",
    "rfcl.score(test_set , test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. Apply Adaboost Ensemble Algorithm for the same data and print the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "#abcl = AdaBoostClassifier(base_estimator=dt_model, n_estimators=50)\n",
    "abcl = AdaBoostClassifier( n_estimators= 20)\n",
    "abcl = abcl.fit(train_set, train_labels)\n",
    "\n",
    "test_pred = abcl.predict(test_set)\n",
    "abcl.score(test_set , test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13. Apply Bagging Classifier Algorithm and print the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "bgcl = BaggingClassifier(n_estimators=10, max_samples= .7, bootstrap=True)\n",
    "bgcl = bgcl.fit(train_set, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = bgcl.predict(test_set)\n",
    "bgcl.score(test_set , test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14. Apply GradientBoost Classifier Algorithm for the same data and print the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbcl = GradientBoostingClassifier(n_estimators = 50, learning_rate = 0.05)\n",
    "gbcl = gbcl.fit(train_set, train_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = gbcl.predict(test_set)\n",
    "gbcl.score(test_set , test_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
