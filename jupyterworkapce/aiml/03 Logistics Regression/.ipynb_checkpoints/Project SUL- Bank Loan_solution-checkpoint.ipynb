{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thera Bank Personal Loan Campaign"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1]  Import the datasets and libraries, check datatype, statistical summary,shape,null values or incorrect imputation. (5 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7lCWwBb-NgG-"
   },
   "outputs": [],
   "source": [
    "## importing libaries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xP18oduDNgHB",
    "outputId": "b69d694d-b81f-4ef4-8fea-36a6e7b65835"
   },
   "outputs": [],
   "source": [
    "# importing data\n",
    "\n",
    "df = pd.read_csv(\"Bank_Personal_Loan_Modelling.csv\")\n",
    "df.head()      # used to see top 5 rows of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dh2IxnHgNgHG",
    "outputId": "84b75141-53fe-477a-8714-56d639d239a2"
   },
   "outputs": [],
   "source": [
    "df.dtypes        ## this would give datatype of each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iWOlgHZYNgHI",
    "outputId": "edb369d6-5d52-4f2a-d922-5d5bad471401",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aMddk8hxNgHL",
    "outputId": "b0f8172e-d422-47ca-8c22-7de98598bfc0"
   },
   "outputs": [],
   "source": [
    "#There are negative numbmers in experience! maybe typing error. \n",
    "# Convert to non-negative using .abs function\n",
    "\n",
    "df['Experience'] = df['Experience'].abs()\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()  #check for null Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2]  EDA: Study the data distribution in each attribute and target variable, share your findings (20 marks)\n",
    "\n",
    "Number of unique in each column?\n",
    "\n",
    "Number of people with zero mortgage?\n",
    "\n",
    "Number of people with zero credit card spending per month?\n",
    "\n",
    "Value counts of all categorical columns.\n",
    "\n",
    "Univariate and Bivariate\n",
    "\n",
    "Get data model ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V5vfe7pZNgHO"
   },
   "outputs": [],
   "source": [
    "# Column descriptions\n",
    "\n",
    "## Data Description:\n",
    "\n",
    "##\tID\tCustomer ID\n",
    "\n",
    "##\tAge\tCustomer's age in completed years\n",
    "\n",
    "##\tExperience\t#years of professional experience\n",
    "\n",
    "##\tIncome\tAnnual income of the customer ($000)\n",
    "\n",
    "##\tZIPCode\tHome Address ZIP code.\n",
    "\n",
    "##\tFamily\tFamily size of the customer\n",
    "\n",
    "##\tCCAvg\tAvg. spending on credit cards per month ($000)\n",
    "\n",
    "##\tEducation\tEducation Level. 1: Undergrad; 2: Graduate; 3: Advanced/Professional\n",
    "\n",
    "##\tMortgage\tValue of house mortgage if any. ($000)\n",
    "\n",
    "##\tPersonal Loan\tDid this customer accept the personal loan offered in the last campaign? 0 - False and 1 - True\n",
    "\n",
    "##\tSecurities Account\tDoes the customer have a securities account with the bank? 0 - False and 1 - True\n",
    "\n",
    "##\tCD Account\tDoes the customer have a certificate of deposit (CD) account with the bank? 0 - False and 1 - True\n",
    "\n",
    "##\tOnline\tDoes the customer use internet banking facilities? 0 - False and 1 - True\n",
    "\n",
    "##\tCreditCard\tDoes the customer use a credit card issued by UniversalBank? 0 - False and 1 - True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nunique()\n",
    "# gives number of unique values in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['ID','ZIP Code'],axis=1,inplace=True)\n",
    "\n",
    "# dropping 'ID' column as it all the unique value and this column wont provide any insight to build a model\n",
    "# Zip Code represents region and region wise distribution of customers is not helping here\n",
    "# as alot region are there in just 5000 customers, therefore dropping 'ZIP Code'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.pairplot(df,diag_kind='kde')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age and experience have strong positive relation\n",
    "# Age and Experience have uniform distribution\n",
    "# Income is positively skewed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target Variable is Personal Loan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XGiFmmezNgHU"
   },
   "outputs": [],
   "source": [
    "vc = df[['Personal Loan', 'Securities Account', 'CD Account',\n",
    "       'Online', 'CreditCard']].sum().reset_index().rename(columns={'index':'Col_Name',0:\"Value_Count_1\"})\n",
    "vc['Value_Count_0'] = df.shape[0] - vc['Value_Count_1']\n",
    "vc\n",
    "\n",
    "# Value counts of all the category column with two unique values (0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Personal Loan'].value_counts(normalize=True)*100)\n",
    "print()\n",
    "df['Personal Loan'].value_counts(normalize=True).plot(kind='bar')\n",
    "plt.xlabel(\"Personal Loan - 0:'NO', 1:'Yes'\")\n",
    "plt.ylabel(\"Percentage\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Mortgage']==0].shape[0]\n",
    "\n",
    "#count of people having home mortgage as zero, Most of the people donot have mortgage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df['Personal Loan'], df['CreditCard'],normalize='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`When CreditCard value is 0 or 1 in both cases the distribution of target variable is same therefore dropping CreditCard`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('CreditCard',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df[df['Personal Loan']==0]['Mortgage'],color='r',label=0)\n",
    "sns.distplot(df[df['Personal Loan']==1]['Mortgage'],color='g',label=1)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Most people with zero motgage are not taking personal loans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df[df['Personal Loan']==0]['Income'],color='r',label=0)\n",
    "sns.distplot(df[df['Personal Loan']==1]['Income'],color='g',label=1)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Number of People with high income taking personal loan are high as compared to low income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df[df['Personal Loan']==0]['CCAvg'],color='r',label=0)\n",
    "sns.distplot(df[df['Personal Loan']==1]['CCAvg'],color='g',label=1)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# People with high avg credit card spending per month are taking personal loans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['CCAvg']==0].shape[0]\n",
    "\n",
    "#count of people having zero monthly spending on credit card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Family'] = df['Family'].astype('category')\n",
    "df['Education'] = df['Education'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = abs(df.corr()) # correlation matrix\n",
    "lower_triangle = np.tril(corr, k = -1)  # select only the lower triangle of the correlation matrix\n",
    "mask = lower_triangle == 0  # to mask the upper triangle in the following heatmap\n",
    "\n",
    "plt.figure(figsize = (15,8))  # setting the figure size\n",
    "sns.set_style(style = 'white')  # Setting it to white so that we do not see the grid lines\n",
    "sns.heatmap(lower_triangle, center=0.5, cmap= 'Blues', annot= True, xticklabels = corr.index, yticklabels = corr.columns,\n",
    "            cbar= False, linewidths= 1, mask = mask)   # Da Heatmap\n",
    "plt.xticks(rotation = 50)   # Aesthetic purposes\n",
    "plt.yticks(rotation = 20)   # Aesthetic purposes\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Age and Experience has 0.99 correlation therefore dropping Experience`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Experience',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3]  \tSplit the data into training and test set in the ratio of 70:30 respectively (5 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j_Dad9_hNgHe"
   },
   "outputs": [],
   "source": [
    "# Separate the independent attributes i.e. every column except personal loan\n",
    "# Store the target column (Personal Loan) into Y array\n",
    "\n",
    "x = df.loc[:, df.columns != 'Personal Loan']  # independent variables\n",
    "\n",
    "y = df.loc[:, df.columns == 'Personal Loan']  # Target variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.get_dummies(x,drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4]  Use Logistic Regression model to predict the likelihood of a customer buying personal loans. Print all the metrics related for evaluating the model performance (15 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the training and test data set in the ratio of 70:30 respectively. Can be of any ratio...\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "xtrain,xtest,ytrain,ytest = train_test_split(x,y,test_size=0.3,random_state=7)\n",
    "\n",
    "# Random state seeding for reapeatability of the code\n",
    "# if random state is not mentioned it would generate different train test sample in every run\n",
    "# test_size is to select the size of test data\n",
    "\n",
    "# two variables taken for split therefore output will generate 4 variables: test train for x and test train for y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mn2mLl5GNgHn",
    "outputId": "e9ce8edf-088d-448f-c714-fdc51962ba7a"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression   # importing logistic regression from scikit learn\n",
    "\n",
    "model = LogisticRegression(random_state=7)  #assigning a variable for the algorithm\n",
    "\n",
    "model.fit(xtrain, ytrain) #training of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = model.predict(xtest)     #model is predicting y values based on test dataset given to the model\n",
    "\n",
    "print(\"Trainig accuracy\",model.score(xtrain,ytrain))  # this will give training accuracy as training data has been used\n",
    "print()\n",
    "print(\"Testing accuracy\",model.score(xtest, ytest))   # this will give testing accuracy as testing data has been used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Here the model performs better in testing than training. Therefore, it is a good model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score, f1_score, roc_auc_score\n",
    "\n",
    "## importing necessary metrics to evaluate model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function to get confusion matrix in a proper format\n",
    "def draw_cm( actual, predicted ):\n",
    "    cm = confusion_matrix( actual, predicted)\n",
    "    sns.heatmap(cm, annot=True,  fmt='.2f', xticklabels = [0,1] , yticklabels = [0,1] )\n",
    "    plt.ylabel('Observed')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_cm(ytest,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(ytest,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(ytest,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(ytest,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(ytest,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install yellowbrick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional\n",
    "\n",
    "from yellowbrick.classifier import ClassificationReport, ROCAUC\n",
    "# Visualize model performance with yellowbrick library\n",
    "viz = ClassificationReport(model)\n",
    "viz.fit(xtrain, ytrain)\n",
    "viz.score(xtest, ytest)\n",
    "viz.show()\n",
    "\n",
    "roc = ROCAUC(model)\n",
    "roc.fit(xtrain, ytrain)\n",
    "roc.score(xtest, ytest)\n",
    "roc.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5]  1.\tCheck different parameters of Logistic Regression and give your reasoning whether the model performance is affected due to it or not? (10 marks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Parameters of logistic regression\n",
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If we dont specify the parameters in the model it takes default value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "\n",
    "Please refer above link for the details of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running a loop to check different values of 'solver'\n",
    "# all solver can be used with l2, only 'liblinear' and 'saga' works with both 'l1' and 'l2'\n",
    "\n",
    "train_score=[]\n",
    "test_score=[]\n",
    "solver = ['newton-cg','lbfgs','liblinear','sag','saga']\n",
    "for i in solver:\n",
    "    model = LogisticRegression(random_state=7,penalty='l2', solver=i)  # changing values of solver\n",
    "    model.fit(xtrain, ytrain) \n",
    "    y_predict = model.predict(xtest)     \n",
    "    train_score.append(round(model.score(xtrain,ytrain),3))\n",
    "    test_score.append(round(model.score(xtest, ytest),3))\n",
    "    \n",
    "print(solver)\n",
    "print()\n",
    "print(train_score)\n",
    "print()\n",
    "print(test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score=[]\n",
    "test_score=[]\n",
    "solver = ['liblinear','saga']  # changing values of solver which works with 'l1'\n",
    "for i in solver:\n",
    "    model = LogisticRegression(random_state=7,penalty='l1', solver=i)  # changed value of penaly to 'l1'\n",
    "    model.fit(xtrain, ytrain) \n",
    "    y_predict = model.predict(xtest)     \n",
    "    train_score.append(round(model.score(xtrain,ytrain),3))\n",
    "    test_score.append(round(model.score(xtest, ytest),3))\n",
    "    \n",
    "print(solver)\n",
    "print()\n",
    "print(train_score)\n",
    "print()\n",
    "print(test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Highest accuracy is same 'l1' with 'liblinear' and 'l2' with 'lbfgs'\n",
    "# choose any one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(random_state=7,penalty='l1',solver='liblinear',class_weight='balanced') # changing class weight to balanced\n",
    "\n",
    "model.fit(xtrain, ytrain) \n",
    "\n",
    "y_predict = model.predict(xtest)     \n",
    "\n",
    "print(\"Trainig accuracy\",model.score(xtrain,ytrain))  \n",
    "print()\n",
    "print(\"Testing accuracy\",model.score(xtest, ytest))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Accuracy decreased so removing class weight from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running a loop to check different values of 'C'\n",
    "\n",
    "train_score=[]                                 \n",
    "test_score=[]\n",
    "C = [0.01,0.1,0.25,0.5,0.75,1]\n",
    "for i in C:\n",
    "    model = LogisticRegression(random_state=7,penalty='l1',solver='liblinear', C=i)  # changing values of C\n",
    "    model.fit(xtrain, ytrain) \n",
    "    y_predict = model.predict(xtest)     \n",
    "    train_score.append(round(model.score(xtrain,ytrain),3)) # appending training accuracy in a blank list for every run of the loop\n",
    "    test_score.append(round(model.score(xtest, ytest),3))   # appending testing accuracy in a blank list for every run of the loop\n",
    "    \n",
    "print(C)\n",
    "print()\n",
    "print(train_score)\n",
    "print()\n",
    "print(test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Best testing accuracy is obtained for C=1, which is default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Therefore final model is\n",
    "model = LogisticRegression(random_state=7,penalty='l1',solver='liblinear') \n",
    "model.fit(xtrain, ytrain)\n",
    "y_predict = model.predict(xtest)\n",
    "print(\"Trainig accuracy\",model.score(xtrain,ytrain))  \n",
    "print()\n",
    "print(\"Testing accuracy\",model.score(xtest, ytest))\n",
    "print()\n",
    "print('Confusion Matrix')\n",
    "print(draw_cm(ytest,y_predict))\n",
    "print()\n",
    "print(\"Recall:\",recall_score(ytest,y_predict))\n",
    "print()\n",
    "print(\"Precision:\",precision_score(ytest,y_predict))\n",
    "print()\n",
    "print(\"F1 Score:\",f1_score(ytest,y_predict))\n",
    "print()\n",
    "print(\"Roc Auc Score:\",roc_auc_score(ytest,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional\n",
    "\n",
    "from yellowbrick.classifier import ClassificationReport, ROCAUC\n",
    "# Visualize model performance with yellowbrick library\n",
    "viz = ClassificationReport(model)\n",
    "viz.fit(xtrain, ytrain)\n",
    "viz.score(xtest, ytest)\n",
    "viz.show()\n",
    "\n",
    "roc = ROCAUC(model)\n",
    "roc.fit(xtrain, ytrain)\n",
    "roc.score(xtest, ytest)\n",
    "roc.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6] Give Business understanding of your model? (5 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confusion matrix means**\n",
    "\n",
    "*True Positive (observed=1,predicted=1):*\n",
    "\n",
    "Predicted Personal loan will be taken and the customer took it\n",
    "\n",
    "*False Positive (observed=0,predicted=1):*\n",
    "\n",
    "Predicted Personal loan will be taken and the customer did not take it\n",
    "\n",
    "*True Negative (observed=0,predicted=0):*\n",
    "\n",
    "Predicted Personal loan will not be taken and the customer did not take it\n",
    "\n",
    "*False Negative (observed=1,predicted=0):*\n",
    "\n",
    "Predicted Personal loan will not be taken and the customer took it\n",
    "\n",
    "Here more focus towards should be towards recall because our target variable is 'Personal Loan' , i.e whether the customer is accepting the personal loan or not. And the bank wants more people to accept personal loan i.e. less number of False Negative, so that bank doesn't lose real customers who want to take loan. Hence the focus should be on increasing Recall.\n",
    "\n",
    "After achieving the desired accuracy we can deploy the model for practical use. As in the bank now can predict who will say yes for the personnel loan. They can use the model for upcoming customers."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Mini+Project+Bank+Loan_solution (1).ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
