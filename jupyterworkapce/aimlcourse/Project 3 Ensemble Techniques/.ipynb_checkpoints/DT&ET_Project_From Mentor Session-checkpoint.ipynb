{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem statement\n",
    "\n",
    "We have data from a Portuguese bank on details of customers related to selling a term deposit\n",
    "The objective of the project is to help the marketing team identify potential customers who are relatively more likely to subscribe to the term deposit and this increase the hit ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data dictionary\n",
    "\n",
    "**Bank client data**\n",
    "* 1 - age \n",
    "* 2 - job : type of job \n",
    "* 3 - marital : marital status\n",
    "* 4 - education \n",
    "* 5 - default: has credit in default? \n",
    "* 6 - housing: has housing loan? \n",
    "* 7 - loan: has personal loan?\n",
    "* 8 - balance in account\n",
    "\n",
    "**Related to previous contact**\n",
    "* 8 - contact: contact communication type\n",
    "* 9 - month: last contact month of year\n",
    "* 10 - day: last contact day of the month\n",
    "* 11 - duration: last contact duration, in seconds*\n",
    "\n",
    "**Other attributes**\n",
    "* 12 - campaign: number of contacts performed during this campaign and for this client\n",
    "* 13 - pdays: number of days that passed by after the client was last contacted from a previous campaign\n",
    "* 14 - previous: number of contacts performed before this campaign and for this client\n",
    "* 15 - poutcome: outcome of the previous marketing campaign\n",
    "\n",
    "**Output variable (desired target):has the client subscribed a term deposit?**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "# To enable plotting graphs in Jupyter notebook\n",
    "import seaborn as sns\n",
    "\n",
    "# Remove scientific notations and display numbers with 2 decimal points instead\n",
    "pd.options.display.float_format = '{:,.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>2143</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>29</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1506</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>unknown</td>\n",
       "      <td>single</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age           job  marital  education default  balance housing loan  \\\n",
       "0   58    management  married   tertiary      no     2143     yes   no   \n",
       "1   44    technician   single  secondary      no       29     yes   no   \n",
       "2   33  entrepreneur  married  secondary      no        2     yes  yes   \n",
       "3   47   blue-collar  married    unknown      no     1506     yes   no   \n",
       "4   33       unknown   single    unknown      no        1      no   no   \n",
       "\n",
       "   contact  day month  duration  campaign  pdays  previous poutcome Target  \n",
       "0  unknown    5   may       261         1     -1         0  unknown     no  \n",
       "1  unknown    5   may       151         1     -1         0  unknown     no  \n",
       "2  unknown    5   may        76         1     -1         0  unknown     no  \n",
       "3  unknown    5   may        92         1     -1         0  unknown     no  \n",
       "4  unknown    5   may       198         1     -1         0  unknown     no  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the file from local directory using pd.read_csv which is a special form of read_table\n",
    "bank_df = pd.read_csv(\"bank-full.csv\")\n",
    "bank_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deliverable â€“ 1 (EDA)\n",
    "\n",
    "### Univariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45211 entries, 0 to 45210\n",
      "Data columns (total 17 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   age        45211 non-null  int64 \n",
      " 1   job        45211 non-null  object\n",
      " 2   marital    45211 non-null  object\n",
      " 3   education  45211 non-null  object\n",
      " 4   default    45211 non-null  object\n",
      " 5   balance    45211 non-null  int64 \n",
      " 6   housing    45211 non-null  object\n",
      " 7   loan       45211 non-null  object\n",
      " 8   contact    45211 non-null  object\n",
      " 9   day        45211 non-null  int64 \n",
      " 10  month      45211 non-null  object\n",
      " 11  duration   45211 non-null  int64 \n",
      " 12  campaign   45211 non-null  int64 \n",
      " 13  pdays      45211 non-null  int64 \n",
      " 14  previous   45211 non-null  int64 \n",
      " 15  poutcome   45211 non-null  object\n",
      " 16  Target     45211 non-null  object\n",
      "dtypes: int64(7), object(10)\n",
      "memory usage: 5.9+ MB\n"
     ]
    }
   ],
   "source": [
    "bank_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Numerical columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`'balance' has negative values those are okay as we have loan and default as features for the given dataset, so we can assume that the balance is of a credit account and it can be negative as well`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df.skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`The distribution of all numerical variables other than age is highly skewed - hence we might want to transform or bin some of these variables`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(bank_df['age'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`People above the age of 70 are outliers`\n",
    "\n",
    "`Age column has some outliers. The median age is about 40 years. There are some customers above 90 years of age. This data might have to be checked`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(bank_df['balance'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(bank_df['campaign'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Binning to be done for both the columns 'balance' and 'campaign'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df[bank_df['duration']==0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df.drop(['duration'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Non numerical columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in bank_df.columns[bank_df.dtypes=='object']:\n",
    "    print(i,\":\")\n",
    "    print()\n",
    "    print(bank_df[i].value_counts(normalize=True)*100)\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`We can drop poutcome as most of the values are unknown`\n",
    "\n",
    "`Target is imbalanced but there is no need to treat it as 'yes' class is around 11%, we treat for imbalanced data when one class is very low`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df.drop(['poutcome'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(bank_df['Target'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df['Target'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`The response rate is only 11.6%. Hence the Y variable has a high class imbalance. Hence accuracy will not be a reliable model performance measure.`\n",
    "\n",
    "`FN is very critical for this business case because a false negative is a customer who will potentially subscribe for a loan but who has been classified as 'will not subscribe'. Hence the most relevant model performance measure is recall`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bivariate analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['age','balance','day','campaign','pdays','previous']:\n",
    "    sns.boxplot(x='Target',y=i,data=bank_df)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Campaign values are higher for people saying no to term deposits i.e. people saying yes to term deposits have less number of contact during the campaign`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group numerical variables by mean for the classes of Y variable\n",
    "np.round(bank_df.groupby([\"Target\"]).mean() ,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`The mean balance is higher for customers who subscribe to the term deposit compared to those who dont`\n",
    "\n",
    "\n",
    "`Number of days that passed by after the client was last contacted from a previous campaign is higher for people who have subscribed`\n",
    "\n",
    "`Number of contacts performed before this campaign is also higher for customers who subscribe`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`All of the above facts indicate that customers with a higher balance and those who have been contacted frequently before the campaign tend to subscribe for the term deposit`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bivariate analysis using crosstab for categorical values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(bank_df['job'], bank_df['Target'], normalize='index').sort_values(by='yes',ascending=False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The highest conversion is for students (28%) and lowest is for blue-collar(7%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(bank_df['marital'], bank_df['Target'], normalize='index').sort_values(by='yes',ascending=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(bank_df['education'], bank_df['Target'], normalize='index').sort_values(by='yes',ascending=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.crosstab(bank_df['default'], bank_df['Target'], normalize='index').sort_values(by='yes',ascending=False ))\n",
    "print()\n",
    "print(bank_df['default'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Since default - yes is only 2% of the data and the conversion is also comparitively lower for default - yes, we can remove this column`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df.drop(['default'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(bank_df['housing'], bank_df['Target'], normalize='index').sort_values(by='yes',ascending=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(bank_df['loan'], bank_df['Target'], normalize='index').sort_values(by='yes',ascending=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(bank_df['contact'], bank_df['Target'], normalize='index').sort_values(by='yes',ascending=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(bank_df['month'], bank_df['Target'], normalize='index').sort_values(by='yes',ascending=False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deliverable â€“ 2 (Prepare the data for analytics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not a necessary step, but it helps having more categorical variables when target is categorical\n",
    "\n",
    "\n",
    "#Binning balance\n",
    "\n",
    "bin_edges=[-8020,0,72,448,1428,102128]\n",
    "# first value is min value -1 of the column and last value is max +1  of the column, so that all values are included\n",
    "# you can choose middle value on your own or select 25th, 50th and 75th percentile value\n",
    "bin_names=['very low','low','medium','high','very high']\n",
    "# Names of each bin or category\n",
    "bank_df['balance'] = pd.cut(bank_df['balance'],bin_edges,labels=bin_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not a necessary step, but it helps having more categorical variables when target is categorical\n",
    "\n",
    "#Binning Campaign\n",
    "\n",
    "bin_edges=[0,2,3,4,564]\n",
    "# first value is min value -1 of the column and last value is max +1  of the column, so that all values are included\n",
    "# you can choose middle value on your own or select 25th, 50th and 75th percentile value\n",
    "bin_names=['<=2','3', '4','>=4']\n",
    "# Names of each bin or category\n",
    "bank_df['campaign'] = pd.cut(bank_df['campaign'],bin_edges,labels=bin_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df['Target'] = bank_df['Target'].map({'yes':1, 'no':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating independent and dependent variables\n",
    "\n",
    "X = bank_df.drop(\"Target\" , axis=1)\n",
    "y = bank_df[\"Target\"]   \n",
    "\n",
    "X = pd.get_dummies(X, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "test_size = 0.30 # taking 70:30 training and test set\n",
    "seed = 7  # Random numbmer seeding for reapeatability of the code\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deliverable â€“ 3 (create the ensemble model)\n",
    "\n",
    "## 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo= []\n",
    "tr = []\n",
    "te = []\n",
    "recall = []\n",
    "precision = []\n",
    "roc = []\n",
    "\n",
    "# Blanks list to store model name, training score, testing score, recall, precision and roc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import recall_score, precision_score, roc_auc_score, accuracy_score\n",
    "model = LogisticRegression(random_state=7)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "algo.append('Logistic Regression')\n",
    "tr.append(model.score(X_train, y_train))\n",
    "te.append(model.score(X_test, y_test))\n",
    "recall.append(recall_score(y_test,model.predict(X_test)))\n",
    "precision.append(precision_score(y_test,model.predict(X_test)))\n",
    "roc.append(roc_auc_score(y_test,model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision Tree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#instantiating decision tree as the default model\n",
    "dt_model = DecisionTreeClassifier()\n",
    "dt_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training acuracy\n",
    "dt_model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing acuracy\n",
    "dt_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Model is an overfit as testing score is less than training score`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: -** `Decision Tree is a non-parametric algorithm and hence prone to overfitting easily. This is evident from the difference in scores in training and testing. In ensemble techniques, we want multiple instances (each different from the other) and each instance to be overfit!!! hopefully, the different instances will do different mistakes in classification and when we club them, their# errors will get cancelled out giving us the benefit of lower bias and lower overall variance errors.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_pruned = DecisionTreeClassifier(criterion = \"entropy\", random_state = 7, max_depth=3, min_samples_leaf=5)\n",
    "clf_pruned.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculating feature importance\n",
    "feature_cols = X_train.columns\n",
    "\n",
    "feat_importance = clf_pruned.tree_.compute_feature_importances(normalize=False)\n",
    "\n",
    "\n",
    "feat_imp_dict = dict(zip(feature_cols, clf_pruned.feature_importances_))\n",
    "feat_imp = pd.DataFrame.from_dict(feat_imp_dict, orient='index')\n",
    "feat_imp.sort_values(by=0, ascending=False)[0:10] #Top 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_pruned = clf_pruned.predict(X_test)\n",
    "preds_pruned_train = clf_pruned.predict(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Accuracy:\",accuracy_score(y_train, preds_pruned_train))\n",
    "print()\n",
    "print(\"Training Accuracy:\",accuracy_score(y_test, preds_pruned))\n",
    "print()\n",
    "print(\"Recall:\",recall_score(y_test, preds_pruned, average=\"binary\", pos_label=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Overfitting is reduced after pruning, but recall has drastically reduced`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Classifier using entropy, adding the values in the list\n",
    "\n",
    "model = DecisionTreeClassifier(criterion = \"entropy\", random_state = 7, max_depth=3, min_samples_leaf=5)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "algo.append('Decision Tree entropy')\n",
    "tr.append(model.score(X_train, y_train))\n",
    "te.append(model.score(X_test, y_test))\n",
    "recall.append(recall_score(y_test,model.predict(X_test)))\n",
    "precision.append(precision_score(y_test,model.predict(X_test)))\n",
    "roc.append(roc_auc_score(y_test,model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Classifier using gini, adding the values in the list\n",
    "\n",
    "model = DecisionTreeClassifier(criterion = \"gini\", random_state = 7, max_depth=3, min_samples_leaf=5)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "algo.append('Decision Tree gini')\n",
    "tr.append(model.score(X_train, y_train))\n",
    "te.append(model.score(X_test, y_test))\n",
    "recall.append(recall_score(y_test,model.predict(X_test)))\n",
    "precision.append(precision_score(y_test,model.predict(X_test)))\n",
    "roc.append(roc_auc_score(y_test,model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(random_state=7, n_estimators=50)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "algo.append('Random Forest')\n",
    "tr.append(model.score(X_train, y_train))\n",
    "te.append(model.score(X_test, y_test))\n",
    "recall.append(recall_score(y_test,model.predict(X_test)))\n",
    "precision.append(precision_score(y_test,model.predict(X_test)))\n",
    "roc.append(roc_auc_score(y_test,model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bagging\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "model = BaggingClassifier(random_state=7,n_estimators=100, max_samples= .7, bootstrap=True, oob_score=True)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "algo.append('Bagging')\n",
    "tr.append(model.score(X_train, y_train))\n",
    "te.append(model.score(X_test, y_test))\n",
    "recall.append(recall_score(y_test,model.predict(X_test)))\n",
    "precision.append(precision_score(y_test,model.predict(X_test)))\n",
    "roc.append(roc_auc_score(y_test,model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdaBoost\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "model = AdaBoostClassifier(random_state=7,n_estimators= 200, learning_rate=0.1)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "algo.append('AdaBoost')\n",
    "tr.append(model.score(X_train, y_train))\n",
    "te.append(model.score(X_test, y_test))\n",
    "recall.append(recall_score(y_test,model.predict(X_test)))\n",
    "precision.append(precision_score(y_test,model.predict(X_test)))\n",
    "roc.append(roc_auc_score(y_test,model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "model = GradientBoostingClassifier(random_state=7, n_estimators=200,)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "algo.append('Gradient Boosting')\n",
    "tr.append(model.score(X_train, y_train))\n",
    "te.append(model.score(X_test, y_test))\n",
    "recall.append(recall_score(y_test,model.predict(X_test)))\n",
    "precision.append(precision_score(y_test,model.predict(X_test)))\n",
    "roc.append(roc_auc_score(y_test,model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame to compare results.\n",
    "\n",
    "results = pd.DataFrame()\n",
    "results['Model'] = algo\n",
    "results['Training Score'] = tr\n",
    "results['Testing Score'] = te\n",
    "results['Recall'] = recall\n",
    "results['Precision'] = precision\n",
    "results['ROC AUC Score'] = roc\n",
    "results = results.set_index('Model')\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confusion matrix means**\n",
    "\n",
    "*True Positive (observed=1,predicted=1):*\n",
    "\n",
    "Customer subscribed to term deposit and model predicted that the customer will\n",
    "\n",
    "*False Positive (observed=0,predicted=1):*\n",
    "\n",
    "Customer did not subscribe to term deposit and model predicted that the customer will\n",
    "\n",
    "*True Negative (observed=0,predicted=0):*\n",
    "\n",
    "Customer did not subscribe to term deposit and model predicted that the customer won't\n",
    "\n",
    "*False Negative (observed=1,predicted=0):*\n",
    "\n",
    "Customer subscribed to term deposit and model predicted that the customer won't\n",
    "\n",
    "Here the company wants more people to subscribe to term deposits. So if we have a customer who is willing to subscribe then we shouldn't loose that customer. Therefore focus shpould be on False negative. Decreasing FN and increasing recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging gives overall best model performance. However, please note that the recall is still very low and will have to be improved"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
