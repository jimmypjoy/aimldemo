{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ca404c3",
   "metadata": {},
   "source": [
    "# LLM fine tuning with GPT[Working locally using Open AI APIs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "619af57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain import OpenAI, LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1c54b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a4f818e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_environment():\n",
    "    import sys\n",
    "    sys.path.append('C:\\\\gitworkspace\\\\aimldemo\\\\jupyterworkapce')\n",
    "    import stratup_env_setup\n",
    "    stratup_env_setup.set_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "808307e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4b5fa475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: openai==0.28 in c:\\users\\jimmy\\appdata\\roaming\\python\\python311\\site-packages (0.28.0)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\programdata\\anaconda3\\lib\\site-packages (from openai==0.28) (2.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\jimmy\\appdata\\roaming\\python\\python311\\site-packages (from openai==0.28) (4.66.5)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\jimmy\\appdata\\roaming\\python\\python311\\site-packages (from openai==0.28) (3.10.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.20->openai==0.28) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.20->openai==0.28) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.20->openai==0.28) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.20->openai==0.28) (2024.6.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\jimmy\\appdata\\roaming\\python\\python311\\site-packages (from aiohttp->openai==0.28) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->openai==0.28) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->openai==0.28) (22.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->openai==0.28) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->openai==0.28) (6.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\jimmy\\appdata\\roaming\\python\\python311\\site-packages (from aiohttp->openai==0.28) (1.15.2)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm->openai==0.28) (0.4.6)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\jimmy\\appdata\\roaming\\python\\python311\\site-packages (from yarl<2.0,>=1.12.0->aiohttp->openai==0.28) (0.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai==0.28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9462d1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are an assistant knowledgeable about Piscataway.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Tell me something about xcv_124 and yhgd_543 in Piscataway.\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5b84e612",
   "metadata": {},
   "outputs": [
    {
     "ename": "APIRemovedInV1",
     "evalue": "\n\nYou tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAPIRemovedInV1\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m response \u001b[38;5;241m=\u001b[39m openai\u001b[38;5;241m.\u001b[39mChatCompletion\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m      2\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-3.5-turbo\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# or \"gpt-4\" depending on your access\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     messages\u001b[38;5;241m=\u001b[39mmessages,\n\u001b[0;32m      4\u001b[0m     temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7\u001b[39m  \u001b[38;5;66;03m# Adjust the temperature for response creativity\u001b[39;00m\n\u001b[0;32m      5\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\openai\\lib\\_old_api.py:39\u001b[0m, in \u001b[0;36m__call__\u001b[1;34m(self, *_args, **_kwargs)\u001b[0m\n",
      "\u001b[1;31mAPIRemovedInV1\u001b[0m: \n\nYou tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",  # or \"gpt-4\" depending on your access\n",
    "    messages=messages,\n",
    "    temperature=0.7  # Adjust the temperature for response creativity\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54090633",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'response' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Extract and print the response from the assistant\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'response' is not defined"
     ]
    }
   ],
   "source": [
    "# Extract and print the response from the assistant\n",
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e9092d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the dataset for fine-tuning\n",
    "response = openai.File.create(\n",
    "    file=open(\"llm_tune_data_gpt3.json\"),\n",
    "    purpose='fine-tune'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd7950b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the file ID\n",
    "file_id = response['id']\n",
    "print(f\"Uploaded file ID: {file_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13979dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the fine-tuning job using the new endpoint\n",
    "fine_tune_response = openai.FineTuningJob.create(\n",
    "    training_file=file_id,\n",
    "    model=\"gpt-3.5-turbo\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef3f2380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning job created with ID: ftjob-gTJdgK1fjxwEBQROzsVCGd72\n"
     ]
    }
   ],
   "source": [
    "# Get the fine-tune job ID\n",
    "fine_tune_id = fine_tune_response['id']\n",
    "print(f\"Fine-tuning job created with ID: {fine_tune_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "42aeb590",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_fine_tune_status(fine_tune_id):\n",
    "    status = openai.FineTuningJob.retrieve(fine_tune_id)\n",
    "    print(f\"Status: {status['status']}\")\n",
    "    return status\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0be18b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning job status: succeeded\n",
      "Error message: {}\n"
     ]
    }
   ],
   "source": [
    "# Check detailed job status\n",
    "status = openai.FineTuningJob.retrieve(fine_tune_id)\n",
    "print(f\"Fine-tuning job status: {status['status']}\")\n",
    "print(f\"Error message: {status.get('error', 'No error message available')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "557be49e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned model ID: ft:gpt-3.5-turbo-0125:personal::A8ubOihk\n"
     ]
    }
   ],
   "source": [
    "# Retrieve details of the fine-tuning job to get the model ID\n",
    "fine_tune_details = openai.FineTuningJob.retrieve(fine_tune_id)\n",
    "\n",
    "# Extract the fine-tuned model ID from the response\n",
    "fine_tuned_model_id = fine_tune_details[\"fine_tuned_model\"]\n",
    "\n",
    "print(f\"Fine-tuned model ID: {fine_tuned_model_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4849d8ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xcv_124 and yhgd_543 are well-known streets in Piscataway.\n"
     ]
    }
   ],
   "source": [
    "fine_tuned_model = fine_tune_id\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=fine_tuned_model_id,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are an assistant knowledgeable about Piscataway.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Tell me something about xcv_124 and yhgd_543 in Piscataway.\"}\n",
    "    ],\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# Print the response\n",
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bae2c6",
   "metadata": {},
   "source": [
    "# GPT personal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e2b74974",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are an assistant knowledgeable about people. You should make sure that teh information matches the full name. If you don't know about the person, say I don't know. Do not provide information based on partail name like first name and last name only.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Tell me something about Jimmy Pulimalayil Joy\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aabed981",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",  # or \"gpt-4\" depending on your access\n",
    "    messages=messages,\n",
    "    temperature=0.7  # Adjust the temperature for response creativity\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "570bed1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't know.\n"
     ]
    }
   ],
   "source": [
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8ce05084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the dataset for fine-tuning\n",
    "response = openai.File.create(\n",
    "    file=open(\"llm_tune_data_personal_gpt3.json\"),\n",
    "    purpose='fine-tune'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "024f3915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded file ID: file-Og69NLVqUDBeheGvBYFG4Bag\n"
     ]
    }
   ],
   "source": [
    "# Get the file ID\n",
    "file_id = response['id']\n",
    "print(f\"Uploaded file ID: {file_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fc884f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the fine-tuning job using the new endpoint\n",
    "fine_tune_response = openai.FineTuningJob.create(\n",
    "    training_file=file_id,\n",
    "    model=\"gpt-3.5-turbo\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "28eec60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning job created with ID: ftjob-ZqiehljqecNdC1FqhSfuNlVm\n"
     ]
    }
   ],
   "source": [
    "# Get the fine-tune job ID\n",
    "fine_tune_id = fine_tune_response['id']\n",
    "print(f\"Fine-tuning job created with ID: {fine_tune_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8e5359ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_fine_tune_status(fine_tune_id):\n",
    "    status = openai.FineTuningJob.retrieve(fine_tune_id)\n",
    "    print(f\"Status: {status['status']}\")\n",
    "    return status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7130f90c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning job status: succeeded\n",
      "Error message: {}\n"
     ]
    }
   ],
   "source": [
    "# Check detailed job status\n",
    "status = openai.FineTuningJob.retrieve(fine_tune_id)\n",
    "print(f\"Fine-tuning job status: {status['status']}\")\n",
    "print(f\"Error message: {status.get('error', 'No error message available')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "032321cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned model ID: ft:gpt-3.5-turbo-0125:personal::A9HSdBae\n"
     ]
    }
   ],
   "source": [
    "# Retrieve details of the fine-tuning job to get the model ID\n",
    "fine_tune_details = openai.FineTuningJob.retrieve(fine_tune_id)\n",
    "\n",
    "# Extract the fine-tuned model ID from the response\n",
    "fine_tuned_model_id = fine_tune_details[\"fine_tuned_model\"]\n",
    "\n",
    "print(f\"Fine-tuned model ID: {fine_tuned_model_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "47cf2807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jimmy Pulimalayil Joy lives in Piscataway.\n"
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=fine_tuned_model_id,\n",
    "    messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are an assistant knowledgeable about people. You should make sure that teh information matches the full name. If you don't know about the person, say I don't know. Do not provide information based on partail name like first name and last name only.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Tell me something about Jimmy Pulimalayil Joy\"}\n",
    "],\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# Print the response\n",
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea259d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7849fa6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c891eb04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
