{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e255d12-ff19-49e0-be1a-8de68720fa96",
   "metadata": {
    "id": "8e255d12-ff19-49e0-be1a-8de68720fa96"
   },
   "source": [
    "# <center> TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6be846a-4ce3-43d1-92c6-ea76960b2b61",
   "metadata": {
    "id": "e6be846a-4ce3-43d1-92c6-ea76960b2b61",
    "tags": []
   },
   "source": [
    "# <a id= 'b0'>\n",
    "<font size = 4>\n",
    "    \n",
    "**Table of contents:**<br>\n",
    "[1. Introduction](#b1)<br>\n",
    "[2. skLearn-Tfidf vectorizer](#b2)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82494ef9-1d5f-4c19-8473-7c9c609f9fd6",
   "metadata": {
    "id": "82494ef9-1d5f-4c19-8473-7c9c609f9fd6",
    "tags": []
   },
   "source": [
    "## <a id = 'b1'>\n",
    "    \n",
    "<font size = 10 color = 'midnightblue'> <b> Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ef659f-a0c8-4c63-9701-a1e3cd62347d",
   "metadata": {
    "id": "51ef659f-a0c8-4c63-9701-a1e3cd62347d"
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">    \n",
    "<font size = 4>\n",
    "\n",
    "**TF-IDF, or Term Frequency-Inverse Document Frequency, is a numerical statistic that reflects the importance of a word in a document relative to a collection of documents.**\n",
    "\n",
    "**1. Term Frequency (TF):**\n",
    "    \n",
    ">- Measures how often a term (word) appears in a document.\n",
    ">- Calculated as the ratio of the number of times a term appears in a document to the total number of terms in that document.\n",
    ">- It aims to highlight words that are more frequent within a specific document."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31b4489-3ef8-455f-bc8a-dc1d8e285904",
   "metadata": {
    "id": "b31b4489-3ef8-455f-bc8a-dc1d8e285904"
   },
   "source": [
    "<font size = 5>\n",
    "\n",
    "$$\\text{TF(t,d)}=\\frac{\\text{number of times t appears in d }}{\\text {total number of terms in d}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307c510f-847c-42a6-bf50-a1503348c8a5",
   "metadata": {
    "id": "307c510f-847c-42a6-bf50-a1503348c8a5"
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">    \n",
    "<font size = 4>  \n",
    "    \n",
    "**2. Inverse Document Frequency (IDF):**\n",
    ">- Measures how important a term is across a collection of documents.\n",
    ">- Calculated as the logarithm of the total number of documents divided by the number of documents containing the term, with the result inverted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8xsOFfZquYXz",
   "metadata": {
    "id": "8xsOFfZquYXz"
   },
   "source": [
    "<font size = 5>\n",
    "$$IDF (t) = log  \\frac {N} {1 + df}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b424a3f5-47a4-461c-917d-fce937fd26a3",
   "metadata": {
    "id": "b424a3f5-47a4-461c-917d-fce937fd26a3"
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">    \n",
    "<font size = 4>  \n",
    "\n",
    "**3. TF-IDF**\n",
    "> - The TF-IDF score for a term in a document is the product of its TF and IDF values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qwgahbY6uDph",
   "metadata": {
    "id": "qwgahbY6uDph"
   },
   "source": [
    "<font size = 5>\n",
    "    \n",
    "$$ TF - IDF(t,d) = TF (t,d) * IDF (t) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd03fda4-7bce-41d2-b05f-5f2bbda1f56d",
   "metadata": {
    "id": "fd03fda4-7bce-41d2-b05f-5f2bbda1f56d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from string import punctuation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88815cb-022b-4986-a2f1-9f613a5cca96",
   "metadata": {
    "id": "a88815cb-022b-4986-a2f1-9f613a5cca96",
    "tags": []
   },
   "source": [
    "<font size = 5 color = seagreen> <b>Create a collection dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea9c18d0-e6bf-446c-a5ec-04cfb8fe2944",
   "metadata": {
    "id": "ea9c18d0-e6bf-446c-a5ec-04cfb8fe2944",
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = [\n",
    "    \"The weather today is fantastic, with clear skies and a gentle breeze.\",\n",
    "    \"Reading is a great way to escape reality and immerse oneself in different worlds.\",\n",
    "    \"Climate change is a pressing global issue that requires immediate attention.\",\n",
    "    \"Exercise is crucial for maintaining good physical and mental health.\",\n",
    "    \"Learning a new language can be challenging but incredibly rewarding.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a4644a-28aa-40d1-8708-787e9e427745",
   "metadata": {
    "id": "07a4644a-28aa-40d1-8708-787e9e427745"
   },
   "source": [
    "## <a id = 'b1'>\n",
    "    \n",
    "<font size = 10 color = 'midnightblue'> <b>tfidf vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8739724b-a929-4db1-bb08-a3edb7468db4",
   "metadata": {
    "id": "8739724b-a929-4db1-bb08-a3edb7468db4",
    "tags": []
   },
   "source": [
    "<font size = 5 color = seagreen><b>  Define a count vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b95a6fd2-eb9d-4314-a9da-27eab60f35c5",
   "metadata": {
    "id": "b95a6fd2-eb9d-4314-a9da-27eab60f35c5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=1000, lowercase=True, analyzer='word')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde0a5c1-101a-424c-a0ff-5233b33802b9",
   "metadata": {
    "id": "cde0a5c1-101a-424c-a0ff-5233b33802b9",
    "tags": []
   },
   "source": [
    "<font size = 5 color = seagreen><b>  Fit the tf-idf model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "218ea9aa-8904-4c17-96b8-002da46da3a5",
   "metadata": {
    "id": "218ea9aa-8904-4c17-96b8-002da46da3a5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "tfidf = vectorizer.fit(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acade19f-c831-4f1f-84d2-a21389763142",
   "metadata": {
    "id": "acade19f-c831-4f1f-84d2-a21389763142",
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">    \n",
    "<font size = 4>\n",
    "\n",
    "**The vectorizer object also returns the feature names for transformation which is the vocabulary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d7ed631-91be-469f-ba61-8098b1a7bbd9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5d7ed631-91be-469f-ba61-8098b1a7bbd9",
    "outputId": "58412767-4808-43ea-a3e2-00af0a0da98a",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and', 'attention', 'be', 'breeze', 'but', 'can', 'challenging', 'change', 'clear', 'climate', 'crucial', 'different', 'escape', 'exercise', 'fantastic', 'for', 'gentle', 'global', 'good', 'great', 'health', 'immediate', 'immerse', 'in', 'incredibly', 'is', 'issue', 'language', 'learning', 'maintaining', 'mental', 'new', 'oneself', 'physical', 'pressing', 'reading', 'reality', 'requires', 'rewarding', 'skies', 'that', 'the', 'to', 'today', 'way', 'weather', 'with', 'worlds']\n"
     ]
    }
   ],
   "source": [
    "print(list(tfidf.get_feature_names_out()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026915c7-06c9-4ceb-9a6d-aa9b6fe98e96",
   "metadata": {
    "id": "026915c7-06c9-4ceb-9a6d-aa9b6fe98e96"
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">    \n",
    "<font size = 4>\n",
    "\n",
    "**The vectorizer returns a sparse matrix where rows represent each sentence of the dataset and columns correspond to each word in vocabulary.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd070120-bfac-4f7c-b09a-0ad417b70b90",
   "metadata": {
    "id": "cd070120-bfac-4f7c-b09a-0ad417b70b90",
    "tags": []
   },
   "outputs": [],
   "source": [
    "vector = tfidf.transform(dataset).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dhmOnWjXtF-n",
   "metadata": {
    "id": "dhmOnWjXtF-n"
   },
   "outputs": [],
   "source": [
    "dataset = [\n",
    "    \"The weather today is fantastic, with clear skies and a gentle breeze.\",\n",
    "    \"Reading is a great way to escape reality and immerse oneself in different worlds.\",\n",
    "    \"Climate change is a pressing global issue that requires immediate attention.\",\n",
    "    \"Exercise is crucial for maintaining good physical and mental health.\",\n",
    "    \"Learning a new language can be challenging but incredibly rewarding.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fe2993e-7d47-4917-812e-67c1a311d7f2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "0fe2993e-7d47-4917-812e-67c1a311d7f2",
    "outputId": "449efad9-0c6c-49dc-9011-66c45388ce47",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>attention</th>\n",
       "      <th>be</th>\n",
       "      <th>breeze</th>\n",
       "      <th>but</th>\n",
       "      <th>can</th>\n",
       "      <th>challenging</th>\n",
       "      <th>change</th>\n",
       "      <th>clear</th>\n",
       "      <th>climate</th>\n",
       "      <th>...</th>\n",
       "      <th>rewarding</th>\n",
       "      <th>skies</th>\n",
       "      <th>that</th>\n",
       "      <th>the</th>\n",
       "      <th>to</th>\n",
       "      <th>today</th>\n",
       "      <th>way</th>\n",
       "      <th>weather</th>\n",
       "      <th>with</th>\n",
       "      <th>worlds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sent_1</th>\n",
       "      <td>0.214305</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.319995</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.319995</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.319995</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.319995</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.319995</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.319995</td>\n",
       "      <td>0.319995</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent_2</th>\n",
       "      <td>0.195243</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.291533</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.291533</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.291533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent_3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.327607</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.327607</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.327607</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.327607</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent_4</th>\n",
       "      <td>0.226198</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent_5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             and  attention        be    breeze       but       can  \\\n",
       "sent_1  0.214305   0.000000  0.000000  0.319995  0.000000  0.000000   \n",
       "sent_2  0.195243   0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "sent_3  0.000000   0.327607  0.000000  0.000000  0.000000  0.000000   \n",
       "sent_4  0.226198   0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "sent_5  0.000000   0.000000  0.333333  0.000000  0.333333  0.333333   \n",
       "\n",
       "        challenging    change     clear   climate  ...  rewarding     skies  \\\n",
       "sent_1     0.000000  0.000000  0.319995  0.000000  ...   0.000000  0.319995   \n",
       "sent_2     0.000000  0.000000  0.000000  0.000000  ...   0.000000  0.000000   \n",
       "sent_3     0.000000  0.327607  0.000000  0.327607  ...   0.000000  0.000000   \n",
       "sent_4     0.000000  0.000000  0.000000  0.000000  ...   0.000000  0.000000   \n",
       "sent_5     0.333333  0.000000  0.000000  0.000000  ...   0.333333  0.000000   \n",
       "\n",
       "            that       the        to     today       way   weather      with  \\\n",
       "sent_1  0.000000  0.319995  0.000000  0.319995  0.000000  0.319995  0.319995   \n",
       "sent_2  0.000000  0.000000  0.291533  0.000000  0.291533  0.000000  0.000000   \n",
       "sent_3  0.327607  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "sent_4  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "sent_5  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "          worlds  \n",
       "sent_1  0.000000  \n",
       "sent_2  0.291533  \n",
       "sent_3  0.000000  \n",
       "sent_4  0.000000  \n",
       "sent_5  0.000000  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(vector,\n",
    "             columns= list(tfidf.get_feature_names_out()),\n",
    "             index = [f'sent_{i}' for i in range(1,len(dataset)+1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bd5f99-286f-4a66-9cd3-4f67247df2eb",
   "metadata": {
    "id": "45bd5f99-286f-4a66-9cd3-4f67247df2eb"
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">    \n",
    "<font size = 4>\n",
    "\n",
    "**This vectorised data can be used as input features (predictors) to any ML model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e251831-37c9-4695-a2e2-08727dd4c4c6",
   "metadata": {
    "id": "0e251831-37c9-4695-a2e2-08727dd4c4c6"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
