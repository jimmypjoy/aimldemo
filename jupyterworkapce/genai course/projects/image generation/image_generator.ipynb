{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cceafe7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.tools import BaseTool\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from PIL import Image\n",
    "import os\n",
    "import requests\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62760326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will setup teh OPENAI API key in os environment variables \n",
    "#os.environ[\"OPENAI_API_KEY\"] = \"xxxxx\"\n",
    "def setup_environment():\n",
    "    import sys\n",
    "    sys.path.append('C:\\\\gitworkspace\\\\aimldemo\\\\jupyterworkapce')\n",
    "    import stratup_env_setup\n",
    "    stratup_env_setup.set_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5500603c",
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68503d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d35bdc99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API key is set.\n"
     ]
    }
   ],
   "source": [
    "if not openai.api_key:\n",
    "    print(\"Error: OpenAI API key is missing.\")\n",
    "else:\n",
    "    print(\"OpenAI API key is set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "293b75ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom LangChain Tool to interact with DALL-E\n",
    "class DalleTool(BaseTool):\n",
    "    name: str = \"DALL-E Image Generator\"\n",
    "    description: str = \"Generates an image from a text prompt using OpenAI's DALL-E.\"\n",
    "\n",
    "    def _run(self, prompt: str) -> str:\n",
    "        \"\"\"\n",
    "        Generate an image URL from the given prompt using OpenAI's updated API.\n",
    "\n",
    "        Args:\n",
    "            prompt (str): Text description of the desired image.\n",
    "\n",
    "        Returns:\n",
    "            str: URL of the generated image.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            response = openai.Image.create(\n",
    "                prompt=prompt,\n",
    "                n=1,  # Number of images\n",
    "                size=\"512x512\"  # Image dimensions\n",
    "            )\n",
    "            return response[\"data\"][0][\"url\"]\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Error generating image: {e}\")\n",
    "\n",
    "    async def _arun(self, *args, **kwargs):\n",
    "        \"\"\"Asynchronous method required by BaseTool but not used here.\"\"\"\n",
    "        raise NotImplementedError(\"DalleTool does not support async operations.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3344ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jimmy\\AppData\\Local\\Temp\\ipykernel_21200\\209903208.py:2: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.7)\n"
     ]
    }
   ],
   "source": [
    "# Initialize the LangChain LLM\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "566eacab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Prompt Template\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"description\"],\n",
    "    template=\"Generate an image of: {description}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebe9dff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jimmy\\AppData\\Local\\Temp\\ipykernel_21200\\3391253797.py:2: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  image_chain = LLMChain(llm=llm, prompt=prompt_template)\n"
     ]
    }
   ],
   "source": [
    "# Combine Prompt Template and LLM into a LangChain\n",
    "image_chain = LLMChain(llm=llm, prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53840e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image_with_langchain(description: str):\n",
    "    \"\"\"\n",
    "    Generate an image using LangChain for processing the prompt and OpenAI's DALL-E.\n",
    "\n",
    "    Args:\n",
    "        description (str): Text prompt describing the image.\n",
    "\n",
    "    Returns:\n",
    "        PIL.Image: The generated image.\n",
    "    \"\"\"\n",
    "    # Generate the raw prompt using LangChain\n",
    "    raw_prompt = image_chain.invoke({\"description\": description})\n",
    "    \n",
    "    # Ensure the raw_prompt is a plain string\n",
    "    if isinstance(raw_prompt, dict) and \"description\" in raw_prompt:\n",
    "        prompt = raw_prompt[\"description\"]\n",
    "    elif isinstance(raw_prompt, str):\n",
    "        prompt = raw_prompt\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected prompt format: {raw_prompt}\")\n",
    "\n",
    "    # Debug: Print the prompt\n",
    "    print(f\"Using prompt for DALL-E: {prompt}\")\n",
    "\n",
    "    # Use DALL-E to generate the image\n",
    "    try:\n",
    "        dalle_tool = DalleTool()\n",
    "        image_url = dalle_tool._run(prompt)  # Pass the plain string prompt\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error generating image: {e}\")\n",
    "\n",
    "    # Fetch the image from the URL\n",
    "    image_response = requests.get(image_url)\n",
    "    image = Image.open(BytesIO(image_response.content))\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d5d72b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradio UI\n",
    "def gradio_ui():\n",
    "    \"\"\"\n",
    "    Creates and launches the Gradio interface for DALL-E with LangChain integration.\n",
    "    \"\"\"\n",
    "    with gr.Blocks() as demo:\n",
    "        gr.Markdown(\"<h1 style='text-align: center;'>Image Generator</h1>\")\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                prompt_input = gr.Textbox(\n",
    "                    label=\"Enter a text prompt\",\n",
    "                    placeholder=\"Describe the image you want to generate...\",\n",
    "                    lines=3\n",
    "                )\n",
    "                generate_button = gr.Button(\"Generate\")\n",
    "            with gr.Column():\n",
    "                image_output = gr.Image(label=\"Generated Image\")\n",
    "        \n",
    "        # Connect the button to the LangChain-based image generation function\n",
    "        generate_button.click(\n",
    "            fn=generate_image_with_langchain,\n",
    "            inputs=[prompt_input],\n",
    "            outputs=[image_output]\n",
    "        )\n",
    "\n",
    "        # Launch the Gradio UI\n",
    "        demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f600c989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using prompt for DALL-E: A serene lake surrounded by snow-capped mountains during sunset\n",
      "Using prompt for DALL-E: A serene lake surrounded by snow-capped mountains during sunset\n",
      "Using prompt for DALL-E: A beautiful areal view of Interlaken,  Switzerland with the two lakes\n",
      "Using prompt for DALL-E: A beautiful areal view of Interlaken,  Switzerland with the two lakes\n",
      "Using prompt for DALL-E: A tiger walking on Brooklyn bridge in teh night\n",
      "Using prompt for DALL-E: A tiger walking on Brooklyn bridge in the night\n",
      "Using prompt for DALL-E: New York city skyline in the night\n",
      "Using prompt for DALL-E: New York city Time square in the night\n",
      "Using prompt for DALL-E: New York city Time square in the night\n"
     ]
    }
   ],
   "source": [
    "gradio_ui()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8a06e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc269d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
