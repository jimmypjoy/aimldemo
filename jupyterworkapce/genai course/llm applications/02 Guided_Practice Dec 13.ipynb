{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "JjVaYKA3E4Sh",
   "metadata": {
    "id": "JjVaYKA3E4Sh"
   },
   "source": [
    "# __Few-Shot Prompting with LangChain and OpenAI__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df7b101f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_environment():\n",
    "    import sys\n",
    "    sys.path.append('C:\\\\gitworkspace\\\\aimldemo\\\\jupyterworkapce')\n",
    "    import stratup_env_setup\n",
    "    stratup_env_setup.set_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e9635f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_environment()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "L5xEJAD-FWkJ",
   "metadata": {
    "id": "L5xEJAD-FWkJ"
   },
   "source": [
    "## __Steps to Perform:__\n",
    "Step 1: Set up the OpenAI API Key\n",
    "\n",
    "Step 2: Define a Function to Get Completion\n",
    "\n",
    "Step 3: Define Your Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oejbW3zZlqXB",
   "metadata": {
    "id": "oejbW3zZlqXB"
   },
   "source": [
    "### __Step 1: Set up the OpenAI API Key__\n",
    "- The code imports the necessary libraries.\n",
    "- The **os** is used for interacting with the operating system, and **openai** is the library required to work with OpenAI's API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "172a828d-22d6-486b-be55-62c9258add5b",
   "metadata": {
    "id": "172a828d-22d6-486b-be55-62c9258add5b"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "#from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "#_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "#openai.api_key  = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yI8QQCxCl-LQ",
   "metadata": {
    "id": "yI8QQCxCl-LQ"
   },
   "source": [
    "### __Step 2: Define a Function to Get Completion__\n",
    "The __get_completion__ function is responsible for sending a prompt to the OpenAI model and receiving its response.\n",
    "\n",
    "__Parameters:__\n",
    "  - __prompt__: It is the text input for which the model will generate a completion.\n",
    "  - __model__: The gpt-3.5-turbo model is used to perform the tasks.\n",
    "\n",
    "The __openai.ChatCompletion.create__ function is used to send a request to the OpenAI API.\n",
    "- This request includes the model, the input messages (formatted as a list of dictionaries with user roles and content), and a temperature setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e778a5d4-77e5-4d61-a77d-3fed1e8d830a",
   "metadata": {
    "id": "e778a5d4-77e5-4d61-a77d-3fed1e8d830a"
   },
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XJS0DNh0nonO",
   "metadata": {
    "id": "XJS0DNh0nonO"
   },
   "source": [
    "### __Step 3: Define Your Prompt__\n",
    "- The prompt variable is defined with a simple  task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ef6aa68-a8aa-45c6-b70b-3060e9253b90",
   "metadata": {
    "id": "3ef6aa68-a8aa-45c6-b70b-3060e9253b90",
    "outputId": "8d98a6c9-99b7-48e7-a2ea-fcf68b053879"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Bonjour, monde!'\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Translate the following English sentence to French:\n",
    "\n",
    "'Hello, world!'\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a4b0eaa-94ca-4756-bc9a-8cf717b64981",
   "metadata": {
    "id": "2a4b0eaa-94ca-4756-bc9a-8cf717b64981",
    "outputId": "6d0833ba-4fce-4a7e-d4bf-2d9996e9cb32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the heart of the whispering woods, the trees seemed to speak in hushed tones, sharing secrets of the creatures that dwelled within their depths.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Title: The Last Lightkeeper\n",
    "Excerpt: In the twilight hours, the last lightkeeper faced the sea, contemplating the solitude of his existence.\n",
    "\n",
    "Title: Beyond the Horizon\n",
    "Excerpt: She sailed beyond the horizon, where the sea meets the sky, in search of lands that maps forgot.\n",
    "\n",
    "Title: Echoes of the Forgotten\n",
    "Excerpt: Through the ancient ruins, whispers of the past echoed, telling tales of a civilization lost to time.\n",
    "\n",
    "Title: The Whispering Woods\n",
    "Excerpt:\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2215ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Title: Gospel of Matthew\n",
    "Total Chapters: 28\n",
    "\n",
    "Title: Gospel of Mark\n",
    "Total Chapters: 16\n",
    "\n",
    "Title: Gospel of Luke\n",
    "Total Chapters: 24\n",
    "\n",
    "Title: Beyond the Horizon\n",
    "Excerpt: She sailed beyond the horizon, where the sea meets the sky, in search of lands that maps forgot.\n",
    "\n",
    "Title: Echoes of the Forgotten\n",
    "Excerpt: Through the ancient ruins, whispers of the past echoed, telling tales of a civilization lost to time.\n",
    "\n",
    "Title: The Whispering Woods\n",
    "Excerpt:\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "865031a9-28f8-4362-9ebc-6a3611f5bbaf",
   "metadata": {
    "id": "865031a9-28f8-4362-9ebc-6a3611f5bbaf",
    "outputId": "b3b14022-07a4-43d3-d6c6-4d6474c840a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Since there is no review provided for the Starlight Projector, we are unable to determine the sentiment.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Product: Moonlight Lantern\n",
    "Review: The Moonlight Lantern offers a gentle, soothing light that perfectly complements evening gatherings. Its durable design ensures countless nights of enjoyment.\n",
    "Sentiment: Positive\n",
    "\n",
    "Product: SolarWave Backpack\n",
    "Review: Despite its innovative solar charging feature, the SolarWave Backpack falls short in comfort and storage space, making it impractical for longer trips.\n",
    "Sentiment: Negative\n",
    "\n",
    "Product: EchoBuds Wireless Earphones\n",
    "Review: The EchoBuds deliver clear sound quality, but their battery life doesn't live up to expectations, leaving a bit to be desired for power users.\n",
    "Sentiment: Neutral\n",
    "\n",
    "Product: Starlight Projector\n",
    "Review:\n",
    "Sentiment:\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a545033-2c1b-4648-9478-a62149a06bf6",
   "metadata": {
    "id": "8a545033-2c1b-4648-9478-a62149a06bf6",
    "outputId": "e431f216-2536-4fc3-c47b-c5f6017a7f4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This hearty soup is a celebration of fall flavors, with roasted butternut squash, sweet apples, and warm spices like cinnamon and nutmeg, creating a comforting and soul-warming dish perfect for chilly autumn evenings.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Dish: Golden Sunrise Pancakes\n",
    "Description: Infused with a hint of vanilla and topped with fresh, sun-ripened berries, these pancakes are like a burst of sunshine on a plate, promising a delightful start to your day.\n",
    "\n",
    "Dish: Midnight Chocolate Decadence Cake\n",
    "Description: This cake is a dream come true for chocolate lovers, featuring layers of rich, moist chocolate cake, enveloped in a velvety chocolate ganache, perfect for those midnight cravings.\n",
    "\n",
    "Dish: Mediterranean Bliss Salad\n",
    "Description: A vibrant salad that captures the essence of the Mediterranean, combining crisp cucumbers, juicy tomatoes, tangy feta, and olives, dressed in a zesty lemon-olive oil vinaigrette.\n",
    "\n",
    "Dish: Rustic Autumn Squash Soup\n",
    "Description:\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xJz45cRPHswb",
   "metadata": {
    "id": "xJz45cRPHswb"
   },
   "source": [
    "## __Conclusion__\n",
    "By following these steps, you can harness the power of LangChain and OpenAI to perform few-shot prompting, allowing you to leverage advanced language models for a wide range of tasks and applications with ease and precision."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
